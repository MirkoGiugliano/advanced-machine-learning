{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### importo le librerie necessarie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 3669,
     "status": "ok",
     "timestamp": 1571503682644,
     "user": {
      "displayName": "Mirko Giugliano",
      "photoUrl": "",
      "userId": "07128242895425647455"
     },
     "user_tz": -120
    },
    "id": "JxdayaWJn1_c",
    "outputId": "4c1cf6b0-f74f-4df2-8c9a-e9d4ce6f76f0"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.initializers import RandomUniform\n",
    "from keras.regularizers import l1_l2,l2\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "from keras.layers import Dropout\n",
    "from keras import optimizers\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from keras.layers import LeakyReLU\n",
    "from sklearn.metrics import classification_report\n",
    "from keras.layers import Dropout\n",
    "from keras import optimizers\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### importo i dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xZuIYbeqn1_i"
   },
   "outputs": [],
   "source": [
    "train_M=pd.read_csv(\"C:/Users/1995m/OneDrive/Desktop/train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6Ph3EUgYn1_l"
   },
   "outputs": [],
   "source": [
    "test_M=pd.read_csv(\"C:/Users/1995m/OneDrive/Desktop/train.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ottenimento di variabili dummy al posto delle variabili qualitative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 224
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 9851,
     "status": "ok",
     "timestamp": 1571503688923,
     "user": {
      "displayName": "Mirko Giugliano",
      "photoUrl": "",
      "userId": "07128242895425647455"
     },
     "user_tz": -120
    },
    "id": "GJRHDpsK74KK",
    "outputId": "d832071b-93da-4b13-9452-f5efbf2ac18a",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LIMIT_BAL</th>\n",
       "      <th>AGE</th>\n",
       "      <th>PAY_0</th>\n",
       "      <th>PAY_2</th>\n",
       "      <th>PAY_3</th>\n",
       "      <th>PAY_4</th>\n",
       "      <th>PAY_5</th>\n",
       "      <th>PAY_6</th>\n",
       "      <th>BILL_AMT1</th>\n",
       "      <th>BILL_AMT2</th>\n",
       "      <th>...</th>\n",
       "      <th>EDUCATION_1</th>\n",
       "      <th>EDUCATION_2</th>\n",
       "      <th>EDUCATION_3</th>\n",
       "      <th>EDUCATION_4</th>\n",
       "      <th>EDUCATION_5</th>\n",
       "      <th>EDUCATION_6</th>\n",
       "      <th>MARRIAGE_0</th>\n",
       "      <th>MARRIAGE_1</th>\n",
       "      <th>MARRIAGE_2</th>\n",
       "      <th>MARRIAGE_3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20000.0</td>\n",
       "      <td>24</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>3913.0</td>\n",
       "      <td>3102.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>120000.0</td>\n",
       "      <td>26</td>\n",
       "      <td>-1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2682.0</td>\n",
       "      <td>1725.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>90000.0</td>\n",
       "      <td>34</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>29239.0</td>\n",
       "      <td>14027.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>50000.0</td>\n",
       "      <td>37</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>46990.0</td>\n",
       "      <td>48233.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>50000.0</td>\n",
       "      <td>57</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8617.0</td>\n",
       "      <td>5670.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 34 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   LIMIT_BAL  AGE  PAY_0  PAY_2  PAY_3  PAY_4  PAY_5  PAY_6  BILL_AMT1  \\\n",
       "0    20000.0   24      2      2     -1     -1     -2     -2     3913.0   \n",
       "1   120000.0   26     -1      2      0      0      0      2     2682.0   \n",
       "2    90000.0   34      0      0      0      0      0      0    29239.0   \n",
       "3    50000.0   37      0      0      0      0      0      0    46990.0   \n",
       "4    50000.0   57     -1      0     -1      0      0      0     8617.0   \n",
       "\n",
       "   BILL_AMT2  ...  EDUCATION_1  EDUCATION_2  EDUCATION_3  EDUCATION_4  \\\n",
       "0     3102.0  ...            0            1            0            0   \n",
       "1     1725.0  ...            0            1            0            0   \n",
       "2    14027.0  ...            0            1            0            0   \n",
       "3    48233.0  ...            0            1            0            0   \n",
       "4     5670.0  ...            0            1            0            0   \n",
       "\n",
       "   EDUCATION_5  EDUCATION_6  MARRIAGE_0  MARRIAGE_1  MARRIAGE_2  MARRIAGE_3  \n",
       "0            0            0           0           1           0           0  \n",
       "1            0            0           0           0           1           0  \n",
       "2            0            0           0           0           1           0  \n",
       "3            0            0           0           1           0           0  \n",
       "4            0            0           0           1           0           0  \n",
       "\n",
       "[5 rows x 34 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_M = pd.get_dummies(train_M,columns=[\"SEX\",\"EDUCATION\",\"MARRIAGE\"])\n",
    "train_M.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### standardizzazione variabili numeriche\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "NDmCN8nm74sf"
   },
   "outputs": [],
   "source": [
    "features = [\"LIMIT_BAL\",\"AGE\",\"PAY_0\",\"PAY_2\",\"PAY_3\",\"PAY_4\",\"PAY_5\",\"PAY_6\",\"BILL_AMT1\",\"BILL_AMT2\",\"BILL_AMT3\",\"BILL_AMT4\",\"BILL_AMT5\",\"BILL_AMT6\",\"PAY_AMT1\",\"PAY_AMT2\",\"PAY_AMT3\",\"PAY_AMT4\",\"PAY_AMT5\",\"PAY_AMT6\"]\n",
    "to_std = train_M[features]\n",
    "train_M[features] = (to_std - to_std.mean())/to_std.std()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### divisione train e test set\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "X4x22wwLoffN"
   },
   "outputs": [],
   "source": [
    "train,test=train_test_split(train_M)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 9816,
     "status": "ok",
     "timestamp": 1571503688925,
     "user": {
      "displayName": "Mirko Giugliano",
      "photoUrl": "",
      "userId": "07128242895425647455"
     },
     "user_tz": -120
    },
    "id": "NorloNhlpbJG",
    "outputId": "b851019a-370e-4ee6-c70e-3a7051971f4b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6750, 34)"
      ]
     },
     "execution_count": 10,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### bilanciamento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "G33AFDo96yuT"
   },
   "outputs": [],
   "source": [
    "train_0=train[train[\"default.payment.next.month\"]==0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 9770,
     "status": "ok",
     "timestamp": 1571503688926,
     "user": {
      "displayName": "Mirko Giugliano",
      "photoUrl": "",
      "userId": "07128242895425647455"
     },
     "user_tz": -120
    },
    "id": "nFbV7MQQ7kAz",
    "outputId": "d618d415-4e00-441a-d90a-659ae53d0fe2"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(15814, 34)"
      ]
     },
     "execution_count": 12,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_0.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "pg8lklzS7A2C"
   },
   "outputs": [],
   "source": [
    "train_1=train[train[\"default.payment.next.month\"]==1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 9743,
     "status": "ok",
     "timestamp": 1571503688928,
     "user": {
      "displayName": "Mirko Giugliano",
      "photoUrl": "",
      "userId": "07128242895425647455"
     },
     "user_tz": -120
    },
    "id": "050lHwWj7cPA",
    "outputId": "397d9e8a-bc59-4887-dc43-a827d1b1d210"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4436, 34)"
      ]
     },
     "execution_count": 14,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "J60RZ3bD7rIp"
   },
   "outputs": [],
   "source": [
    "train_0b=train_0.sample(n=train_1.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 9708,
     "status": "ok",
     "timestamp": 1571503688930,
     "user": {
      "displayName": "Mirko Giugliano",
      "photoUrl": "",
      "userId": "07128242895425647455"
     },
     "user_tz": -120
    },
    "id": "7GWLL22_B8As",
    "outputId": "d635eee0-6962-4e98-8828-dcb6fb68f908"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4436, 34)"
      ]
     },
     "execution_count": 16,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_0b.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7_x8uiEc77-0"
   },
   "outputs": [],
   "source": [
    "train_balanced=pd.concat([train_1,train_0b],axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 9668,
     "status": "ok",
     "timestamp": 1571503688932,
     "user": {
      "displayName": "Mirko Giugliano",
      "photoUrl": "",
      "userId": "07128242895425647455"
     },
     "user_tz": -120
    },
    "id": "kfr7XZucn1__",
    "outputId": "a5912e26-6cc7-44b8-b3b4-dae4f877aa4f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8872, 34)"
      ]
     },
     "execution_count": 18,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_balanced.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 224
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 9651,
     "status": "ok",
     "timestamp": 1571503688933,
     "user": {
      "displayName": "Mirko Giugliano",
      "photoUrl": "",
      "userId": "07128242895425647455"
     },
     "user_tz": -120
    },
    "id": "b4nN_q8Yy2d_",
    "outputId": "f498e841-6dbf-4d7d-e7ca-3cfeede2e90c"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LIMIT_BAL</th>\n",
       "      <th>AGE</th>\n",
       "      <th>PAY_0</th>\n",
       "      <th>PAY_2</th>\n",
       "      <th>PAY_3</th>\n",
       "      <th>PAY_4</th>\n",
       "      <th>PAY_5</th>\n",
       "      <th>PAY_6</th>\n",
       "      <th>BILL_AMT1</th>\n",
       "      <th>BILL_AMT2</th>\n",
       "      <th>BILL_AMT3</th>\n",
       "      <th>BILL_AMT4</th>\n",
       "      <th>BILL_AMT5</th>\n",
       "      <th>BILL_AMT6</th>\n",
       "      <th>PAY_AMT1</th>\n",
       "      <th>PAY_AMT2</th>\n",
       "      <th>PAY_AMT3</th>\n",
       "      <th>PAY_AMT4</th>\n",
       "      <th>PAY_AMT5</th>\n",
       "      <th>PAY_AMT6</th>\n",
       "      <th>default.payment.next.month</th>\n",
       "      <th>SEX_1</th>\n",
       "      <th>SEX_2</th>\n",
       "      <th>EDUCATION_0</th>\n",
       "      <th>EDUCATION_1</th>\n",
       "      <th>EDUCATION_2</th>\n",
       "      <th>EDUCATION_3</th>\n",
       "      <th>EDUCATION_4</th>\n",
       "      <th>EDUCATION_5</th>\n",
       "      <th>EDUCATION_6</th>\n",
       "      <th>MARRIAGE_0</th>\n",
       "      <th>MARRIAGE_1</th>\n",
       "      <th>MARRIAGE_2</th>\n",
       "      <th>MARRIAGE_3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>16171</th>\n",
       "      <td>-0.055641</td>\n",
       "      <td>0.166550</td>\n",
       "      <td>0.904137</td>\n",
       "      <td>1.779066</td>\n",
       "      <td>1.806072</td>\n",
       "      <td>0.186622</td>\n",
       "      <td>0.233215</td>\n",
       "      <td>0.251359</td>\n",
       "      <td>0.659189</td>\n",
       "      <td>0.732302</td>\n",
       "      <td>0.746397</td>\n",
       "      <td>0.732835</td>\n",
       "      <td>0.826945</td>\n",
       "      <td>0.901211</td>\n",
       "      <td>-0.082135</td>\n",
       "      <td>-0.252186</td>\n",
       "      <td>-0.057612</td>\n",
       "      <td>-0.101017</td>\n",
       "      <td>-0.092764</td>\n",
       "      <td>-0.092529</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12148</th>\n",
       "      <td>-1.138083</td>\n",
       "      <td>-1.245505</td>\n",
       "      <td>0.904137</td>\n",
       "      <td>-0.725180</td>\n",
       "      <td>-0.696611</td>\n",
       "      <td>-1.519997</td>\n",
       "      <td>-1.525917</td>\n",
       "      <td>-1.482373</td>\n",
       "      <td>-0.698120</td>\n",
       "      <td>-0.628439</td>\n",
       "      <td>-0.678093</td>\n",
       "      <td>-0.671943</td>\n",
       "      <td>-0.662903</td>\n",
       "      <td>-0.653703</td>\n",
       "      <td>0.441060</td>\n",
       "      <td>-0.233777</td>\n",
       "      <td>-0.293741</td>\n",
       "      <td>-0.303667</td>\n",
       "      <td>-0.318774</td>\n",
       "      <td>-0.288988</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4379</th>\n",
       "      <td>1.181434</td>\n",
       "      <td>-0.811027</td>\n",
       "      <td>0.904137</td>\n",
       "      <td>-1.559929</td>\n",
       "      <td>-0.696611</td>\n",
       "      <td>-0.666688</td>\n",
       "      <td>-0.646351</td>\n",
       "      <td>-0.615507</td>\n",
       "      <td>-0.698011</td>\n",
       "      <td>-0.691460</td>\n",
       "      <td>-0.660775</td>\n",
       "      <td>-0.671943</td>\n",
       "      <td>-0.653035</td>\n",
       "      <td>-0.553939</td>\n",
       "      <td>-0.336401</td>\n",
       "      <td>-0.201169</td>\n",
       "      <td>-0.293741</td>\n",
       "      <td>-0.266116</td>\n",
       "      <td>0.075880</td>\n",
       "      <td>-0.262978</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4089</th>\n",
       "      <td>-0.983448</td>\n",
       "      <td>-1.354125</td>\n",
       "      <td>-0.872681</td>\n",
       "      <td>1.779066</td>\n",
       "      <td>-0.696611</td>\n",
       "      <td>-0.666688</td>\n",
       "      <td>0.233215</td>\n",
       "      <td>0.251359</td>\n",
       "      <td>-0.689144</td>\n",
       "      <td>-0.686879</td>\n",
       "      <td>-0.673388</td>\n",
       "      <td>-0.262423</td>\n",
       "      <td>-0.258782</td>\n",
       "      <td>-0.234984</td>\n",
       "      <td>-0.336401</td>\n",
       "      <td>-0.238326</td>\n",
       "      <td>1.188810</td>\n",
       "      <td>-0.248217</td>\n",
       "      <td>-0.247315</td>\n",
       "      <td>-0.243055</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3003</th>\n",
       "      <td>1.954607</td>\n",
       "      <td>0.166550</td>\n",
       "      <td>0.015728</td>\n",
       "      <td>0.109569</td>\n",
       "      <td>0.137617</td>\n",
       "      <td>0.186622</td>\n",
       "      <td>0.233215</td>\n",
       "      <td>0.251359</td>\n",
       "      <td>4.949547</td>\n",
       "      <td>5.092448</td>\n",
       "      <td>4.926624</td>\n",
       "      <td>5.384720</td>\n",
       "      <td>5.886535</td>\n",
       "      <td>6.229423</td>\n",
       "      <td>0.659965</td>\n",
       "      <td>0.407722</td>\n",
       "      <td>0.493355</td>\n",
       "      <td>0.603814</td>\n",
       "      <td>0.878215</td>\n",
       "      <td>0.415665</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       LIMIT_BAL       AGE     PAY_0  ...  MARRIAGE_1  MARRIAGE_2  MARRIAGE_3\n",
       "16171  -0.055641  0.166550  0.904137  ...           0           1           0\n",
       "12148  -1.138083 -1.245505  0.904137  ...           0           1           0\n",
       "4379    1.181434 -0.811027  0.904137  ...           0           1           0\n",
       "4089   -0.983448 -1.354125 -0.872681  ...           0           1           0\n",
       "3003    1.954607  0.166550  0.015728  ...           1           0           0\n",
       "\n",
       "[5 rows x 34 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_balanced.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 9614,
     "status": "ok",
     "timestamp": 1571503688935,
     "user": {
      "displayName": "Mirko Giugliano",
      "photoUrl": "",
      "userId": "07128242895425647455"
     },
     "user_tz": -120
    },
    "id": "VVm630EG2mN4",
    "outputId": "ab3bc9da-c402-4439-ac6d-13891c390e83"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8872, 34)"
      ]
     },
     "execution_count": 21,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_balanced.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### creazione numpy array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "XW3nAsLun2AC"
   },
   "outputs": [],
   "source": [
    "X=train_balanced.drop(\"default.payment.next.month\",axis=1).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9Kp7tmTDn2AG"
   },
   "outputs": [],
   "source": [
    "Y=train_balanced[\"default.payment.next.month\"].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3rTTMbXVEpmD"
   },
   "outputs": [],
   "source": [
    "X_test=test.drop(\"default.payment.next.month\",axis=1).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2nO7wAWfq1aZ"
   },
   "outputs": [],
   "source": [
    "Y_test=test[\"default.payment.next.month\"].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 9421,
     "status": "ok",
     "timestamp": 1571503688939,
     "user": {
      "displayName": "Mirko Giugliano",
      "photoUrl": "",
      "userId": "07128242895425647455"
     },
     "user_tz": -120
    },
    "id": "DI0p_KcR3tau",
    "outputId": "b8463203-b033-4b1d-bc01-69cc57569f55"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "33"
      ]
     },
     "execution_count": 27,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### creazione e valutazione modello 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 172652,
     "status": "ok",
     "timestamp": 1571503852185,
     "user": {
      "displayName": "Mirko Giugliano",
      "photoUrl": "",
      "userId": "07128242895425647455"
     },
     "user_tz": -120
    },
    "id": "pA6n5lppn2AP",
    "outputId": "5e2bde02-8ba3-4df2-bb7c-71669fb050a8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:66: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:541: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4432: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:148: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3733: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:793: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3657: The name tf.log is deprecated. Please use tf.math.log instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/nn_impl.py:183: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1033: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1020: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
      "\n",
      "Train on 8872 samples, validate on 6750 samples\n",
      "Epoch 1/700\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:216: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:223: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
      "\n",
      "8872/8872 [==============================] - 1s 135us/step - loss: 0.6712 - acc: 0.5809 - val_loss: 0.6761 - val_acc: 0.5671\n",
      "Epoch 2/700\n",
      "8872/8872 [==============================] - 0s 29us/step - loss: 0.6524 - acc: 0.6108 - val_loss: 0.6653 - val_acc: 0.6006\n",
      "Epoch 3/700\n",
      "8872/8872 [==============================] - 0s 26us/step - loss: 0.6399 - acc: 0.6241 - val_loss: 0.6562 - val_acc: 0.6197\n",
      "Epoch 4/700\n",
      "8872/8872 [==============================] - 0s 24us/step - loss: 0.6329 - acc: 0.6335 - val_loss: 0.6464 - val_acc: 0.6462\n",
      "Epoch 5/700\n",
      "8872/8872 [==============================] - 0s 24us/step - loss: 0.6267 - acc: 0.6504 - val_loss: 0.6422 - val_acc: 0.6561\n",
      "Epoch 6/700\n",
      "8872/8872 [==============================] - 0s 24us/step - loss: 0.6243 - acc: 0.6513 - val_loss: 0.6376 - val_acc: 0.6723\n",
      "Epoch 7/700\n",
      "8872/8872 [==============================] - 0s 25us/step - loss: 0.6190 - acc: 0.6605 - val_loss: 0.6326 - val_acc: 0.6921\n",
      "Epoch 8/700\n",
      "8872/8872 [==============================] - 0s 26us/step - loss: 0.6168 - acc: 0.6669 - val_loss: 0.6286 - val_acc: 0.7105\n",
      "Epoch 9/700\n",
      "8872/8872 [==============================] - 0s 25us/step - loss: 0.6138 - acc: 0.6688 - val_loss: 0.6257 - val_acc: 0.7227\n",
      "Epoch 10/700\n",
      "8872/8872 [==============================] - 0s 31us/step - loss: 0.6110 - acc: 0.6729 - val_loss: 0.6212 - val_acc: 0.7341\n",
      "Epoch 11/700\n",
      "8872/8872 [==============================] - 0s 29us/step - loss: 0.6087 - acc: 0.6818 - val_loss: 0.6166 - val_acc: 0.7455\n",
      "Epoch 12/700\n",
      "8872/8872 [==============================] - 0s 27us/step - loss: 0.6075 - acc: 0.6834 - val_loss: 0.6153 - val_acc: 0.7479\n",
      "Epoch 13/700\n",
      "8872/8872 [==============================] - 0s 27us/step - loss: 0.6066 - acc: 0.6895 - val_loss: 0.6124 - val_acc: 0.7533\n",
      "Epoch 14/700\n",
      "8872/8872 [==============================] - 0s 24us/step - loss: 0.6047 - acc: 0.6900 - val_loss: 0.6101 - val_acc: 0.7550\n",
      "Epoch 15/700\n",
      "8872/8872 [==============================] - 0s 25us/step - loss: 0.6026 - acc: 0.6907 - val_loss: 0.6055 - val_acc: 0.7607\n",
      "Epoch 16/700\n",
      "8872/8872 [==============================] - 0s 24us/step - loss: 0.6018 - acc: 0.6943 - val_loss: 0.6065 - val_acc: 0.7597\n",
      "Epoch 17/700\n",
      "8872/8872 [==============================] - 0s 25us/step - loss: 0.6011 - acc: 0.6934 - val_loss: 0.6039 - val_acc: 0.7628\n",
      "Epoch 18/700\n",
      "8872/8872 [==============================] - 0s 25us/step - loss: 0.5989 - acc: 0.6957 - val_loss: 0.6003 - val_acc: 0.7655\n",
      "Epoch 19/700\n",
      "8872/8872 [==============================] - 0s 28us/step - loss: 0.5990 - acc: 0.6942 - val_loss: 0.5993 - val_acc: 0.7662\n",
      "Epoch 20/700\n",
      "8872/8872 [==============================] - 0s 26us/step - loss: 0.5964 - acc: 0.6996 - val_loss: 0.5973 - val_acc: 0.7664\n",
      "Epoch 21/700\n",
      "8872/8872 [==============================] - 0s 25us/step - loss: 0.5956 - acc: 0.6972 - val_loss: 0.5961 - val_acc: 0.7681\n",
      "Epoch 22/700\n",
      "8872/8872 [==============================] - 0s 27us/step - loss: 0.5967 - acc: 0.6986 - val_loss: 0.5936 - val_acc: 0.7696\n",
      "Epoch 23/700\n",
      "8872/8872 [==============================] - 0s 30us/step - loss: 0.5953 - acc: 0.6993 - val_loss: 0.5934 - val_acc: 0.7686\n",
      "Epoch 24/700\n",
      "8872/8872 [==============================] - 0s 27us/step - loss: 0.5928 - acc: 0.6983 - val_loss: 0.5924 - val_acc: 0.7687\n",
      "Epoch 25/700\n",
      "8872/8872 [==============================] - 0s 26us/step - loss: 0.5937 - acc: 0.7016 - val_loss: 0.5907 - val_acc: 0.7680\n",
      "Epoch 26/700\n",
      "8872/8872 [==============================] - 0s 25us/step - loss: 0.5924 - acc: 0.6992 - val_loss: 0.5893 - val_acc: 0.7693\n",
      "Epoch 27/700\n",
      "8872/8872 [==============================] - 0s 26us/step - loss: 0.5919 - acc: 0.7009 - val_loss: 0.5880 - val_acc: 0.7689\n",
      "Epoch 28/700\n",
      "8872/8872 [==============================] - 0s 24us/step - loss: 0.5902 - acc: 0.7003 - val_loss: 0.5873 - val_acc: 0.7693\n",
      "Epoch 29/700\n",
      "8872/8872 [==============================] - 0s 25us/step - loss: 0.5897 - acc: 0.7011 - val_loss: 0.5898 - val_acc: 0.7670\n",
      "Epoch 30/700\n",
      "8872/8872 [==============================] - 0s 28us/step - loss: 0.5897 - acc: 0.7032 - val_loss: 0.5877 - val_acc: 0.7674\n",
      "Epoch 31/700\n",
      "8872/8872 [==============================] - 0s 24us/step - loss: 0.5896 - acc: 0.6993 - val_loss: 0.5869 - val_acc: 0.7679\n",
      "Epoch 32/700\n",
      "8872/8872 [==============================] - 0s 23us/step - loss: 0.5888 - acc: 0.7004 - val_loss: 0.5852 - val_acc: 0.7683\n",
      "Epoch 33/700\n",
      "8872/8872 [==============================] - 0s 24us/step - loss: 0.5883 - acc: 0.7006 - val_loss: 0.5848 - val_acc: 0.7681\n",
      "Epoch 34/700\n",
      "8872/8872 [==============================] - 0s 26us/step - loss: 0.5885 - acc: 0.7013 - val_loss: 0.5833 - val_acc: 0.7690\n",
      "Epoch 35/700\n",
      "8872/8872 [==============================] - 0s 25us/step - loss: 0.5871 - acc: 0.7027 - val_loss: 0.5816 - val_acc: 0.7695\n",
      "Epoch 36/700\n",
      "8872/8872 [==============================] - 0s 25us/step - loss: 0.5880 - acc: 0.7011 - val_loss: 0.5810 - val_acc: 0.7699\n",
      "Epoch 37/700\n",
      "8872/8872 [==============================] - 0s 26us/step - loss: 0.5869 - acc: 0.7032 - val_loss: 0.5800 - val_acc: 0.7704\n",
      "Epoch 38/700\n",
      "8872/8872 [==============================] - 0s 26us/step - loss: 0.5876 - acc: 0.7021 - val_loss: 0.5810 - val_acc: 0.7695\n",
      "Epoch 39/700\n",
      "8872/8872 [==============================] - 0s 26us/step - loss: 0.5867 - acc: 0.7030 - val_loss: 0.5786 - val_acc: 0.7708\n",
      "Epoch 40/700\n",
      "8872/8872 [==============================] - 0s 25us/step - loss: 0.5868 - acc: 0.6989 - val_loss: 0.5776 - val_acc: 0.7711\n",
      "Epoch 41/700\n",
      "8872/8872 [==============================] - 0s 25us/step - loss: 0.5852 - acc: 0.7048 - val_loss: 0.5757 - val_acc: 0.7717\n",
      "Epoch 42/700\n",
      "8872/8872 [==============================] - 0s 23us/step - loss: 0.5850 - acc: 0.7029 - val_loss: 0.5780 - val_acc: 0.7701\n",
      "Epoch 43/700\n",
      "8872/8872 [==============================] - 0s 25us/step - loss: 0.5836 - acc: 0.7033 - val_loss: 0.5773 - val_acc: 0.7701\n",
      "Epoch 44/700\n",
      "8872/8872 [==============================] - 0s 27us/step - loss: 0.5835 - acc: 0.7024 - val_loss: 0.5777 - val_acc: 0.7699\n",
      "Epoch 45/700\n",
      "8872/8872 [==============================] - 0s 29us/step - loss: 0.5842 - acc: 0.7036 - val_loss: 0.5751 - val_acc: 0.7716\n",
      "Epoch 46/700\n",
      "8872/8872 [==============================] - 0s 24us/step - loss: 0.5847 - acc: 0.7040 - val_loss: 0.5762 - val_acc: 0.7704\n",
      "Epoch 47/700\n",
      "8872/8872 [==============================] - 0s 24us/step - loss: 0.5825 - acc: 0.7047 - val_loss: 0.5769 - val_acc: 0.7690\n",
      "Epoch 48/700\n",
      "8872/8872 [==============================] - 0s 26us/step - loss: 0.5848 - acc: 0.7024 - val_loss: 0.5765 - val_acc: 0.7693\n",
      "Epoch 49/700\n",
      "8872/8872 [==============================] - 0s 24us/step - loss: 0.5823 - acc: 0.7036 - val_loss: 0.5748 - val_acc: 0.7702\n",
      "Epoch 50/700\n",
      "8872/8872 [==============================] - 0s 26us/step - loss: 0.5820 - acc: 0.7045 - val_loss: 0.5745 - val_acc: 0.7705\n",
      "Epoch 51/700\n",
      "8872/8872 [==============================] - 0s 25us/step - loss: 0.5825 - acc: 0.7024 - val_loss: 0.5746 - val_acc: 0.7701\n",
      "Epoch 52/700\n",
      "8872/8872 [==============================] - 0s 25us/step - loss: 0.5816 - acc: 0.7031 - val_loss: 0.5741 - val_acc: 0.7696\n",
      "Epoch 53/700\n",
      "8872/8872 [==============================] - 0s 26us/step - loss: 0.5807 - acc: 0.7074 - val_loss: 0.5738 - val_acc: 0.7698\n",
      "Epoch 54/700\n",
      "8872/8872 [==============================] - 0s 26us/step - loss: 0.5807 - acc: 0.7014 - val_loss: 0.5738 - val_acc: 0.7696\n",
      "Epoch 55/700\n",
      "8872/8872 [==============================] - 0s 27us/step - loss: 0.5816 - acc: 0.7039 - val_loss: 0.5743 - val_acc: 0.7696\n",
      "Epoch 56/700\n",
      "8872/8872 [==============================] - 0s 27us/step - loss: 0.5808 - acc: 0.7044 - val_loss: 0.5753 - val_acc: 0.7683\n",
      "Epoch 57/700\n",
      "8872/8872 [==============================] - 0s 26us/step - loss: 0.5818 - acc: 0.7030 - val_loss: 0.5742 - val_acc: 0.7689\n",
      "Epoch 58/700\n",
      "8872/8872 [==============================] - 0s 23us/step - loss: 0.5808 - acc: 0.7074 - val_loss: 0.5709 - val_acc: 0.7708\n",
      "Epoch 59/700\n",
      "8872/8872 [==============================] - 0s 23us/step - loss: 0.5806 - acc: 0.7015 - val_loss: 0.5727 - val_acc: 0.7692\n",
      "Epoch 60/700\n",
      "8872/8872 [==============================] - 0s 23us/step - loss: 0.5809 - acc: 0.7044 - val_loss: 0.5746 - val_acc: 0.7683\n",
      "Epoch 61/700\n",
      "8872/8872 [==============================] - 0s 23us/step - loss: 0.5796 - acc: 0.7014 - val_loss: 0.5751 - val_acc: 0.7677\n",
      "Epoch 62/700\n",
      "8872/8872 [==============================] - 0s 29us/step - loss: 0.5786 - acc: 0.7077 - val_loss: 0.5713 - val_acc: 0.7696\n",
      "Epoch 63/700\n",
      "8872/8872 [==============================] - 0s 31us/step - loss: 0.5792 - acc: 0.7050 - val_loss: 0.5704 - val_acc: 0.7698\n",
      "Epoch 64/700\n",
      "8872/8872 [==============================] - 0s 31us/step - loss: 0.5791 - acc: 0.7040 - val_loss: 0.5712 - val_acc: 0.7693\n",
      "Epoch 65/700\n",
      "8872/8872 [==============================] - 0s 33us/step - loss: 0.5797 - acc: 0.7057 - val_loss: 0.5711 - val_acc: 0.7695\n",
      "Epoch 66/700\n",
      "8872/8872 [==============================] - 0s 29us/step - loss: 0.5771 - acc: 0.7073 - val_loss: 0.5704 - val_acc: 0.7695\n",
      "Epoch 67/700\n",
      "8872/8872 [==============================] - 0s 29us/step - loss: 0.5783 - acc: 0.7080 - val_loss: 0.5692 - val_acc: 0.7704\n",
      "Epoch 68/700\n",
      "8872/8872 [==============================] - 0s 24us/step - loss: 0.5772 - acc: 0.7034 - val_loss: 0.5695 - val_acc: 0.7698\n",
      "Epoch 69/700\n",
      "8872/8872 [==============================] - 0s 26us/step - loss: 0.5761 - acc: 0.7080 - val_loss: 0.5693 - val_acc: 0.7695\n",
      "Epoch 70/700\n",
      "8872/8872 [==============================] - 0s 27us/step - loss: 0.5777 - acc: 0.7057 - val_loss: 0.5688 - val_acc: 0.7696\n",
      "Epoch 71/700\n",
      "8872/8872 [==============================] - 0s 24us/step - loss: 0.5765 - acc: 0.7042 - val_loss: 0.5698 - val_acc: 0.7695\n",
      "Epoch 72/700\n",
      "8872/8872 [==============================] - 0s 26us/step - loss: 0.5769 - acc: 0.7071 - val_loss: 0.5682 - val_acc: 0.7698\n",
      "Epoch 73/700\n",
      "8872/8872 [==============================] - 0s 26us/step - loss: 0.5767 - acc: 0.7076 - val_loss: 0.5699 - val_acc: 0.7701\n",
      "Epoch 74/700\n",
      "8872/8872 [==============================] - 0s 26us/step - loss: 0.5776 - acc: 0.7075 - val_loss: 0.5686 - val_acc: 0.7701\n",
      "Epoch 75/700\n",
      "8872/8872 [==============================] - 0s 26us/step - loss: 0.5764 - acc: 0.7096 - val_loss: 0.5697 - val_acc: 0.7704\n",
      "Epoch 76/700\n",
      "8872/8872 [==============================] - 0s 25us/step - loss: 0.5766 - acc: 0.7055 - val_loss: 0.5711 - val_acc: 0.7701\n",
      "Epoch 77/700\n",
      "8872/8872 [==============================] - 0s 24us/step - loss: 0.5761 - acc: 0.7073 - val_loss: 0.5710 - val_acc: 0.7699\n",
      "Epoch 78/700\n",
      "8872/8872 [==============================] - 0s 28us/step - loss: 0.5763 - acc: 0.7073 - val_loss: 0.5672 - val_acc: 0.7704\n",
      "Epoch 79/700\n",
      "8872/8872 [==============================] - 0s 29us/step - loss: 0.5762 - acc: 0.7054 - val_loss: 0.5715 - val_acc: 0.7696\n",
      "Epoch 80/700\n",
      "8872/8872 [==============================] - 0s 28us/step - loss: 0.5760 - acc: 0.7039 - val_loss: 0.5680 - val_acc: 0.7701\n",
      "Epoch 81/700\n",
      "8872/8872 [==============================] - 0s 25us/step - loss: 0.5750 - acc: 0.7076 - val_loss: 0.5687 - val_acc: 0.7698\n",
      "Epoch 82/700\n",
      "8872/8872 [==============================] - 0s 24us/step - loss: 0.5751 - acc: 0.7087 - val_loss: 0.5682 - val_acc: 0.7698\n",
      "Epoch 83/700\n",
      "8872/8872 [==============================] - 0s 26us/step - loss: 0.5741 - acc: 0.7074 - val_loss: 0.5699 - val_acc: 0.7692\n",
      "Epoch 84/700\n",
      "8872/8872 [==============================] - 0s 24us/step - loss: 0.5751 - acc: 0.7090 - val_loss: 0.5691 - val_acc: 0.7695\n",
      "Epoch 85/700\n",
      "8872/8872 [==============================] - 0s 26us/step - loss: 0.5743 - acc: 0.7091 - val_loss: 0.5672 - val_acc: 0.7698\n",
      "Epoch 86/700\n",
      "8872/8872 [==============================] - 0s 24us/step - loss: 0.5747 - acc: 0.7083 - val_loss: 0.5685 - val_acc: 0.7696\n",
      "Epoch 87/700\n",
      "8872/8872 [==============================] - 0s 31us/step - loss: 0.5749 - acc: 0.7080 - val_loss: 0.5678 - val_acc: 0.7696\n",
      "Epoch 88/700\n",
      "8872/8872 [==============================] - 0s 30us/step - loss: 0.5750 - acc: 0.7093 - val_loss: 0.5679 - val_acc: 0.7690\n",
      "Epoch 89/700\n",
      "8872/8872 [==============================] - 0s 26us/step - loss: 0.5737 - acc: 0.7116 - val_loss: 0.5678 - val_acc: 0.7680\n",
      "Epoch 90/700\n",
      "8872/8872 [==============================] - 0s 26us/step - loss: 0.5732 - acc: 0.7098 - val_loss: 0.5657 - val_acc: 0.7699\n",
      "Epoch 91/700\n",
      "8872/8872 [==============================] - 0s 26us/step - loss: 0.5724 - acc: 0.7084 - val_loss: 0.5672 - val_acc: 0.7686\n",
      "Epoch 92/700\n",
      "8872/8872 [==============================] - 0s 26us/step - loss: 0.5727 - acc: 0.7112 - val_loss: 0.5622 - val_acc: 0.7707\n",
      "Epoch 93/700\n",
      "8872/8872 [==============================] - 0s 25us/step - loss: 0.5736 - acc: 0.7101 - val_loss: 0.5635 - val_acc: 0.7696\n",
      "Epoch 94/700\n",
      "8872/8872 [==============================] - 0s 25us/step - loss: 0.5733 - acc: 0.7118 - val_loss: 0.5677 - val_acc: 0.7674\n",
      "Epoch 95/700\n",
      "8872/8872 [==============================] - 0s 26us/step - loss: 0.5724 - acc: 0.7101 - val_loss: 0.5636 - val_acc: 0.7699\n",
      "Epoch 96/700\n",
      "8872/8872 [==============================] - 0s 27us/step - loss: 0.5738 - acc: 0.7113 - val_loss: 0.5631 - val_acc: 0.7695\n",
      "Epoch 97/700\n",
      "8872/8872 [==============================] - 0s 25us/step - loss: 0.5721 - acc: 0.7089 - val_loss: 0.5626 - val_acc: 0.7711\n",
      "Epoch 98/700\n",
      "8872/8872 [==============================] - 0s 28us/step - loss: 0.5720 - acc: 0.7095 - val_loss: 0.5652 - val_acc: 0.7692\n",
      "Epoch 99/700\n",
      "8872/8872 [==============================] - 0s 30us/step - loss: 0.5726 - acc: 0.7073 - val_loss: 0.5659 - val_acc: 0.7683\n",
      "Epoch 100/700\n",
      "8872/8872 [==============================] - 0s 26us/step - loss: 0.5724 - acc: 0.7101 - val_loss: 0.5667 - val_acc: 0.7681\n",
      "Epoch 101/700\n",
      "8872/8872 [==============================] - 0s 26us/step - loss: 0.5714 - acc: 0.7130 - val_loss: 0.5661 - val_acc: 0.7683\n",
      "Epoch 102/700\n",
      "8872/8872 [==============================] - 0s 26us/step - loss: 0.5725 - acc: 0.7080 - val_loss: 0.5661 - val_acc: 0.7681\n",
      "Epoch 103/700\n",
      "8872/8872 [==============================] - 0s 25us/step - loss: 0.5706 - acc: 0.7089 - val_loss: 0.5648 - val_acc: 0.7681\n",
      "Epoch 104/700\n",
      "8872/8872 [==============================] - 0s 23us/step - loss: 0.5713 - acc: 0.7109 - val_loss: 0.5617 - val_acc: 0.7698\n",
      "Epoch 105/700\n",
      "8872/8872 [==============================] - 0s 26us/step - loss: 0.5708 - acc: 0.7087 - val_loss: 0.5661 - val_acc: 0.7677\n",
      "Epoch 106/700\n",
      "8872/8872 [==============================] - 0s 25us/step - loss: 0.5711 - acc: 0.7093 - val_loss: 0.5642 - val_acc: 0.7684\n",
      "Epoch 107/700\n",
      "8872/8872 [==============================] - 0s 23us/step - loss: 0.5699 - acc: 0.7120 - val_loss: 0.5642 - val_acc: 0.7679\n",
      "Epoch 108/700\n",
      "8872/8872 [==============================] - 0s 24us/step - loss: 0.5689 - acc: 0.7136 - val_loss: 0.5657 - val_acc: 0.7665\n",
      "Epoch 109/700\n",
      "8872/8872 [==============================] - 0s 26us/step - loss: 0.5733 - acc: 0.7076 - val_loss: 0.5609 - val_acc: 0.7696\n",
      "Epoch 110/700\n",
      "8872/8872 [==============================] - 0s 24us/step - loss: 0.5704 - acc: 0.7091 - val_loss: 0.5622 - val_acc: 0.7686\n",
      "Epoch 111/700\n",
      "8872/8872 [==============================] - 0s 24us/step - loss: 0.5692 - acc: 0.7116 - val_loss: 0.5636 - val_acc: 0.7670\n",
      "Epoch 112/700\n",
      "8872/8872 [==============================] - 0s 24us/step - loss: 0.5721 - acc: 0.7128 - val_loss: 0.5627 - val_acc: 0.7671\n",
      "Epoch 113/700\n",
      "8872/8872 [==============================] - 0s 24us/step - loss: 0.5690 - acc: 0.7126 - val_loss: 0.5641 - val_acc: 0.7661\n",
      "Epoch 114/700\n",
      "8872/8872 [==============================] - 0s 26us/step - loss: 0.5704 - acc: 0.7095 - val_loss: 0.5632 - val_acc: 0.7670\n",
      "Epoch 115/700\n",
      "8872/8872 [==============================] - 0s 25us/step - loss: 0.5700 - acc: 0.7125 - val_loss: 0.5662 - val_acc: 0.7639\n",
      "Epoch 116/700\n",
      "8872/8872 [==============================] - 0s 24us/step - loss: 0.5703 - acc: 0.7107 - val_loss: 0.5624 - val_acc: 0.7664\n",
      "Epoch 117/700\n",
      "8872/8872 [==============================] - 0s 26us/step - loss: 0.5687 - acc: 0.7130 - val_loss: 0.5630 - val_acc: 0.7655\n",
      "Epoch 118/700\n",
      "8872/8872 [==============================] - 0s 24us/step - loss: 0.5687 - acc: 0.7142 - val_loss: 0.5603 - val_acc: 0.7671\n",
      "Epoch 119/700\n",
      "8872/8872 [==============================] - 0s 26us/step - loss: 0.5694 - acc: 0.7103 - val_loss: 0.5625 - val_acc: 0.7662\n",
      "Epoch 120/700\n",
      "8872/8872 [==============================] - 0s 26us/step - loss: 0.5704 - acc: 0.7128 - val_loss: 0.5616 - val_acc: 0.7662\n",
      "Epoch 121/700\n",
      "8872/8872 [==============================] - 0s 27us/step - loss: 0.5699 - acc: 0.7124 - val_loss: 0.5626 - val_acc: 0.7653\n",
      "Epoch 122/700\n",
      "8872/8872 [==============================] - 0s 27us/step - loss: 0.5678 - acc: 0.7142 - val_loss: 0.5628 - val_acc: 0.7649\n",
      "Epoch 123/700\n",
      "8872/8872 [==============================] - 0s 27us/step - loss: 0.5681 - acc: 0.7131 - val_loss: 0.5612 - val_acc: 0.7670\n",
      "Epoch 124/700\n",
      "8872/8872 [==============================] - 0s 24us/step - loss: 0.5681 - acc: 0.7135 - val_loss: 0.5632 - val_acc: 0.7646\n",
      "Epoch 125/700\n",
      "8872/8872 [==============================] - 0s 24us/step - loss: 0.5678 - acc: 0.7100 - val_loss: 0.5639 - val_acc: 0.7634\n",
      "Epoch 126/700\n",
      "8872/8872 [==============================] - 0s 24us/step - loss: 0.5673 - acc: 0.7144 - val_loss: 0.5620 - val_acc: 0.7656\n",
      "Epoch 127/700\n",
      "8872/8872 [==============================] - 0s 25us/step - loss: 0.5679 - acc: 0.7112 - val_loss: 0.5631 - val_acc: 0.7636\n",
      "Epoch 128/700\n",
      "8872/8872 [==============================] - 0s 26us/step - loss: 0.5676 - acc: 0.7126 - val_loss: 0.5626 - val_acc: 0.7639\n",
      "Epoch 129/700\n",
      "8872/8872 [==============================] - 0s 23us/step - loss: 0.5675 - acc: 0.7104 - val_loss: 0.5638 - val_acc: 0.7640\n",
      "Epoch 130/700\n",
      "8872/8872 [==============================] - 0s 23us/step - loss: 0.5677 - acc: 0.7137 - val_loss: 0.5628 - val_acc: 0.7641\n",
      "Epoch 131/700\n",
      "8872/8872 [==============================] - 0s 24us/step - loss: 0.5669 - acc: 0.7102 - val_loss: 0.5627 - val_acc: 0.7643\n",
      "Epoch 132/700\n",
      "8872/8872 [==============================] - 0s 26us/step - loss: 0.5671 - acc: 0.7113 - val_loss: 0.5631 - val_acc: 0.7637\n",
      "Epoch 133/700\n",
      "8872/8872 [==============================] - 0s 25us/step - loss: 0.5671 - acc: 0.7146 - val_loss: 0.5602 - val_acc: 0.7653\n",
      "Epoch 134/700\n",
      "8872/8872 [==============================] - 0s 25us/step - loss: 0.5676 - acc: 0.7115 - val_loss: 0.5612 - val_acc: 0.7644\n",
      "Epoch 135/700\n",
      "8872/8872 [==============================] - 0s 26us/step - loss: 0.5665 - acc: 0.7161 - val_loss: 0.5592 - val_acc: 0.7665\n",
      "Epoch 136/700\n",
      "8872/8872 [==============================] - 0s 25us/step - loss: 0.5682 - acc: 0.7110 - val_loss: 0.5621 - val_acc: 0.7640\n",
      "Epoch 137/700\n",
      "8872/8872 [==============================] - 0s 29us/step - loss: 0.5672 - acc: 0.7119 - val_loss: 0.5605 - val_acc: 0.7639\n",
      "Epoch 138/700\n",
      "8872/8872 [==============================] - 0s 25us/step - loss: 0.5666 - acc: 0.7129 - val_loss: 0.5628 - val_acc: 0.7621\n",
      "Epoch 139/700\n",
      "8872/8872 [==============================] - 0s 27us/step - loss: 0.5672 - acc: 0.7116 - val_loss: 0.5619 - val_acc: 0.7627\n",
      "Epoch 140/700\n",
      "8872/8872 [==============================] - 0s 24us/step - loss: 0.5663 - acc: 0.7169 - val_loss: 0.5621 - val_acc: 0.7622\n",
      "Epoch 141/700\n",
      "8872/8872 [==============================] - 0s 27us/step - loss: 0.5667 - acc: 0.7135 - val_loss: 0.5596 - val_acc: 0.7650\n",
      "Epoch 142/700\n",
      "8872/8872 [==============================] - 0s 28us/step - loss: 0.5667 - acc: 0.7119 - val_loss: 0.5584 - val_acc: 0.7658\n",
      "Epoch 143/700\n",
      "8872/8872 [==============================] - 0s 31us/step - loss: 0.5670 - acc: 0.7111 - val_loss: 0.5611 - val_acc: 0.7634\n",
      "Epoch 144/700\n",
      "8872/8872 [==============================] - 0s 27us/step - loss: 0.5655 - acc: 0.7165 - val_loss: 0.5598 - val_acc: 0.7652\n",
      "Epoch 145/700\n",
      "8872/8872 [==============================] - 0s 26us/step - loss: 0.5655 - acc: 0.7134 - val_loss: 0.5597 - val_acc: 0.7647\n",
      "Epoch 146/700\n",
      "8872/8872 [==============================] - 0s 27us/step - loss: 0.5665 - acc: 0.7144 - val_loss: 0.5590 - val_acc: 0.7644\n",
      "Epoch 147/700\n",
      "8872/8872 [==============================] - 0s 25us/step - loss: 0.5650 - acc: 0.7152 - val_loss: 0.5595 - val_acc: 0.7647\n",
      "Epoch 148/700\n",
      "8872/8872 [==============================] - 0s 26us/step - loss: 0.5645 - acc: 0.7122 - val_loss: 0.5640 - val_acc: 0.7613\n",
      "Epoch 149/700\n",
      "8872/8872 [==============================] - 0s 26us/step - loss: 0.5632 - acc: 0.7162 - val_loss: 0.5591 - val_acc: 0.7644\n",
      "Epoch 150/700\n",
      "8872/8872 [==============================] - 0s 27us/step - loss: 0.5671 - acc: 0.7158 - val_loss: 0.5626 - val_acc: 0.7636\n",
      "Epoch 151/700\n",
      "8872/8872 [==============================] - 0s 24us/step - loss: 0.5640 - acc: 0.7153 - val_loss: 0.5586 - val_acc: 0.7650\n",
      "Epoch 152/700\n",
      "8872/8872 [==============================] - 0s 26us/step - loss: 0.5657 - acc: 0.7113 - val_loss: 0.5606 - val_acc: 0.7641\n",
      "Epoch 153/700\n",
      "8872/8872 [==============================] - 0s 26us/step - loss: 0.5649 - acc: 0.7140 - val_loss: 0.5628 - val_acc: 0.7634\n",
      "Epoch 154/700\n",
      "8872/8872 [==============================] - 0s 27us/step - loss: 0.5637 - acc: 0.7143 - val_loss: 0.5610 - val_acc: 0.7643\n",
      "Epoch 155/700\n",
      "8872/8872 [==============================] - 0s 24us/step - loss: 0.5619 - acc: 0.7164 - val_loss: 0.5603 - val_acc: 0.7650\n",
      "Epoch 156/700\n",
      "8872/8872 [==============================] - 0s 26us/step - loss: 0.5647 - acc: 0.7182 - val_loss: 0.5599 - val_acc: 0.7647\n",
      "Epoch 157/700\n",
      "8872/8872 [==============================] - 0s 24us/step - loss: 0.5645 - acc: 0.7149 - val_loss: 0.5609 - val_acc: 0.7634\n",
      "Epoch 158/700\n",
      "8872/8872 [==============================] - 0s 26us/step - loss: 0.5637 - acc: 0.7151 - val_loss: 0.5592 - val_acc: 0.7646\n",
      "Epoch 159/700\n",
      "8872/8872 [==============================] - 0s 26us/step - loss: 0.5652 - acc: 0.7149 - val_loss: 0.5594 - val_acc: 0.7650\n",
      "Epoch 160/700\n",
      "8872/8872 [==============================] - 0s 24us/step - loss: 0.5636 - acc: 0.7133 - val_loss: 0.5574 - val_acc: 0.7655\n",
      "Epoch 161/700\n",
      "8872/8872 [==============================] - 0s 24us/step - loss: 0.5630 - acc: 0.7135 - val_loss: 0.5567 - val_acc: 0.7659\n",
      "Epoch 162/700\n",
      "8872/8872 [==============================] - 0s 28us/step - loss: 0.5640 - acc: 0.7135 - val_loss: 0.5575 - val_acc: 0.7655\n",
      "Epoch 163/700\n",
      "8872/8872 [==============================] - 0s 27us/step - loss: 0.5627 - acc: 0.7163 - val_loss: 0.5575 - val_acc: 0.7658\n",
      "Epoch 164/700\n",
      "8872/8872 [==============================] - 0s 25us/step - loss: 0.5635 - acc: 0.7101 - val_loss: 0.5563 - val_acc: 0.7667\n",
      "Epoch 165/700\n",
      "8872/8872 [==============================] - 0s 24us/step - loss: 0.5639 - acc: 0.7104 - val_loss: 0.5604 - val_acc: 0.7644\n",
      "Epoch 166/700\n",
      "8872/8872 [==============================] - 0s 26us/step - loss: 0.5637 - acc: 0.7126 - val_loss: 0.5601 - val_acc: 0.7625\n",
      "Epoch 167/700\n",
      "8872/8872 [==============================] - 0s 26us/step - loss: 0.5628 - acc: 0.7156 - val_loss: 0.5636 - val_acc: 0.7597\n",
      "Epoch 168/700\n",
      "8872/8872 [==============================] - 0s 27us/step - loss: 0.5627 - acc: 0.7148 - val_loss: 0.5621 - val_acc: 0.7615\n",
      "Epoch 169/700\n",
      "8872/8872 [==============================] - 0s 24us/step - loss: 0.5620 - acc: 0.7135 - val_loss: 0.5568 - val_acc: 0.7658\n",
      "Epoch 170/700\n",
      "8872/8872 [==============================] - 0s 26us/step - loss: 0.5617 - acc: 0.7167 - val_loss: 0.5609 - val_acc: 0.7618\n",
      "Epoch 171/700\n",
      "8872/8872 [==============================] - 0s 26us/step - loss: 0.5626 - acc: 0.7153 - val_loss: 0.5582 - val_acc: 0.7653\n",
      "Epoch 172/700\n",
      "8872/8872 [==============================] - 0s 26us/step - loss: 0.5620 - acc: 0.7130 - val_loss: 0.5591 - val_acc: 0.7644\n",
      "Epoch 173/700\n",
      "8872/8872 [==============================] - 0s 26us/step - loss: 0.5627 - acc: 0.7147 - val_loss: 0.5606 - val_acc: 0.7624\n",
      "Epoch 174/700\n",
      "8872/8872 [==============================] - 0s 30us/step - loss: 0.5631 - acc: 0.7167 - val_loss: 0.5584 - val_acc: 0.7637\n",
      "Epoch 175/700\n",
      "8872/8872 [==============================] - 0s 30us/step - loss: 0.5628 - acc: 0.7155 - val_loss: 0.5587 - val_acc: 0.7637\n",
      "Epoch 176/700\n",
      "8872/8872 [==============================] - 0s 27us/step - loss: 0.5625 - acc: 0.7186 - val_loss: 0.5607 - val_acc: 0.7640\n",
      "Epoch 177/700\n",
      "8872/8872 [==============================] - 0s 26us/step - loss: 0.5618 - acc: 0.7179 - val_loss: 0.5620 - val_acc: 0.7630\n",
      "Epoch 178/700\n",
      "8872/8872 [==============================] - 0s 28us/step - loss: 0.5620 - acc: 0.7146 - val_loss: 0.5610 - val_acc: 0.7627\n",
      "Epoch 179/700\n",
      "8872/8872 [==============================] - 0s 25us/step - loss: 0.5611 - acc: 0.7151 - val_loss: 0.5610 - val_acc: 0.7622\n",
      "Epoch 180/700\n",
      "8872/8872 [==============================] - 0s 27us/step - loss: 0.5634 - acc: 0.7145 - val_loss: 0.5600 - val_acc: 0.7634\n",
      "Epoch 181/700\n",
      "8872/8872 [==============================] - 0s 28us/step - loss: 0.5624 - acc: 0.7144 - val_loss: 0.5581 - val_acc: 0.7633\n",
      "Epoch 182/700\n",
      "8872/8872 [==============================] - 0s 30us/step - loss: 0.5616 - acc: 0.7182 - val_loss: 0.5579 - val_acc: 0.7647\n",
      "Epoch 183/700\n",
      "8872/8872 [==============================] - 0s 30us/step - loss: 0.5614 - acc: 0.7162 - val_loss: 0.5574 - val_acc: 0.7653\n",
      "Epoch 184/700\n",
      "8872/8872 [==============================] - 0s 26us/step - loss: 0.5616 - acc: 0.7129 - val_loss: 0.5573 - val_acc: 0.7649\n",
      "Epoch 185/700\n",
      "8872/8872 [==============================] - 0s 26us/step - loss: 0.5615 - acc: 0.7148 - val_loss: 0.5593 - val_acc: 0.7636\n",
      "Epoch 186/700\n",
      "8872/8872 [==============================] - 0s 27us/step - loss: 0.5611 - acc: 0.7167 - val_loss: 0.5573 - val_acc: 0.7647\n",
      "Epoch 187/700\n",
      "8872/8872 [==============================] - 0s 26us/step - loss: 0.5608 - acc: 0.7217 - val_loss: 0.5601 - val_acc: 0.7636\n",
      "Epoch 188/700\n",
      "8872/8872 [==============================] - 0s 27us/step - loss: 0.5615 - acc: 0.7155 - val_loss: 0.5599 - val_acc: 0.7636\n",
      "Epoch 189/700\n",
      "8872/8872 [==============================] - 0s 28us/step - loss: 0.5612 - acc: 0.7167 - val_loss: 0.5577 - val_acc: 0.7643\n",
      "Epoch 190/700\n",
      "8872/8872 [==============================] - 0s 27us/step - loss: 0.5621 - acc: 0.7178 - val_loss: 0.5600 - val_acc: 0.7624\n",
      "Epoch 191/700\n",
      "8872/8872 [==============================] - 0s 26us/step - loss: 0.5590 - acc: 0.7147 - val_loss: 0.5604 - val_acc: 0.7622\n",
      "Epoch 192/700\n",
      "8872/8872 [==============================] - 0s 24us/step - loss: 0.5614 - acc: 0.7180 - val_loss: 0.5585 - val_acc: 0.7636\n",
      "Epoch 193/700\n",
      "8872/8872 [==============================] - 0s 27us/step - loss: 0.5618 - acc: 0.7154 - val_loss: 0.5587 - val_acc: 0.7633\n",
      "Epoch 194/700\n",
      "8872/8872 [==============================] - 0s 25us/step - loss: 0.5605 - acc: 0.7162 - val_loss: 0.5565 - val_acc: 0.7643\n",
      "Epoch 195/700\n",
      "8872/8872 [==============================] - 0s 26us/step - loss: 0.5592 - acc: 0.7166 - val_loss: 0.5580 - val_acc: 0.7631\n",
      "Epoch 196/700\n",
      "8872/8872 [==============================] - 0s 26us/step - loss: 0.5611 - acc: 0.7174 - val_loss: 0.5618 - val_acc: 0.7607\n",
      "Epoch 197/700\n",
      "8872/8872 [==============================] - 0s 26us/step - loss: 0.5585 - acc: 0.7192 - val_loss: 0.5586 - val_acc: 0.7625\n",
      "Epoch 198/700\n",
      "8872/8872 [==============================] - 0s 27us/step - loss: 0.5597 - acc: 0.7153 - val_loss: 0.5592 - val_acc: 0.7616\n",
      "Epoch 199/700\n",
      "8872/8872 [==============================] - 0s 26us/step - loss: 0.5617 - acc: 0.7148 - val_loss: 0.5568 - val_acc: 0.7641\n",
      "Epoch 200/700\n",
      "8872/8872 [==============================] - 0s 25us/step - loss: 0.5609 - acc: 0.7157 - val_loss: 0.5575 - val_acc: 0.7639\n",
      "Epoch 201/700\n",
      "8872/8872 [==============================] - 0s 24us/step - loss: 0.5604 - acc: 0.7140 - val_loss: 0.5584 - val_acc: 0.7624\n",
      "Epoch 202/700\n",
      "8872/8872 [==============================] - 0s 26us/step - loss: 0.5589 - acc: 0.7154 - val_loss: 0.5593 - val_acc: 0.7625\n",
      "Epoch 203/700\n",
      "8872/8872 [==============================] - 0s 25us/step - loss: 0.5603 - acc: 0.7164 - val_loss: 0.5583 - val_acc: 0.7624\n",
      "Epoch 204/700\n",
      "8872/8872 [==============================] - 0s 26us/step - loss: 0.5583 - acc: 0.7171 - val_loss: 0.5577 - val_acc: 0.7630\n",
      "Epoch 205/700\n",
      "8872/8872 [==============================] - 0s 24us/step - loss: 0.5588 - acc: 0.7163 - val_loss: 0.5562 - val_acc: 0.7640\n",
      "Epoch 206/700\n",
      "8872/8872 [==============================] - 0s 26us/step - loss: 0.5589 - acc: 0.7170 - val_loss: 0.5578 - val_acc: 0.7631\n",
      "Epoch 207/700\n",
      "8872/8872 [==============================] - 0s 27us/step - loss: 0.5593 - acc: 0.7174 - val_loss: 0.5599 - val_acc: 0.7599\n",
      "Epoch 208/700\n",
      "8872/8872 [==============================] - 0s 32us/step - loss: 0.5591 - acc: 0.7165 - val_loss: 0.5597 - val_acc: 0.7601\n",
      "Epoch 209/700\n",
      "8872/8872 [==============================] - 0s 28us/step - loss: 0.5602 - acc: 0.7169 - val_loss: 0.5563 - val_acc: 0.7641\n",
      "Epoch 210/700\n",
      "8872/8872 [==============================] - 0s 28us/step - loss: 0.5583 - acc: 0.7183 - val_loss: 0.5596 - val_acc: 0.7600\n",
      "Epoch 211/700\n",
      "8872/8872 [==============================] - 0s 29us/step - loss: 0.5589 - acc: 0.7165 - val_loss: 0.5590 - val_acc: 0.7616\n",
      "Epoch 212/700\n",
      "8872/8872 [==============================] - 0s 24us/step - loss: 0.5574 - acc: 0.7191 - val_loss: 0.5580 - val_acc: 0.7621\n",
      "Epoch 213/700\n",
      "8872/8872 [==============================] - 0s 25us/step - loss: 0.5591 - acc: 0.7196 - val_loss: 0.5604 - val_acc: 0.7591\n",
      "Epoch 214/700\n",
      "8872/8872 [==============================] - 0s 24us/step - loss: 0.5597 - acc: 0.7173 - val_loss: 0.5587 - val_acc: 0.7616\n",
      "Epoch 215/700\n",
      "8872/8872 [==============================] - 0s 25us/step - loss: 0.5587 - acc: 0.7160 - val_loss: 0.5599 - val_acc: 0.7600\n",
      "Epoch 216/700\n",
      "8872/8872 [==============================] - 0s 24us/step - loss: 0.5589 - acc: 0.7165 - val_loss: 0.5575 - val_acc: 0.7627\n",
      "Epoch 217/700\n",
      "8872/8872 [==============================] - 0s 28us/step - loss: 0.5563 - acc: 0.7178 - val_loss: 0.5569 - val_acc: 0.7633\n",
      "Epoch 218/700\n",
      "8872/8872 [==============================] - 0s 29us/step - loss: 0.5588 - acc: 0.7146 - val_loss: 0.5560 - val_acc: 0.7636\n",
      "Epoch 219/700\n",
      "8872/8872 [==============================] - 0s 31us/step - loss: 0.5590 - acc: 0.7184 - val_loss: 0.5572 - val_acc: 0.7627\n",
      "Epoch 220/700\n",
      "8872/8872 [==============================] - 0s 25us/step - loss: 0.5589 - acc: 0.7175 - val_loss: 0.5584 - val_acc: 0.7618\n",
      "Epoch 221/700\n",
      "8872/8872 [==============================] - 0s 25us/step - loss: 0.5564 - acc: 0.7153 - val_loss: 0.5572 - val_acc: 0.7624\n",
      "Epoch 222/700\n",
      "8872/8872 [==============================] - 0s 26us/step - loss: 0.5570 - acc: 0.7163 - val_loss: 0.5583 - val_acc: 0.7609\n",
      "Epoch 223/700\n",
      "8872/8872 [==============================] - 0s 26us/step - loss: 0.5580 - acc: 0.7163 - val_loss: 0.5593 - val_acc: 0.7596\n",
      "Epoch 224/700\n",
      "8872/8872 [==============================] - 0s 27us/step - loss: 0.5568 - acc: 0.7170 - val_loss: 0.5569 - val_acc: 0.7612\n",
      "Epoch 225/700\n",
      "8872/8872 [==============================] - 0s 30us/step - loss: 0.5574 - acc: 0.7192 - val_loss: 0.5585 - val_acc: 0.7601\n",
      "Epoch 226/700\n",
      "8872/8872 [==============================] - 0s 28us/step - loss: 0.5574 - acc: 0.7215 - val_loss: 0.5568 - val_acc: 0.7619\n",
      "Epoch 227/700\n",
      "8872/8872 [==============================] - 0s 24us/step - loss: 0.5575 - acc: 0.7177 - val_loss: 0.5598 - val_acc: 0.7588\n",
      "Epoch 228/700\n",
      "8872/8872 [==============================] - 0s 27us/step - loss: 0.5580 - acc: 0.7167 - val_loss: 0.5569 - val_acc: 0.7615\n",
      "Epoch 229/700\n",
      "8872/8872 [==============================] - 0s 26us/step - loss: 0.5577 - acc: 0.7190 - val_loss: 0.5566 - val_acc: 0.7618\n",
      "Epoch 230/700\n",
      "8872/8872 [==============================] - 0s 25us/step - loss: 0.5565 - acc: 0.7197 - val_loss: 0.5575 - val_acc: 0.7607\n",
      "Epoch 231/700\n",
      "8872/8872 [==============================] - 0s 25us/step - loss: 0.5585 - acc: 0.7183 - val_loss: 0.5610 - val_acc: 0.7578\n",
      "Epoch 232/700\n",
      "8872/8872 [==============================] - 0s 25us/step - loss: 0.5545 - acc: 0.7218 - val_loss: 0.5600 - val_acc: 0.7596\n",
      "Epoch 233/700\n",
      "8872/8872 [==============================] - 0s 27us/step - loss: 0.5554 - acc: 0.7196 - val_loss: 0.5567 - val_acc: 0.7613\n",
      "Epoch 234/700\n",
      "8872/8872 [==============================] - 0s 26us/step - loss: 0.5567 - acc: 0.7179 - val_loss: 0.5595 - val_acc: 0.7587\n",
      "Epoch 235/700\n",
      "8872/8872 [==============================] - 0s 26us/step - loss: 0.5577 - acc: 0.7163 - val_loss: 0.5579 - val_acc: 0.7610\n",
      "Epoch 236/700\n",
      "8872/8872 [==============================] - 0s 24us/step - loss: 0.5555 - acc: 0.7209 - val_loss: 0.5561 - val_acc: 0.7622\n",
      "Epoch 237/700\n",
      "8872/8872 [==============================] - 0s 27us/step - loss: 0.5570 - acc: 0.7156 - val_loss: 0.5566 - val_acc: 0.7612\n",
      "Epoch 238/700\n",
      "8872/8872 [==============================] - 0s 26us/step - loss: 0.5580 - acc: 0.7158 - val_loss: 0.5541 - val_acc: 0.7634\n",
      "Epoch 239/700\n",
      "8872/8872 [==============================] - 0s 23us/step - loss: 0.5578 - acc: 0.7160 - val_loss: 0.5579 - val_acc: 0.7612\n",
      "Epoch 240/700\n",
      "8872/8872 [==============================] - 0s 24us/step - loss: 0.5570 - acc: 0.7190 - val_loss: 0.5542 - val_acc: 0.7628\n",
      "Epoch 241/700\n",
      "8872/8872 [==============================] - 0s 24us/step - loss: 0.5581 - acc: 0.7205 - val_loss: 0.5573 - val_acc: 0.7613\n",
      "Epoch 242/700\n",
      "8872/8872 [==============================] - 0s 25us/step - loss: 0.5568 - acc: 0.7174 - val_loss: 0.5595 - val_acc: 0.7591\n",
      "Epoch 243/700\n",
      "8872/8872 [==============================] - 0s 27us/step - loss: 0.5556 - acc: 0.7218 - val_loss: 0.5563 - val_acc: 0.7621\n",
      "Epoch 244/700\n",
      "8872/8872 [==============================] - 0s 25us/step - loss: 0.5549 - acc: 0.7198 - val_loss: 0.5557 - val_acc: 0.7610\n",
      "Epoch 245/700\n",
      "8872/8872 [==============================] - 0s 25us/step - loss: 0.5562 - acc: 0.7196 - val_loss: 0.5560 - val_acc: 0.7610\n",
      "Epoch 246/700\n",
      "8872/8872 [==============================] - 0s 29us/step - loss: 0.5570 - acc: 0.7180 - val_loss: 0.5580 - val_acc: 0.7604\n",
      "Epoch 247/700\n",
      "8872/8872 [==============================] - 0s 31us/step - loss: 0.5552 - acc: 0.7192 - val_loss: 0.5580 - val_acc: 0.7600\n",
      "Epoch 248/700\n",
      "8872/8872 [==============================] - 0s 29us/step - loss: 0.5550 - acc: 0.7181 - val_loss: 0.5618 - val_acc: 0.7566\n",
      "Epoch 249/700\n",
      "8872/8872 [==============================] - 0s 29us/step - loss: 0.5555 - acc: 0.7220 - val_loss: 0.5579 - val_acc: 0.7596\n",
      "Epoch 250/700\n",
      "8872/8872 [==============================] - 0s 26us/step - loss: 0.5559 - acc: 0.7207 - val_loss: 0.5599 - val_acc: 0.7576\n",
      "Epoch 251/700\n",
      "8872/8872 [==============================] - 0s 24us/step - loss: 0.5543 - acc: 0.7181 - val_loss: 0.5552 - val_acc: 0.7610\n",
      "Epoch 252/700\n",
      "8872/8872 [==============================] - 0s 24us/step - loss: 0.5544 - acc: 0.7174 - val_loss: 0.5579 - val_acc: 0.7597\n",
      "Epoch 253/700\n",
      "8872/8872 [==============================] - 0s 25us/step - loss: 0.5549 - acc: 0.7211 - val_loss: 0.5588 - val_acc: 0.7593\n",
      "Epoch 254/700\n",
      "8872/8872 [==============================] - 0s 23us/step - loss: 0.5548 - acc: 0.7167 - val_loss: 0.5606 - val_acc: 0.7560\n",
      "Epoch 255/700\n",
      "8872/8872 [==============================] - 0s 26us/step - loss: 0.5566 - acc: 0.7181 - val_loss: 0.5550 - val_acc: 0.7616\n",
      "Epoch 256/700\n",
      "8872/8872 [==============================] - 0s 23us/step - loss: 0.5543 - acc: 0.7202 - val_loss: 0.5582 - val_acc: 0.7601\n",
      "Epoch 257/700\n",
      "8872/8872 [==============================] - 0s 24us/step - loss: 0.5567 - acc: 0.7171 - val_loss: 0.5536 - val_acc: 0.7624\n",
      "Epoch 258/700\n",
      "8872/8872 [==============================] - 0s 24us/step - loss: 0.5566 - acc: 0.7175 - val_loss: 0.5580 - val_acc: 0.7601\n",
      "Epoch 259/700\n",
      "8872/8872 [==============================] - 0s 24us/step - loss: 0.5544 - acc: 0.7201 - val_loss: 0.5600 - val_acc: 0.7573\n",
      "Epoch 260/700\n",
      "8872/8872 [==============================] - 0s 23us/step - loss: 0.5546 - acc: 0.7200 - val_loss: 0.5600 - val_acc: 0.7584\n",
      "Epoch 261/700\n",
      "8872/8872 [==============================] - 0s 23us/step - loss: 0.5562 - acc: 0.7196 - val_loss: 0.5566 - val_acc: 0.7604\n",
      "Epoch 262/700\n",
      "8872/8872 [==============================] - 0s 22us/step - loss: 0.5541 - acc: 0.7199 - val_loss: 0.5569 - val_acc: 0.7601\n",
      "Epoch 263/700\n",
      "8872/8872 [==============================] - 0s 26us/step - loss: 0.5546 - acc: 0.7200 - val_loss: 0.5590 - val_acc: 0.7597\n",
      "Epoch 264/700\n",
      "8872/8872 [==============================] - 0s 26us/step - loss: 0.5540 - acc: 0.7191 - val_loss: 0.5579 - val_acc: 0.7597\n",
      "Epoch 265/700\n",
      "8872/8872 [==============================] - 0s 25us/step - loss: 0.5538 - acc: 0.7202 - val_loss: 0.5570 - val_acc: 0.7600\n",
      "Epoch 266/700\n",
      "8872/8872 [==============================] - 0s 24us/step - loss: 0.5534 - acc: 0.7186 - val_loss: 0.5584 - val_acc: 0.7596\n",
      "Epoch 267/700\n",
      "8872/8872 [==============================] - 0s 24us/step - loss: 0.5543 - acc: 0.7215 - val_loss: 0.5538 - val_acc: 0.7618\n",
      "Epoch 268/700\n",
      "8872/8872 [==============================] - 0s 26us/step - loss: 0.5542 - acc: 0.7161 - val_loss: 0.5538 - val_acc: 0.7612\n",
      "Epoch 269/700\n",
      "8872/8872 [==============================] - 0s 27us/step - loss: 0.5548 - acc: 0.7210 - val_loss: 0.5556 - val_acc: 0.7606\n",
      "Epoch 270/700\n",
      "8872/8872 [==============================] - 0s 26us/step - loss: 0.5540 - acc: 0.7208 - val_loss: 0.5622 - val_acc: 0.7563\n",
      "Epoch 271/700\n",
      "8872/8872 [==============================] - 0s 25us/step - loss: 0.5542 - acc: 0.7177 - val_loss: 0.5599 - val_acc: 0.7582\n",
      "Epoch 272/700\n",
      "8872/8872 [==============================] - 0s 24us/step - loss: 0.5539 - acc: 0.7224 - val_loss: 0.5594 - val_acc: 0.7588\n",
      "Epoch 273/700\n",
      "8872/8872 [==============================] - 0s 27us/step - loss: 0.5530 - acc: 0.7204 - val_loss: 0.5573 - val_acc: 0.7594\n",
      "Epoch 274/700\n",
      "8872/8872 [==============================] - 0s 24us/step - loss: 0.5532 - acc: 0.7206 - val_loss: 0.5544 - val_acc: 0.7610\n",
      "Epoch 275/700\n",
      "8872/8872 [==============================] - 0s 26us/step - loss: 0.5551 - acc: 0.7210 - val_loss: 0.5557 - val_acc: 0.7600\n",
      "Epoch 276/700\n",
      "8872/8872 [==============================] - 0s 24us/step - loss: 0.5526 - acc: 0.7249 - val_loss: 0.5540 - val_acc: 0.7606\n",
      "Epoch 277/700\n",
      "8872/8872 [==============================] - 0s 26us/step - loss: 0.5518 - acc: 0.7209 - val_loss: 0.5524 - val_acc: 0.7616\n",
      "Epoch 278/700\n",
      "8872/8872 [==============================] - 0s 26us/step - loss: 0.5530 - acc: 0.7223 - val_loss: 0.5556 - val_acc: 0.7600\n",
      "Epoch 279/700\n",
      "8872/8872 [==============================] - 0s 25us/step - loss: 0.5538 - acc: 0.7210 - val_loss: 0.5559 - val_acc: 0.7596\n",
      "Epoch 280/700\n",
      "8872/8872 [==============================] - 0s 24us/step - loss: 0.5510 - acc: 0.7213 - val_loss: 0.5528 - val_acc: 0.7616\n",
      "Epoch 281/700\n",
      "8872/8872 [==============================] - 0s 26us/step - loss: 0.5523 - acc: 0.7190 - val_loss: 0.5574 - val_acc: 0.7588\n",
      "Epoch 282/700\n",
      "8872/8872 [==============================] - 0s 26us/step - loss: 0.5528 - acc: 0.7195 - val_loss: 0.5551 - val_acc: 0.7601\n",
      "Epoch 283/700\n",
      "8872/8872 [==============================] - 0s 24us/step - loss: 0.5500 - acc: 0.7208 - val_loss: 0.5576 - val_acc: 0.7591\n",
      "Epoch 284/700\n",
      "8872/8872 [==============================] - 0s 24us/step - loss: 0.5534 - acc: 0.7223 - val_loss: 0.5598 - val_acc: 0.7561\n",
      "Epoch 285/700\n",
      "8872/8872 [==============================] - 0s 25us/step - loss: 0.5512 - acc: 0.7237 - val_loss: 0.5614 - val_acc: 0.7527\n",
      "Epoch 286/700\n",
      "8872/8872 [==============================] - 0s 26us/step - loss: 0.5536 - acc: 0.7192 - val_loss: 0.5617 - val_acc: 0.7539\n",
      "Epoch 287/700\n",
      "8872/8872 [==============================] - 0s 26us/step - loss: 0.5533 - acc: 0.7207 - val_loss: 0.5545 - val_acc: 0.7597\n",
      "Epoch 288/700\n",
      "8872/8872 [==============================] - 0s 26us/step - loss: 0.5522 - acc: 0.7202 - val_loss: 0.5584 - val_acc: 0.7567\n",
      "Epoch 289/700\n",
      "8872/8872 [==============================] - 0s 27us/step - loss: 0.5513 - acc: 0.7200 - val_loss: 0.5554 - val_acc: 0.7599\n",
      "Epoch 290/700\n",
      "8872/8872 [==============================] - 0s 31us/step - loss: 0.5520 - acc: 0.7207 - val_loss: 0.5531 - val_acc: 0.7607\n",
      "Epoch 291/700\n",
      "8872/8872 [==============================] - 0s 30us/step - loss: 0.5530 - acc: 0.7186 - val_loss: 0.5567 - val_acc: 0.7596\n",
      "Epoch 292/700\n",
      "8872/8872 [==============================] - 0s 28us/step - loss: 0.5530 - acc: 0.7198 - val_loss: 0.5592 - val_acc: 0.7559\n",
      "Epoch 293/700\n",
      "8872/8872 [==============================] - 0s 28us/step - loss: 0.5531 - acc: 0.7214 - val_loss: 0.5528 - val_acc: 0.7612\n",
      "Epoch 294/700\n",
      "8872/8872 [==============================] - 0s 24us/step - loss: 0.5522 - acc: 0.7229 - val_loss: 0.5594 - val_acc: 0.7567\n",
      "Epoch 295/700\n",
      "8872/8872 [==============================] - 0s 27us/step - loss: 0.5506 - acc: 0.7204 - val_loss: 0.5627 - val_acc: 0.7524\n",
      "Epoch 296/700\n",
      "8872/8872 [==============================] - 0s 26us/step - loss: 0.5523 - acc: 0.7207 - val_loss: 0.5581 - val_acc: 0.7578\n",
      "Epoch 297/700\n",
      "8872/8872 [==============================] - 0s 25us/step - loss: 0.5520 - acc: 0.7226 - val_loss: 0.5613 - val_acc: 0.7560\n",
      "Epoch 298/700\n",
      "8872/8872 [==============================] - 0s 24us/step - loss: 0.5508 - acc: 0.7235 - val_loss: 0.5568 - val_acc: 0.7593\n",
      "Epoch 299/700\n",
      "8872/8872 [==============================] - 0s 23us/step - loss: 0.5517 - acc: 0.7206 - val_loss: 0.5561 - val_acc: 0.7599\n",
      "Epoch 300/700\n",
      "8872/8872 [==============================] - 0s 27us/step - loss: 0.5505 - acc: 0.7240 - val_loss: 0.5591 - val_acc: 0.7541\n",
      "Epoch 301/700\n",
      "8872/8872 [==============================] - 0s 25us/step - loss: 0.5514 - acc: 0.7222 - val_loss: 0.5518 - val_acc: 0.7609\n",
      "Epoch 302/700\n",
      "8872/8872 [==============================] - 0s 26us/step - loss: 0.5516 - acc: 0.7211 - val_loss: 0.5554 - val_acc: 0.7593\n",
      "Epoch 303/700\n",
      "8872/8872 [==============================] - 0s 26us/step - loss: 0.5517 - acc: 0.7186 - val_loss: 0.5552 - val_acc: 0.7597\n",
      "Epoch 304/700\n",
      "8872/8872 [==============================] - 0s 26us/step - loss: 0.5511 - acc: 0.7216 - val_loss: 0.5595 - val_acc: 0.7570\n",
      "Epoch 305/700\n",
      "8872/8872 [==============================] - 0s 27us/step - loss: 0.5514 - acc: 0.7204 - val_loss: 0.5567 - val_acc: 0.7579\n",
      "Epoch 306/700\n",
      "8872/8872 [==============================] - 0s 25us/step - loss: 0.5487 - acc: 0.7228 - val_loss: 0.5567 - val_acc: 0.7578\n",
      "Epoch 307/700\n",
      "8872/8872 [==============================] - 0s 25us/step - loss: 0.5523 - acc: 0.7202 - val_loss: 0.5559 - val_acc: 0.7585\n",
      "Epoch 308/700\n",
      "8872/8872 [==============================] - 0s 27us/step - loss: 0.5498 - acc: 0.7228 - val_loss: 0.5585 - val_acc: 0.7567\n",
      "Epoch 309/700\n",
      "8872/8872 [==============================] - 0s 28us/step - loss: 0.5500 - acc: 0.7207 - val_loss: 0.5540 - val_acc: 0.7603\n",
      "Epoch 310/700\n",
      "8872/8872 [==============================] - 0s 26us/step - loss: 0.5504 - acc: 0.7260 - val_loss: 0.5557 - val_acc: 0.7581\n",
      "Epoch 311/700\n",
      "8872/8872 [==============================] - 0s 23us/step - loss: 0.5499 - acc: 0.7243 - val_loss: 0.5569 - val_acc: 0.7570\n",
      "Epoch 312/700\n",
      "8872/8872 [==============================] - 0s 23us/step - loss: 0.5492 - acc: 0.7258 - val_loss: 0.5589 - val_acc: 0.7541\n",
      "Epoch 313/700\n",
      "8872/8872 [==============================] - 0s 26us/step - loss: 0.5507 - acc: 0.7229 - val_loss: 0.5560 - val_acc: 0.7579\n",
      "Epoch 314/700\n",
      "8872/8872 [==============================] - 0s 24us/step - loss: 0.5498 - acc: 0.7226 - val_loss: 0.5606 - val_acc: 0.7551\n",
      "Epoch 315/700\n",
      "8872/8872 [==============================] - 0s 25us/step - loss: 0.5522 - acc: 0.7208 - val_loss: 0.5551 - val_acc: 0.7582\n",
      "Epoch 316/700\n",
      "8872/8872 [==============================] - 0s 27us/step - loss: 0.5508 - acc: 0.7224 - val_loss: 0.5548 - val_acc: 0.7579\n",
      "Epoch 317/700\n",
      "8872/8872 [==============================] - 0s 25us/step - loss: 0.5500 - acc: 0.7213 - val_loss: 0.5565 - val_acc: 0.7570\n",
      "Epoch 318/700\n",
      "8872/8872 [==============================] - 0s 25us/step - loss: 0.5502 - acc: 0.7202 - val_loss: 0.5540 - val_acc: 0.7600\n",
      "Epoch 319/700\n",
      "8872/8872 [==============================] - 0s 26us/step - loss: 0.5490 - acc: 0.7219 - val_loss: 0.5613 - val_acc: 0.7526\n",
      "Epoch 320/700\n",
      "8872/8872 [==============================] - 0s 26us/step - loss: 0.5489 - acc: 0.7252 - val_loss: 0.5562 - val_acc: 0.7588\n",
      "Epoch 321/700\n",
      "8872/8872 [==============================] - 0s 27us/step - loss: 0.5490 - acc: 0.7226 - val_loss: 0.5571 - val_acc: 0.7567\n",
      "Epoch 322/700\n",
      "8872/8872 [==============================] - 0s 26us/step - loss: 0.5506 - acc: 0.7223 - val_loss: 0.5580 - val_acc: 0.7556\n",
      "Epoch 323/700\n",
      "8872/8872 [==============================] - 0s 27us/step - loss: 0.5487 - acc: 0.7224 - val_loss: 0.5582 - val_acc: 0.7550\n",
      "Epoch 324/700\n",
      "8872/8872 [==============================] - 0s 30us/step - loss: 0.5475 - acc: 0.7243 - val_loss: 0.5595 - val_acc: 0.7548\n",
      "Epoch 325/700\n",
      "8872/8872 [==============================] - 0s 26us/step - loss: 0.5504 - acc: 0.7200 - val_loss: 0.5557 - val_acc: 0.7584\n",
      "Epoch 326/700\n",
      "8872/8872 [==============================] - 0s 28us/step - loss: 0.5496 - acc: 0.7240 - val_loss: 0.5534 - val_acc: 0.7599\n",
      "Epoch 327/700\n",
      "8872/8872 [==============================] - 0s 26us/step - loss: 0.5507 - acc: 0.7207 - val_loss: 0.5569 - val_acc: 0.7563\n",
      "Epoch 328/700\n",
      "8872/8872 [==============================] - 0s 26us/step - loss: 0.5500 - acc: 0.7198 - val_loss: 0.5583 - val_acc: 0.7550\n",
      "Epoch 329/700\n",
      "8872/8872 [==============================] - 0s 25us/step - loss: 0.5495 - acc: 0.7241 - val_loss: 0.5602 - val_acc: 0.7541\n",
      "Epoch 330/700\n",
      "8872/8872 [==============================] - 0s 22us/step - loss: 0.5504 - acc: 0.7228 - val_loss: 0.5601 - val_acc: 0.7544\n",
      "Epoch 331/700\n",
      "8872/8872 [==============================] - 0s 27us/step - loss: 0.5494 - acc: 0.7219 - val_loss: 0.5586 - val_acc: 0.7550\n",
      "Epoch 332/700\n",
      "8872/8872 [==============================] - 0s 23us/step - loss: 0.5488 - acc: 0.7227 - val_loss: 0.5569 - val_acc: 0.7554\n",
      "Epoch 333/700\n",
      "8872/8872 [==============================] - 0s 24us/step - loss: 0.5521 - acc: 0.7222 - val_loss: 0.5587 - val_acc: 0.7545\n",
      "Epoch 334/700\n",
      "8872/8872 [==============================] - 0s 24us/step - loss: 0.5479 - acc: 0.7204 - val_loss: 0.5563 - val_acc: 0.7581\n",
      "Epoch 335/700\n",
      "8872/8872 [==============================] - 0s 24us/step - loss: 0.5486 - acc: 0.7239 - val_loss: 0.5604 - val_acc: 0.7538\n",
      "Epoch 336/700\n",
      "8872/8872 [==============================] - 0s 27us/step - loss: 0.5491 - acc: 0.7244 - val_loss: 0.5528 - val_acc: 0.7587\n",
      "Epoch 337/700\n",
      "8872/8872 [==============================] - 0s 28us/step - loss: 0.5477 - acc: 0.7235 - val_loss: 0.5548 - val_acc: 0.7588\n",
      "Epoch 338/700\n",
      "8872/8872 [==============================] - 0s 25us/step - loss: 0.5478 - acc: 0.7260 - val_loss: 0.5554 - val_acc: 0.7581\n",
      "Epoch 339/700\n",
      "8872/8872 [==============================] - 0s 26us/step - loss: 0.5482 - acc: 0.7196 - val_loss: 0.5568 - val_acc: 0.7581\n",
      "Epoch 340/700\n",
      "8872/8872 [==============================] - 0s 28us/step - loss: 0.5489 - acc: 0.7236 - val_loss: 0.5529 - val_acc: 0.7603\n",
      "Epoch 341/700\n",
      "8872/8872 [==============================] - 0s 25us/step - loss: 0.5486 - acc: 0.7227 - val_loss: 0.5559 - val_acc: 0.7582\n",
      "Epoch 342/700\n",
      "8872/8872 [==============================] - 0s 23us/step - loss: 0.5502 - acc: 0.7217 - val_loss: 0.5544 - val_acc: 0.7576\n",
      "Epoch 343/700\n",
      "8872/8872 [==============================] - 0s 23us/step - loss: 0.5472 - acc: 0.7251 - val_loss: 0.5558 - val_acc: 0.7575\n",
      "Epoch 344/700\n",
      "8872/8872 [==============================] - 0s 24us/step - loss: 0.5483 - acc: 0.7240 - val_loss: 0.5577 - val_acc: 0.7553\n",
      "Epoch 345/700\n",
      "8872/8872 [==============================] - 0s 26us/step - loss: 0.5485 - acc: 0.7219 - val_loss: 0.5607 - val_acc: 0.7541\n",
      "Epoch 346/700\n",
      "8872/8872 [==============================] - 0s 25us/step - loss: 0.5490 - acc: 0.7222 - val_loss: 0.5584 - val_acc: 0.7569\n",
      "Epoch 347/700\n",
      "8872/8872 [==============================] - 0s 23us/step - loss: 0.5478 - acc: 0.7224 - val_loss: 0.5553 - val_acc: 0.7584\n",
      "Epoch 348/700\n",
      "8872/8872 [==============================] - 0s 25us/step - loss: 0.5480 - acc: 0.7208 - val_loss: 0.5535 - val_acc: 0.7588\n",
      "Epoch 349/700\n",
      "8872/8872 [==============================] - 0s 26us/step - loss: 0.5474 - acc: 0.7237 - val_loss: 0.5535 - val_acc: 0.7585\n",
      "Epoch 350/700\n",
      "8872/8872 [==============================] - 0s 28us/step - loss: 0.5476 - acc: 0.7259 - val_loss: 0.5554 - val_acc: 0.7581\n",
      "Epoch 351/700\n",
      "8872/8872 [==============================] - 0s 26us/step - loss: 0.5473 - acc: 0.7220 - val_loss: 0.5570 - val_acc: 0.7556\n",
      "Epoch 352/700\n",
      "8872/8872 [==============================] - 0s 25us/step - loss: 0.5470 - acc: 0.7227 - val_loss: 0.5548 - val_acc: 0.7570\n",
      "Epoch 353/700\n",
      "8872/8872 [==============================] - 0s 25us/step - loss: 0.5491 - acc: 0.7232 - val_loss: 0.5576 - val_acc: 0.7560\n",
      "Epoch 354/700\n",
      "8872/8872 [==============================] - 0s 25us/step - loss: 0.5487 - acc: 0.7249 - val_loss: 0.5528 - val_acc: 0.7596\n",
      "Epoch 355/700\n",
      "8872/8872 [==============================] - 0s 25us/step - loss: 0.5479 - acc: 0.7231 - val_loss: 0.5562 - val_acc: 0.7563\n",
      "Epoch 356/700\n",
      "8872/8872 [==============================] - 0s 24us/step - loss: 0.5488 - acc: 0.7260 - val_loss: 0.5561 - val_acc: 0.7570\n",
      "Epoch 357/700\n",
      "8872/8872 [==============================] - 0s 25us/step - loss: 0.5458 - acc: 0.7254 - val_loss: 0.5553 - val_acc: 0.7569\n",
      "Epoch 358/700\n",
      "8872/8872 [==============================] - 0s 24us/step - loss: 0.5468 - acc: 0.7250 - val_loss: 0.5564 - val_acc: 0.7561\n",
      "Epoch 359/700\n",
      "8872/8872 [==============================] - 0s 25us/step - loss: 0.5474 - acc: 0.7241 - val_loss: 0.5567 - val_acc: 0.7556\n",
      "Epoch 360/700\n",
      "8872/8872 [==============================] - 0s 26us/step - loss: 0.5472 - acc: 0.7248 - val_loss: 0.5613 - val_acc: 0.7521\n",
      "Epoch 361/700\n",
      "8872/8872 [==============================] - 0s 25us/step - loss: 0.5489 - acc: 0.7244 - val_loss: 0.5568 - val_acc: 0.7569\n",
      "Epoch 362/700\n",
      "8872/8872 [==============================] - 0s 25us/step - loss: 0.5471 - acc: 0.7237 - val_loss: 0.5580 - val_acc: 0.7545\n",
      "Epoch 363/700\n",
      "8872/8872 [==============================] - 0s 26us/step - loss: 0.5481 - acc: 0.7217 - val_loss: 0.5573 - val_acc: 0.7544\n",
      "Epoch 364/700\n",
      "8872/8872 [==============================] - 0s 26us/step - loss: 0.5467 - acc: 0.7259 - val_loss: 0.5626 - val_acc: 0.7514\n",
      "Epoch 365/700\n",
      "8872/8872 [==============================] - 0s 24us/step - loss: 0.5474 - acc: 0.7270 - val_loss: 0.5569 - val_acc: 0.7556\n",
      "Epoch 366/700\n",
      "8872/8872 [==============================] - 0s 26us/step - loss: 0.5452 - acc: 0.7236 - val_loss: 0.5600 - val_acc: 0.7520\n",
      "Epoch 367/700\n",
      "8872/8872 [==============================] - 0s 28us/step - loss: 0.5467 - acc: 0.7232 - val_loss: 0.5575 - val_acc: 0.7553\n",
      "Epoch 368/700\n",
      "8872/8872 [==============================] - 0s 29us/step - loss: 0.5468 - acc: 0.7234 - val_loss: 0.5553 - val_acc: 0.7548\n",
      "Epoch 369/700\n",
      "8872/8872 [==============================] - 0s 24us/step - loss: 0.5445 - acc: 0.7264 - val_loss: 0.5639 - val_acc: 0.7486\n",
      "Epoch 370/700\n",
      "8872/8872 [==============================] - 0s 26us/step - loss: 0.5452 - acc: 0.7227 - val_loss: 0.5594 - val_acc: 0.7533\n",
      "Epoch 371/700\n",
      "8872/8872 [==============================] - 0s 25us/step - loss: 0.5466 - acc: 0.7228 - val_loss: 0.5564 - val_acc: 0.7556\n",
      "Epoch 372/700\n",
      "8872/8872 [==============================] - 0s 26us/step - loss: 0.5464 - acc: 0.7248 - val_loss: 0.5579 - val_acc: 0.7550\n",
      "Epoch 373/700\n",
      "8872/8872 [==============================] - 0s 25us/step - loss: 0.5463 - acc: 0.7211 - val_loss: 0.5580 - val_acc: 0.7539\n",
      "Epoch 374/700\n",
      "8872/8872 [==============================] - 0s 23us/step - loss: 0.5441 - acc: 0.7233 - val_loss: 0.5557 - val_acc: 0.7561\n",
      "Epoch 375/700\n",
      "8872/8872 [==============================] - 0s 27us/step - loss: 0.5452 - acc: 0.7261 - val_loss: 0.5629 - val_acc: 0.7490\n",
      "Epoch 376/700\n",
      "8872/8872 [==============================] - 0s 26us/step - loss: 0.5460 - acc: 0.7306 - val_loss: 0.5594 - val_acc: 0.7524\n",
      "Epoch 377/700\n",
      "8872/8872 [==============================] - 0s 28us/step - loss: 0.5451 - acc: 0.7261 - val_loss: 0.5619 - val_acc: 0.7517\n",
      "Epoch 378/700\n",
      "8872/8872 [==============================] - 0s 30us/step - loss: 0.5458 - acc: 0.7242 - val_loss: 0.5595 - val_acc: 0.7532\n",
      "Epoch 379/700\n",
      "8872/8872 [==============================] - 0s 26us/step - loss: 0.5442 - acc: 0.7227 - val_loss: 0.5526 - val_acc: 0.7590\n",
      "Epoch 380/700\n",
      "8872/8872 [==============================] - 0s 25us/step - loss: 0.5461 - acc: 0.7258 - val_loss: 0.5557 - val_acc: 0.7542\n",
      "Epoch 381/700\n",
      "8872/8872 [==============================] - 0s 27us/step - loss: 0.5466 - acc: 0.7243 - val_loss: 0.5596 - val_acc: 0.7520\n",
      "Epoch 382/700\n",
      "8872/8872 [==============================] - 0s 25us/step - loss: 0.5446 - acc: 0.7246 - val_loss: 0.5555 - val_acc: 0.7560\n",
      "Epoch 383/700\n",
      "8872/8872 [==============================] - 0s 26us/step - loss: 0.5468 - acc: 0.7248 - val_loss: 0.5620 - val_acc: 0.7505\n",
      "Epoch 384/700\n",
      "8872/8872 [==============================] - 0s 27us/step - loss: 0.5438 - acc: 0.7261 - val_loss: 0.5574 - val_acc: 0.7536\n",
      "Epoch 385/700\n",
      "8872/8872 [==============================] - 0s 27us/step - loss: 0.5464 - acc: 0.7232 - val_loss: 0.5577 - val_acc: 0.7550\n",
      "Epoch 386/700\n",
      "8872/8872 [==============================] - 0s 26us/step - loss: 0.5441 - acc: 0.7298 - val_loss: 0.5591 - val_acc: 0.7541\n",
      "Epoch 387/700\n",
      "8872/8872 [==============================] - 0s 27us/step - loss: 0.5466 - acc: 0.7236 - val_loss: 0.5553 - val_acc: 0.7569\n",
      "Epoch 388/700\n",
      "8872/8872 [==============================] - 0s 26us/step - loss: 0.5463 - acc: 0.7262 - val_loss: 0.5552 - val_acc: 0.7582\n",
      "Epoch 389/700\n",
      "8872/8872 [==============================] - 0s 26us/step - loss: 0.5453 - acc: 0.7237 - val_loss: 0.5571 - val_acc: 0.7545\n",
      "Epoch 390/700\n",
      "8872/8872 [==============================] - 0s 24us/step - loss: 0.5452 - acc: 0.7236 - val_loss: 0.5561 - val_acc: 0.7553\n",
      "Epoch 391/700\n",
      "8872/8872 [==============================] - 0s 25us/step - loss: 0.5446 - acc: 0.7244 - val_loss: 0.5591 - val_acc: 0.7529\n",
      "Epoch 392/700\n",
      "8872/8872 [==============================] - 0s 24us/step - loss: 0.5467 - acc: 0.7236 - val_loss: 0.5613 - val_acc: 0.7511\n",
      "Epoch 393/700\n",
      "8872/8872 [==============================] - 0s 26us/step - loss: 0.5458 - acc: 0.7250 - val_loss: 0.5547 - val_acc: 0.7563\n",
      "Epoch 394/700\n",
      "8872/8872 [==============================] - 0s 26us/step - loss: 0.5462 - acc: 0.7243 - val_loss: 0.5585 - val_acc: 0.7529\n",
      "Epoch 395/700\n",
      "8872/8872 [==============================] - 0s 25us/step - loss: 0.5435 - acc: 0.7277 - val_loss: 0.5557 - val_acc: 0.7547\n",
      "Epoch 396/700\n",
      "8872/8872 [==============================] - 0s 25us/step - loss: 0.5456 - acc: 0.7220 - val_loss: 0.5561 - val_acc: 0.7550\n",
      "Epoch 397/700\n",
      "8872/8872 [==============================] - 0s 25us/step - loss: 0.5448 - acc: 0.7245 - val_loss: 0.5607 - val_acc: 0.7511\n",
      "Epoch 398/700\n",
      "8872/8872 [==============================] - 0s 26us/step - loss: 0.5439 - acc: 0.7242 - val_loss: 0.5561 - val_acc: 0.7539\n",
      "Epoch 399/700\n",
      "8872/8872 [==============================] - 0s 28us/step - loss: 0.5448 - acc: 0.7261 - val_loss: 0.5540 - val_acc: 0.7582\n",
      "Epoch 400/700\n",
      "8872/8872 [==============================] - 0s 28us/step - loss: 0.5438 - acc: 0.7251 - val_loss: 0.5553 - val_acc: 0.7570\n",
      "Epoch 401/700\n",
      "8872/8872 [==============================] - 0s 24us/step - loss: 0.5437 - acc: 0.7252 - val_loss: 0.5565 - val_acc: 0.7548\n",
      "Epoch 402/700\n",
      "8872/8872 [==============================] - 0s 27us/step - loss: 0.5429 - acc: 0.7254 - val_loss: 0.5548 - val_acc: 0.7569\n",
      "Epoch 403/700\n",
      "8872/8872 [==============================] - 0s 26us/step - loss: 0.5442 - acc: 0.7239 - val_loss: 0.5534 - val_acc: 0.7579\n",
      "Epoch 404/700\n",
      "8872/8872 [==============================] - 0s 25us/step - loss: 0.5423 - acc: 0.7275 - val_loss: 0.5570 - val_acc: 0.7533\n",
      "Epoch 405/700\n",
      "8872/8872 [==============================] - 0s 23us/step - loss: 0.5441 - acc: 0.7254 - val_loss: 0.5579 - val_acc: 0.7541\n",
      "Epoch 406/700\n",
      "8872/8872 [==============================] - 0s 24us/step - loss: 0.5426 - acc: 0.7255 - val_loss: 0.5561 - val_acc: 0.7556\n",
      "Epoch 407/700\n",
      "8872/8872 [==============================] - 0s 26us/step - loss: 0.5427 - acc: 0.7246 - val_loss: 0.5609 - val_acc: 0.7504\n",
      "Epoch 408/700\n",
      "8872/8872 [==============================] - 0s 24us/step - loss: 0.5449 - acc: 0.7263 - val_loss: 0.5568 - val_acc: 0.7559\n",
      "Epoch 409/700\n",
      "8872/8872 [==============================] - 0s 24us/step - loss: 0.5437 - acc: 0.7266 - val_loss: 0.5599 - val_acc: 0.7511\n",
      "Epoch 410/700\n",
      "8872/8872 [==============================] - 0s 26us/step - loss: 0.5430 - acc: 0.7262 - val_loss: 0.5594 - val_acc: 0.7516\n",
      "Epoch 411/700\n",
      "8872/8872 [==============================] - 0s 31us/step - loss: 0.5408 - acc: 0.7267 - val_loss: 0.5522 - val_acc: 0.7584\n",
      "Epoch 412/700\n",
      "8872/8872 [==============================] - 0s 27us/step - loss: 0.5448 - acc: 0.7268 - val_loss: 0.5528 - val_acc: 0.7576\n",
      "Epoch 413/700\n",
      "8872/8872 [==============================] - 0s 27us/step - loss: 0.5446 - acc: 0.7257 - val_loss: 0.5592 - val_acc: 0.7523\n",
      "Epoch 414/700\n",
      "8872/8872 [==============================] - 0s 27us/step - loss: 0.5429 - acc: 0.7277 - val_loss: 0.5575 - val_acc: 0.7529\n",
      "Epoch 415/700\n",
      "8872/8872 [==============================] - 0s 24us/step - loss: 0.5424 - acc: 0.7246 - val_loss: 0.5581 - val_acc: 0.7529\n",
      "Epoch 416/700\n",
      "8872/8872 [==============================] - 0s 28us/step - loss: 0.5428 - acc: 0.7282 - val_loss: 0.5572 - val_acc: 0.7551\n",
      "Epoch 417/700\n",
      "8872/8872 [==============================] - 0s 25us/step - loss: 0.5428 - acc: 0.7277 - val_loss: 0.5616 - val_acc: 0.7484\n",
      "Epoch 418/700\n",
      "8872/8872 [==============================] - 0s 24us/step - loss: 0.5432 - acc: 0.7264 - val_loss: 0.5622 - val_acc: 0.7484\n",
      "Epoch 419/700\n",
      "8872/8872 [==============================] - 0s 25us/step - loss: 0.5450 - acc: 0.7263 - val_loss: 0.5569 - val_acc: 0.7538\n",
      "Epoch 420/700\n",
      "8872/8872 [==============================] - 0s 29us/step - loss: 0.5427 - acc: 0.7293 - val_loss: 0.5572 - val_acc: 0.7533\n",
      "Epoch 421/700\n",
      "8872/8872 [==============================] - 0s 24us/step - loss: 0.5429 - acc: 0.7281 - val_loss: 0.5587 - val_acc: 0.7523\n",
      "Epoch 422/700\n",
      "8872/8872 [==============================] - 0s 26us/step - loss: 0.5430 - acc: 0.7242 - val_loss: 0.5580 - val_acc: 0.7538\n",
      "Epoch 423/700\n",
      "8872/8872 [==============================] - 0s 27us/step - loss: 0.5434 - acc: 0.7240 - val_loss: 0.5569 - val_acc: 0.7547\n",
      "Epoch 424/700\n",
      "8872/8872 [==============================] - 0s 25us/step - loss: 0.5432 - acc: 0.7261 - val_loss: 0.5556 - val_acc: 0.7551\n",
      "Epoch 425/700\n",
      "8872/8872 [==============================] - 0s 26us/step - loss: 0.5423 - acc: 0.7251 - val_loss: 0.5584 - val_acc: 0.7538\n",
      "Epoch 426/700\n",
      "8872/8872 [==============================] - 0s 26us/step - loss: 0.5425 - acc: 0.7268 - val_loss: 0.5580 - val_acc: 0.7535\n",
      "Epoch 427/700\n",
      "8872/8872 [==============================] - 0s 25us/step - loss: 0.5434 - acc: 0.7275 - val_loss: 0.5567 - val_acc: 0.7550\n",
      "Epoch 428/700\n",
      "8872/8872 [==============================] - 0s 26us/step - loss: 0.5424 - acc: 0.7275 - val_loss: 0.5562 - val_acc: 0.7556\n",
      "Epoch 429/700\n",
      "8872/8872 [==============================] - 0s 28us/step - loss: 0.5412 - acc: 0.7279 - val_loss: 0.5619 - val_acc: 0.7499\n",
      "Epoch 430/700\n",
      "8872/8872 [==============================] - 0s 27us/step - loss: 0.5432 - acc: 0.7298 - val_loss: 0.5587 - val_acc: 0.7516\n",
      "Epoch 431/700\n",
      "8872/8872 [==============================] - 0s 26us/step - loss: 0.5411 - acc: 0.7262 - val_loss: 0.5587 - val_acc: 0.7508\n",
      "Epoch 432/700\n",
      "8872/8872 [==============================] - 0s 25us/step - loss: 0.5404 - acc: 0.7288 - val_loss: 0.5624 - val_acc: 0.7474\n",
      "Epoch 433/700\n",
      "8872/8872 [==============================] - 0s 29us/step - loss: 0.5434 - acc: 0.7254 - val_loss: 0.5591 - val_acc: 0.7501\n",
      "Epoch 434/700\n",
      "8872/8872 [==============================] - 0s 29us/step - loss: 0.5433 - acc: 0.7264 - val_loss: 0.5511 - val_acc: 0.7569\n",
      "Epoch 435/700\n",
      "8872/8872 [==============================] - 0s 26us/step - loss: 0.5420 - acc: 0.7266 - val_loss: 0.5547 - val_acc: 0.7560\n",
      "Epoch 436/700\n",
      "8872/8872 [==============================] - 0s 24us/step - loss: 0.5415 - acc: 0.7253 - val_loss: 0.5590 - val_acc: 0.7523\n",
      "Epoch 437/700\n",
      "8872/8872 [==============================] - 0s 24us/step - loss: 0.5412 - acc: 0.7252 - val_loss: 0.5544 - val_acc: 0.7557\n",
      "Epoch 438/700\n",
      "8872/8872 [==============================] - 0s 25us/step - loss: 0.5406 - acc: 0.7314 - val_loss: 0.5535 - val_acc: 0.7563\n",
      "Epoch 439/700\n",
      "8872/8872 [==============================] - 0s 24us/step - loss: 0.5411 - acc: 0.7281 - val_loss: 0.5563 - val_acc: 0.7536\n",
      "Epoch 440/700\n",
      "8872/8872 [==============================] - 0s 24us/step - loss: 0.5424 - acc: 0.7294 - val_loss: 0.5622 - val_acc: 0.7473\n",
      "Epoch 441/700\n",
      "8872/8872 [==============================] - 0s 25us/step - loss: 0.5426 - acc: 0.7267 - val_loss: 0.5579 - val_acc: 0.7524\n",
      "Epoch 442/700\n",
      "8872/8872 [==============================] - 0s 28us/step - loss: 0.5435 - acc: 0.7267 - val_loss: 0.5629 - val_acc: 0.7476\n",
      "Epoch 443/700\n",
      "8872/8872 [==============================] - 0s 24us/step - loss: 0.5428 - acc: 0.7257 - val_loss: 0.5596 - val_acc: 0.7516\n",
      "Epoch 444/700\n",
      "8872/8872 [==============================] - 0s 23us/step - loss: 0.5424 - acc: 0.7239 - val_loss: 0.5572 - val_acc: 0.7541\n",
      "Epoch 445/700\n",
      "8872/8872 [==============================] - 0s 24us/step - loss: 0.5417 - acc: 0.7269 - val_loss: 0.5572 - val_acc: 0.7536\n",
      "Epoch 446/700\n",
      "8872/8872 [==============================] - 0s 24us/step - loss: 0.5421 - acc: 0.7280 - val_loss: 0.5553 - val_acc: 0.7553\n",
      "Epoch 447/700\n",
      "8872/8872 [==============================] - 0s 25us/step - loss: 0.5408 - acc: 0.7258 - val_loss: 0.5565 - val_acc: 0.7536\n",
      "Epoch 448/700\n",
      "8872/8872 [==============================] - 0s 25us/step - loss: 0.5398 - acc: 0.7276 - val_loss: 0.5566 - val_acc: 0.7532\n",
      "Epoch 449/700\n",
      "8872/8872 [==============================] - 0s 24us/step - loss: 0.5397 - acc: 0.7280 - val_loss: 0.5603 - val_acc: 0.7508\n",
      "Epoch 450/700\n",
      "8872/8872 [==============================] - 0s 25us/step - loss: 0.5410 - acc: 0.7272 - val_loss: 0.5584 - val_acc: 0.7524\n",
      "Epoch 451/700\n",
      "8872/8872 [==============================] - 0s 25us/step - loss: 0.5416 - acc: 0.7298 - val_loss: 0.5557 - val_acc: 0.7539\n",
      "Epoch 452/700\n",
      "8872/8872 [==============================] - 0s 26us/step - loss: 0.5400 - acc: 0.7296 - val_loss: 0.5609 - val_acc: 0.7479\n",
      "Epoch 453/700\n",
      "8872/8872 [==============================] - 0s 25us/step - loss: 0.5401 - acc: 0.7253 - val_loss: 0.5601 - val_acc: 0.7513\n",
      "Epoch 454/700\n",
      "8872/8872 [==============================] - 0s 26us/step - loss: 0.5389 - acc: 0.7278 - val_loss: 0.5533 - val_acc: 0.7553\n",
      "Epoch 455/700\n",
      "8872/8872 [==============================] - 0s 26us/step - loss: 0.5410 - acc: 0.7239 - val_loss: 0.5574 - val_acc: 0.7516\n",
      "Epoch 456/700\n",
      "8872/8872 [==============================] - 0s 25us/step - loss: 0.5403 - acc: 0.7258 - val_loss: 0.5637 - val_acc: 0.7443\n",
      "Epoch 457/700\n",
      "8872/8872 [==============================] - 0s 27us/step - loss: 0.5412 - acc: 0.7291 - val_loss: 0.5578 - val_acc: 0.7513\n",
      "Epoch 458/700\n",
      "8872/8872 [==============================] - 0s 25us/step - loss: 0.5415 - acc: 0.7259 - val_loss: 0.5581 - val_acc: 0.7508\n",
      "Epoch 459/700\n",
      "8872/8872 [==============================] - 0s 25us/step - loss: 0.5420 - acc: 0.7240 - val_loss: 0.5576 - val_acc: 0.7514\n",
      "Epoch 460/700\n",
      "8872/8872 [==============================] - 0s 26us/step - loss: 0.5401 - acc: 0.7284 - val_loss: 0.5551 - val_acc: 0.7541\n",
      "Epoch 461/700\n",
      "8872/8872 [==============================] - 0s 26us/step - loss: 0.5411 - acc: 0.7258 - val_loss: 0.5608 - val_acc: 0.7479\n",
      "Epoch 462/700\n",
      "8872/8872 [==============================] - 0s 24us/step - loss: 0.5411 - acc: 0.7254 - val_loss: 0.5576 - val_acc: 0.7527\n",
      "Epoch 463/700\n",
      "8872/8872 [==============================] - 0s 25us/step - loss: 0.5402 - acc: 0.7300 - val_loss: 0.5553 - val_acc: 0.7538\n",
      "Epoch 464/700\n",
      "8872/8872 [==============================] - 0s 26us/step - loss: 0.5402 - acc: 0.7275 - val_loss: 0.5521 - val_acc: 0.7566\n",
      "Epoch 465/700\n",
      "8872/8872 [==============================] - 0s 27us/step - loss: 0.5401 - acc: 0.7260 - val_loss: 0.5643 - val_acc: 0.7447\n",
      "Epoch 466/700\n",
      "8872/8872 [==============================] - 0s 23us/step - loss: 0.5414 - acc: 0.7304 - val_loss: 0.5590 - val_acc: 0.7507\n",
      "Epoch 467/700\n",
      "8872/8872 [==============================] - 0s 26us/step - loss: 0.5396 - acc: 0.7290 - val_loss: 0.5573 - val_acc: 0.7505\n",
      "Epoch 468/700\n",
      "8872/8872 [==============================] - 0s 26us/step - loss: 0.5395 - acc: 0.7287 - val_loss: 0.5573 - val_acc: 0.7510\n",
      "Epoch 469/700\n",
      "8872/8872 [==============================] - 0s 25us/step - loss: 0.5393 - acc: 0.7302 - val_loss: 0.5606 - val_acc: 0.7476\n",
      "Epoch 470/700\n",
      "8872/8872 [==============================] - 0s 27us/step - loss: 0.5402 - acc: 0.7298 - val_loss: 0.5537 - val_acc: 0.7544\n",
      "Epoch 471/700\n",
      "8872/8872 [==============================] - 0s 27us/step - loss: 0.5393 - acc: 0.7263 - val_loss: 0.5604 - val_acc: 0.7496\n",
      "Epoch 472/700\n",
      "8872/8872 [==============================] - 0s 28us/step - loss: 0.5381 - acc: 0.7249 - val_loss: 0.5560 - val_acc: 0.7526\n",
      "Epoch 473/700\n",
      "8872/8872 [==============================] - 0s 25us/step - loss: 0.5410 - acc: 0.7268 - val_loss: 0.5566 - val_acc: 0.7519\n",
      "Epoch 474/700\n",
      "8872/8872 [==============================] - 0s 26us/step - loss: 0.5395 - acc: 0.7269 - val_loss: 0.5540 - val_acc: 0.7541\n",
      "Epoch 475/700\n",
      "8872/8872 [==============================] - 0s 26us/step - loss: 0.5381 - acc: 0.7290 - val_loss: 0.5558 - val_acc: 0.7530\n",
      "Epoch 476/700\n",
      "8872/8872 [==============================] - 0s 26us/step - loss: 0.5382 - acc: 0.7287 - val_loss: 0.5552 - val_acc: 0.7533\n",
      "Epoch 477/700\n",
      "8872/8872 [==============================] - 0s 24us/step - loss: 0.5386 - acc: 0.7313 - val_loss: 0.5572 - val_acc: 0.7508\n",
      "Epoch 478/700\n",
      "8872/8872 [==============================] - 0s 25us/step - loss: 0.5394 - acc: 0.7250 - val_loss: 0.5607 - val_acc: 0.7477\n",
      "Epoch 479/700\n",
      "8872/8872 [==============================] - 0s 26us/step - loss: 0.5390 - acc: 0.7267 - val_loss: 0.5564 - val_acc: 0.7524\n",
      "Epoch 480/700\n",
      "8872/8872 [==============================] - 0s 26us/step - loss: 0.5400 - acc: 0.7252 - val_loss: 0.5620 - val_acc: 0.7465\n",
      "Epoch 481/700\n",
      "8872/8872 [==============================] - 0s 24us/step - loss: 0.5369 - acc: 0.7298 - val_loss: 0.5601 - val_acc: 0.7480\n",
      "Epoch 482/700\n",
      "8872/8872 [==============================] - 0s 23us/step - loss: 0.5399 - acc: 0.7310 - val_loss: 0.5573 - val_acc: 0.7516\n",
      "Epoch 483/700\n",
      "8872/8872 [==============================] - 0s 26us/step - loss: 0.5379 - acc: 0.7302 - val_loss: 0.5554 - val_acc: 0.7516\n",
      "Epoch 484/700\n",
      "8872/8872 [==============================] - 0s 26us/step - loss: 0.5380 - acc: 0.7296 - val_loss: 0.5570 - val_acc: 0.7505\n",
      "Epoch 485/700\n",
      "8872/8872 [==============================] - 0s 26us/step - loss: 0.5394 - acc: 0.7298 - val_loss: 0.5624 - val_acc: 0.7444\n",
      "Epoch 486/700\n",
      "8872/8872 [==============================] - 0s 26us/step - loss: 0.5396 - acc: 0.7281 - val_loss: 0.5603 - val_acc: 0.7481\n",
      "Epoch 487/700\n",
      "8872/8872 [==============================] - 0s 27us/step - loss: 0.5370 - acc: 0.7340 - val_loss: 0.5636 - val_acc: 0.7453\n",
      "Epoch 488/700\n",
      "8872/8872 [==============================] - 0s 26us/step - loss: 0.5383 - acc: 0.7303 - val_loss: 0.5536 - val_acc: 0.7536\n",
      "Epoch 489/700\n",
      "8872/8872 [==============================] - 0s 25us/step - loss: 0.5384 - acc: 0.7308 - val_loss: 0.5594 - val_acc: 0.7508\n",
      "Epoch 490/700\n",
      "8872/8872 [==============================] - 0s 28us/step - loss: 0.5383 - acc: 0.7279 - val_loss: 0.5598 - val_acc: 0.7496\n",
      "Epoch 491/700\n",
      "8872/8872 [==============================] - 0s 28us/step - loss: 0.5371 - acc: 0.7303 - val_loss: 0.5557 - val_acc: 0.7524\n",
      "Epoch 492/700\n",
      "8872/8872 [==============================] - 0s 30us/step - loss: 0.5410 - acc: 0.7278 - val_loss: 0.5631 - val_acc: 0.7464\n",
      "Epoch 493/700\n",
      "8872/8872 [==============================] - 0s 29us/step - loss: 0.5373 - acc: 0.7299 - val_loss: 0.5640 - val_acc: 0.7465\n",
      "Epoch 494/700\n",
      "8872/8872 [==============================] - 0s 26us/step - loss: 0.5380 - acc: 0.7252 - val_loss: 0.5573 - val_acc: 0.7520\n",
      "Epoch 495/700\n",
      "8872/8872 [==============================] - 0s 24us/step - loss: 0.5370 - acc: 0.7284 - val_loss: 0.5581 - val_acc: 0.7514\n",
      "Epoch 496/700\n",
      "8872/8872 [==============================] - 0s 26us/step - loss: 0.5399 - acc: 0.7296 - val_loss: 0.5582 - val_acc: 0.7505\n",
      "Epoch 497/700\n",
      "8872/8872 [==============================] - 0s 25us/step - loss: 0.5391 - acc: 0.7298 - val_loss: 0.5597 - val_acc: 0.7477\n",
      "Epoch 498/700\n",
      "8872/8872 [==============================] - 0s 24us/step - loss: 0.5387 - acc: 0.7303 - val_loss: 0.5547 - val_acc: 0.7519\n",
      "Epoch 499/700\n",
      "8872/8872 [==============================] - 0s 26us/step - loss: 0.5386 - acc: 0.7300 - val_loss: 0.5625 - val_acc: 0.7449\n",
      "Epoch 500/700\n",
      "8872/8872 [==============================] - 0s 27us/step - loss: 0.5366 - acc: 0.7310 - val_loss: 0.5586 - val_acc: 0.7501\n",
      "Epoch 501/700\n",
      "8872/8872 [==============================] - 0s 26us/step - loss: 0.5364 - acc: 0.7284 - val_loss: 0.5611 - val_acc: 0.7465\n",
      "Epoch 502/700\n",
      "8872/8872 [==============================] - 0s 24us/step - loss: 0.5371 - acc: 0.7264 - val_loss: 0.5598 - val_acc: 0.7474\n",
      "Epoch 503/700\n",
      "8872/8872 [==============================] - 0s 24us/step - loss: 0.5368 - acc: 0.7262 - val_loss: 0.5584 - val_acc: 0.7479\n",
      "Epoch 504/700\n",
      "8872/8872 [==============================] - 0s 24us/step - loss: 0.5356 - acc: 0.7331 - val_loss: 0.5643 - val_acc: 0.7443\n",
      "Epoch 505/700\n",
      "8872/8872 [==============================] - 0s 29us/step - loss: 0.5356 - acc: 0.7325 - val_loss: 0.5530 - val_acc: 0.7538\n",
      "Epoch 506/700\n",
      "8872/8872 [==============================] - 0s 26us/step - loss: 0.5370 - acc: 0.7307 - val_loss: 0.5569 - val_acc: 0.7510\n",
      "Epoch 507/700\n",
      "8872/8872 [==============================] - 0s 24us/step - loss: 0.5362 - acc: 0.7289 - val_loss: 0.5608 - val_acc: 0.7484\n",
      "Epoch 508/700\n",
      "8872/8872 [==============================] - 0s 23us/step - loss: 0.5375 - acc: 0.7284 - val_loss: 0.5595 - val_acc: 0.7508\n",
      "Epoch 509/700\n",
      "8872/8872 [==============================] - 0s 24us/step - loss: 0.5371 - acc: 0.7261 - val_loss: 0.5648 - val_acc: 0.7418\n",
      "Epoch 510/700\n",
      "8872/8872 [==============================] - 0s 26us/step - loss: 0.5366 - acc: 0.7307 - val_loss: 0.5618 - val_acc: 0.7464\n",
      "Epoch 511/700\n",
      "8872/8872 [==============================] - 0s 24us/step - loss: 0.5363 - acc: 0.7307 - val_loss: 0.5587 - val_acc: 0.7499\n",
      "Epoch 512/700\n",
      "8872/8872 [==============================] - 0s 29us/step - loss: 0.5384 - acc: 0.7288 - val_loss: 0.5604 - val_acc: 0.7470\n",
      "Epoch 513/700\n",
      "8872/8872 [==============================] - 0s 27us/step - loss: 0.5362 - acc: 0.7312 - val_loss: 0.5509 - val_acc: 0.7550\n",
      "Epoch 514/700\n",
      "8872/8872 [==============================] - 0s 25us/step - loss: 0.5365 - acc: 0.7294 - val_loss: 0.5597 - val_acc: 0.7492\n",
      "Epoch 515/700\n",
      "8872/8872 [==============================] - 0s 24us/step - loss: 0.5364 - acc: 0.7324 - val_loss: 0.5610 - val_acc: 0.7450\n",
      "Epoch 516/700\n",
      "8872/8872 [==============================] - 0s 27us/step - loss: 0.5383 - acc: 0.7305 - val_loss: 0.5609 - val_acc: 0.7471\n",
      "Epoch 517/700\n",
      "8872/8872 [==============================] - 0s 26us/step - loss: 0.5353 - acc: 0.7299 - val_loss: 0.5653 - val_acc: 0.7418\n",
      "Epoch 518/700\n",
      "8872/8872 [==============================] - 0s 26us/step - loss: 0.5372 - acc: 0.7332 - val_loss: 0.5536 - val_acc: 0.7529\n",
      "Epoch 519/700\n",
      "8872/8872 [==============================] - 0s 24us/step - loss: 0.5378 - acc: 0.7285 - val_loss: 0.5532 - val_acc: 0.7524\n",
      "Epoch 520/700\n",
      "8872/8872 [==============================] - 0s 27us/step - loss: 0.5386 - acc: 0.7303 - val_loss: 0.5564 - val_acc: 0.7511\n",
      "Epoch 521/700\n",
      "8872/8872 [==============================] - 0s 28us/step - loss: 0.5360 - acc: 0.7302 - val_loss: 0.5596 - val_acc: 0.7467\n",
      "Epoch 522/700\n",
      "8872/8872 [==============================] - 0s 28us/step - loss: 0.5342 - acc: 0.7322 - val_loss: 0.5589 - val_acc: 0.7473\n",
      "Epoch 523/700\n",
      "8872/8872 [==============================] - 0s 26us/step - loss: 0.5373 - acc: 0.7284 - val_loss: 0.5625 - val_acc: 0.7455\n",
      "Epoch 524/700\n",
      "8872/8872 [==============================] - 0s 24us/step - loss: 0.5342 - acc: 0.7328 - val_loss: 0.5618 - val_acc: 0.7447\n",
      "Epoch 525/700\n",
      "8872/8872 [==============================] - 0s 26us/step - loss: 0.5374 - acc: 0.7272 - val_loss: 0.5565 - val_acc: 0.7501\n",
      "Epoch 526/700\n",
      "8872/8872 [==============================] - 0s 26us/step - loss: 0.5359 - acc: 0.7316 - val_loss: 0.5595 - val_acc: 0.7476\n",
      "Epoch 527/700\n",
      "8872/8872 [==============================] - 0s 26us/step - loss: 0.5348 - acc: 0.7311 - val_loss: 0.5593 - val_acc: 0.7483\n",
      "Epoch 528/700\n",
      "8872/8872 [==============================] - 0s 27us/step - loss: 0.5337 - acc: 0.7321 - val_loss: 0.5635 - val_acc: 0.7450\n",
      "Epoch 529/700\n",
      "8872/8872 [==============================] - 0s 26us/step - loss: 0.5350 - acc: 0.7333 - val_loss: 0.5555 - val_acc: 0.7516\n",
      "Epoch 530/700\n",
      "8872/8872 [==============================] - 0s 27us/step - loss: 0.5354 - acc: 0.7308 - val_loss: 0.5598 - val_acc: 0.7465\n",
      "Epoch 531/700\n",
      "8872/8872 [==============================] - 0s 28us/step - loss: 0.5369 - acc: 0.7290 - val_loss: 0.5579 - val_acc: 0.7484\n",
      "Epoch 532/700\n",
      "8872/8872 [==============================] - 0s 25us/step - loss: 0.5360 - acc: 0.7298 - val_loss: 0.5631 - val_acc: 0.7428\n",
      "Epoch 533/700\n",
      "8872/8872 [==============================] - 0s 25us/step - loss: 0.5350 - acc: 0.7312 - val_loss: 0.5539 - val_acc: 0.7505\n",
      "Epoch 534/700\n",
      "8872/8872 [==============================] - 0s 24us/step - loss: 0.5347 - acc: 0.7288 - val_loss: 0.5602 - val_acc: 0.7467\n",
      "Epoch 535/700\n",
      "8872/8872 [==============================] - 0s 24us/step - loss: 0.5361 - acc: 0.7280 - val_loss: 0.5556 - val_acc: 0.7504\n",
      "Epoch 536/700\n",
      "8872/8872 [==============================] - 0s 26us/step - loss: 0.5370 - acc: 0.7294 - val_loss: 0.5577 - val_acc: 0.7473\n",
      "Epoch 537/700\n",
      "8872/8872 [==============================] - 0s 28us/step - loss: 0.5352 - acc: 0.7286 - val_loss: 0.5610 - val_acc: 0.7452\n",
      "Epoch 538/700\n",
      "8872/8872 [==============================] - 0s 25us/step - loss: 0.5363 - acc: 0.7287 - val_loss: 0.5599 - val_acc: 0.7461\n",
      "Epoch 539/700\n",
      "8872/8872 [==============================] - 0s 25us/step - loss: 0.5367 - acc: 0.7270 - val_loss: 0.5611 - val_acc: 0.7441\n",
      "Epoch 540/700\n",
      "8872/8872 [==============================] - 0s 25us/step - loss: 0.5352 - acc: 0.7308 - val_loss: 0.5526 - val_acc: 0.7527\n",
      "Epoch 541/700\n",
      "8872/8872 [==============================] - 0s 26us/step - loss: 0.5343 - acc: 0.7317 - val_loss: 0.5596 - val_acc: 0.7446\n",
      "Epoch 542/700\n",
      "8872/8872 [==============================] - 0s 24us/step - loss: 0.5332 - acc: 0.7337 - val_loss: 0.5556 - val_acc: 0.7501\n",
      "Epoch 543/700\n",
      "8872/8872 [==============================] - 0s 23us/step - loss: 0.5341 - acc: 0.7288 - val_loss: 0.5543 - val_acc: 0.7513\n",
      "Epoch 544/700\n",
      "8872/8872 [==============================] - 0s 24us/step - loss: 0.5383 - acc: 0.7294 - val_loss: 0.5571 - val_acc: 0.7484\n",
      "Epoch 545/700\n",
      "8872/8872 [==============================] - 0s 28us/step - loss: 0.5344 - acc: 0.7312 - val_loss: 0.5619 - val_acc: 0.7440\n",
      "Epoch 546/700\n",
      "8872/8872 [==============================] - 0s 24us/step - loss: 0.5350 - acc: 0.7313 - val_loss: 0.5546 - val_acc: 0.7498\n",
      "Epoch 547/700\n",
      "8872/8872 [==============================] - 0s 27us/step - loss: 0.5340 - acc: 0.7319 - val_loss: 0.5575 - val_acc: 0.7470\n",
      "Epoch 548/700\n",
      "8872/8872 [==============================] - 0s 24us/step - loss: 0.5346 - acc: 0.7289 - val_loss: 0.5570 - val_acc: 0.7465\n",
      "Epoch 549/700\n",
      "8872/8872 [==============================] - 0s 26us/step - loss: 0.5348 - acc: 0.7284 - val_loss: 0.5607 - val_acc: 0.7450\n",
      "Epoch 550/700\n",
      "8872/8872 [==============================] - 0s 29us/step - loss: 0.5355 - acc: 0.7332 - val_loss: 0.5581 - val_acc: 0.7455\n",
      "Epoch 551/700\n",
      "8872/8872 [==============================] - 0s 30us/step - loss: 0.5334 - acc: 0.7320 - val_loss: 0.5605 - val_acc: 0.7455\n",
      "Epoch 552/700\n",
      "8872/8872 [==============================] - 0s 33us/step - loss: 0.5337 - acc: 0.7307 - val_loss: 0.5594 - val_acc: 0.7450\n",
      "Epoch 553/700\n",
      "8872/8872 [==============================] - 0s 30us/step - loss: 0.5346 - acc: 0.7258 - val_loss: 0.5606 - val_acc: 0.7422\n",
      "Epoch 554/700\n",
      "8872/8872 [==============================] - 0s 30us/step - loss: 0.5323 - acc: 0.7314 - val_loss: 0.5569 - val_acc: 0.7492\n",
      "Epoch 555/700\n",
      "8872/8872 [==============================] - 0s 25us/step - loss: 0.5313 - acc: 0.7337 - val_loss: 0.5611 - val_acc: 0.7444\n",
      "Epoch 556/700\n",
      "8872/8872 [==============================] - 0s 25us/step - loss: 0.5337 - acc: 0.7302 - val_loss: 0.5583 - val_acc: 0.7477\n",
      "Epoch 557/700\n",
      "8872/8872 [==============================] - 0s 24us/step - loss: 0.5318 - acc: 0.7339 - val_loss: 0.5580 - val_acc: 0.7465\n",
      "Epoch 558/700\n",
      "8872/8872 [==============================] - 0s 28us/step - loss: 0.5335 - acc: 0.7302 - val_loss: 0.5609 - val_acc: 0.7437\n",
      "Epoch 559/700\n",
      "8872/8872 [==============================] - 0s 24us/step - loss: 0.5343 - acc: 0.7295 - val_loss: 0.5608 - val_acc: 0.7456\n",
      "Epoch 560/700\n",
      "8872/8872 [==============================] - 0s 25us/step - loss: 0.5347 - acc: 0.7310 - val_loss: 0.5605 - val_acc: 0.7455\n",
      "Epoch 561/700\n",
      "8872/8872 [==============================] - 0s 24us/step - loss: 0.5321 - acc: 0.7340 - val_loss: 0.5602 - val_acc: 0.7450\n",
      "Epoch 562/700\n",
      "8872/8872 [==============================] - 0s 26us/step - loss: 0.5314 - acc: 0.7299 - val_loss: 0.5622 - val_acc: 0.7425\n",
      "Epoch 563/700\n",
      "8872/8872 [==============================] - 0s 23us/step - loss: 0.5342 - acc: 0.7298 - val_loss: 0.5596 - val_acc: 0.7440\n",
      "Epoch 564/700\n",
      "8872/8872 [==============================] - 0s 23us/step - loss: 0.5327 - acc: 0.7325 - val_loss: 0.5632 - val_acc: 0.7418\n",
      "Epoch 565/700\n",
      "8872/8872 [==============================] - 0s 23us/step - loss: 0.5314 - acc: 0.7325 - val_loss: 0.5575 - val_acc: 0.7473\n",
      "Epoch 566/700\n",
      "8872/8872 [==============================] - 0s 23us/step - loss: 0.5312 - acc: 0.7370 - val_loss: 0.5578 - val_acc: 0.7464\n",
      "Epoch 567/700\n",
      "8872/8872 [==============================] - 0s 25us/step - loss: 0.5341 - acc: 0.7297 - val_loss: 0.5646 - val_acc: 0.7421\n",
      "Epoch 568/700\n",
      "8872/8872 [==============================] - 0s 25us/step - loss: 0.5328 - acc: 0.7339 - val_loss: 0.5566 - val_acc: 0.7495\n",
      "Epoch 569/700\n",
      "8872/8872 [==============================] - 0s 23us/step - loss: 0.5338 - acc: 0.7279 - val_loss: 0.5602 - val_acc: 0.7436\n",
      "Epoch 570/700\n",
      "8872/8872 [==============================] - 0s 23us/step - loss: 0.5312 - acc: 0.7328 - val_loss: 0.5656 - val_acc: 0.7387\n",
      "Epoch 571/700\n",
      "8872/8872 [==============================] - 0s 24us/step - loss: 0.5341 - acc: 0.7312 - val_loss: 0.5627 - val_acc: 0.7409\n",
      "Epoch 572/700\n",
      "8872/8872 [==============================] - 0s 27us/step - loss: 0.5320 - acc: 0.7322 - val_loss: 0.5632 - val_acc: 0.7413\n",
      "Epoch 573/700\n",
      "8872/8872 [==============================] - 0s 25us/step - loss: 0.5309 - acc: 0.7294 - val_loss: 0.5636 - val_acc: 0.7410\n",
      "Epoch 574/700\n",
      "8872/8872 [==============================] - 0s 23us/step - loss: 0.5328 - acc: 0.7343 - val_loss: 0.5562 - val_acc: 0.7477\n",
      "Epoch 575/700\n",
      "8872/8872 [==============================] - 0s 26us/step - loss: 0.5325 - acc: 0.7367 - val_loss: 0.5605 - val_acc: 0.7434\n",
      "Epoch 576/700\n",
      "8872/8872 [==============================] - 0s 24us/step - loss: 0.5332 - acc: 0.7328 - val_loss: 0.5624 - val_acc: 0.7418\n",
      "Epoch 577/700\n",
      "8872/8872 [==============================] - 0s 30us/step - loss: 0.5320 - acc: 0.7337 - val_loss: 0.5617 - val_acc: 0.7424\n",
      "Epoch 578/700\n",
      "8872/8872 [==============================] - 0s 30us/step - loss: 0.5325 - acc: 0.7339 - val_loss: 0.5637 - val_acc: 0.7418\n",
      "Epoch 579/700\n",
      "8872/8872 [==============================] - 0s 24us/step - loss: 0.5332 - acc: 0.7319 - val_loss: 0.5568 - val_acc: 0.7473\n",
      "Epoch 580/700\n",
      "8872/8872 [==============================] - 0s 25us/step - loss: 0.5337 - acc: 0.7348 - val_loss: 0.5546 - val_acc: 0.7474\n",
      "Epoch 581/700\n",
      "8872/8872 [==============================] - 0s 27us/step - loss: 0.5332 - acc: 0.7311 - val_loss: 0.5590 - val_acc: 0.7437\n",
      "Epoch 582/700\n",
      "8872/8872 [==============================] - 0s 26us/step - loss: 0.5310 - acc: 0.7344 - val_loss: 0.5529 - val_acc: 0.7499\n",
      "Epoch 583/700\n",
      "8872/8872 [==============================] - 0s 26us/step - loss: 0.5314 - acc: 0.7346 - val_loss: 0.5553 - val_acc: 0.7476\n",
      "Epoch 584/700\n",
      "8872/8872 [==============================] - 0s 23us/step - loss: 0.5329 - acc: 0.7289 - val_loss: 0.5582 - val_acc: 0.7450\n",
      "Epoch 585/700\n",
      "8872/8872 [==============================] - 0s 27us/step - loss: 0.5309 - acc: 0.7323 - val_loss: 0.5642 - val_acc: 0.7399\n",
      "Epoch 586/700\n",
      "8872/8872 [==============================] - 0s 25us/step - loss: 0.5312 - acc: 0.7356 - val_loss: 0.5547 - val_acc: 0.7501\n",
      "Epoch 587/700\n",
      "8872/8872 [==============================] - 0s 25us/step - loss: 0.5317 - acc: 0.7330 - val_loss: 0.5623 - val_acc: 0.7413\n",
      "Epoch 588/700\n",
      "8872/8872 [==============================] - 0s 23us/step - loss: 0.5298 - acc: 0.7358 - val_loss: 0.5619 - val_acc: 0.7424\n",
      "Epoch 589/700\n",
      "8872/8872 [==============================] - 0s 24us/step - loss: 0.5310 - acc: 0.7326 - val_loss: 0.5561 - val_acc: 0.7455\n",
      "Epoch 590/700\n",
      "8872/8872 [==============================] - 0s 26us/step - loss: 0.5307 - acc: 0.7332 - val_loss: 0.5561 - val_acc: 0.7489\n",
      "Epoch 591/700\n",
      "8872/8872 [==============================] - 0s 25us/step - loss: 0.5328 - acc: 0.7326 - val_loss: 0.5625 - val_acc: 0.7418\n",
      "Epoch 592/700\n",
      "8872/8872 [==============================] - 0s 25us/step - loss: 0.5318 - acc: 0.7308 - val_loss: 0.5561 - val_acc: 0.7464\n",
      "Epoch 593/700\n",
      "8872/8872 [==============================] - 0s 24us/step - loss: 0.5306 - acc: 0.7355 - val_loss: 0.5558 - val_acc: 0.7467\n",
      "Epoch 594/700\n",
      "8872/8872 [==============================] - 0s 24us/step - loss: 0.5299 - acc: 0.7313 - val_loss: 0.5575 - val_acc: 0.7439\n",
      "Epoch 595/700\n",
      "8872/8872 [==============================] - 0s 26us/step - loss: 0.5290 - acc: 0.7334 - val_loss: 0.5615 - val_acc: 0.7425\n",
      "Epoch 596/700\n",
      "8872/8872 [==============================] - 0s 26us/step - loss: 0.5313 - acc: 0.7334 - val_loss: 0.5615 - val_acc: 0.7424\n",
      "Epoch 597/700\n",
      "8872/8872 [==============================] - 0s 23us/step - loss: 0.5317 - acc: 0.7294 - val_loss: 0.5605 - val_acc: 0.7431\n",
      "Epoch 598/700\n",
      "8872/8872 [==============================] - 0s 27us/step - loss: 0.5318 - acc: 0.7306 - val_loss: 0.5599 - val_acc: 0.7427\n",
      "Epoch 599/700\n",
      "8872/8872 [==============================] - 0s 27us/step - loss: 0.5299 - acc: 0.7346 - val_loss: 0.5580 - val_acc: 0.7456\n",
      "Epoch 600/700\n",
      "8872/8872 [==============================] - 0s 24us/step - loss: 0.5311 - acc: 0.7360 - val_loss: 0.5601 - val_acc: 0.7439\n",
      "Epoch 601/700\n",
      "8872/8872 [==============================] - 0s 24us/step - loss: 0.5300 - acc: 0.7312 - val_loss: 0.5609 - val_acc: 0.7419\n",
      "Epoch 602/700\n",
      "8872/8872 [==============================] - 0s 26us/step - loss: 0.5313 - acc: 0.7359 - val_loss: 0.5605 - val_acc: 0.7416\n",
      "Epoch 603/700\n",
      "8872/8872 [==============================] - 0s 26us/step - loss: 0.5299 - acc: 0.7333 - val_loss: 0.5621 - val_acc: 0.7424\n",
      "Epoch 604/700\n",
      "8872/8872 [==============================] - 0s 27us/step - loss: 0.5310 - acc: 0.7332 - val_loss: 0.5634 - val_acc: 0.7404\n",
      "Epoch 605/700\n",
      "8872/8872 [==============================] - 0s 25us/step - loss: 0.5305 - acc: 0.7295 - val_loss: 0.5573 - val_acc: 0.7443\n",
      "Epoch 606/700\n",
      "8872/8872 [==============================] - 0s 25us/step - loss: 0.5299 - acc: 0.7342 - val_loss: 0.5541 - val_acc: 0.7470\n",
      "Epoch 607/700\n",
      "8872/8872 [==============================] - 0s 25us/step - loss: 0.5285 - acc: 0.7351 - val_loss: 0.5527 - val_acc: 0.7480\n",
      "Epoch 608/700\n",
      "8872/8872 [==============================] - 0s 25us/step - loss: 0.5311 - acc: 0.7367 - val_loss: 0.5569 - val_acc: 0.7447\n",
      "Epoch 609/700\n",
      "8872/8872 [==============================] - 0s 24us/step - loss: 0.5311 - acc: 0.7319 - val_loss: 0.5585 - val_acc: 0.7430\n",
      "Epoch 610/700\n",
      "8872/8872 [==============================] - 0s 26us/step - loss: 0.5308 - acc: 0.7350 - val_loss: 0.5601 - val_acc: 0.7419\n",
      "Epoch 611/700\n",
      "8872/8872 [==============================] - 0s 23us/step - loss: 0.5312 - acc: 0.7331 - val_loss: 0.5574 - val_acc: 0.7447\n",
      "Epoch 612/700\n",
      "8872/8872 [==============================] - 0s 25us/step - loss: 0.5285 - acc: 0.7344 - val_loss: 0.5586 - val_acc: 0.7425\n",
      "Epoch 613/700\n",
      "8872/8872 [==============================] - 0s 27us/step - loss: 0.5305 - acc: 0.7349 - val_loss: 0.5605 - val_acc: 0.7443\n",
      "Epoch 614/700\n",
      "8872/8872 [==============================] - 0s 26us/step - loss: 0.5308 - acc: 0.7306 - val_loss: 0.5569 - val_acc: 0.7461\n",
      "Epoch 615/700\n",
      "8872/8872 [==============================] - 0s 25us/step - loss: 0.5289 - acc: 0.7328 - val_loss: 0.5600 - val_acc: 0.7433\n",
      "Epoch 616/700\n",
      "8872/8872 [==============================] - 0s 26us/step - loss: 0.5306 - acc: 0.7356 - val_loss: 0.5595 - val_acc: 0.7446\n",
      "Epoch 617/700\n",
      "8872/8872 [==============================] - 0s 27us/step - loss: 0.5297 - acc: 0.7351 - val_loss: 0.5542 - val_acc: 0.7468\n",
      "Epoch 618/700\n",
      "8872/8872 [==============================] - 0s 24us/step - loss: 0.5290 - acc: 0.7323 - val_loss: 0.5585 - val_acc: 0.7444\n",
      "Epoch 619/700\n",
      "8872/8872 [==============================] - 0s 25us/step - loss: 0.5303 - acc: 0.7349 - val_loss: 0.5556 - val_acc: 0.7450\n",
      "Epoch 620/700\n",
      "8872/8872 [==============================] - 0s 23us/step - loss: 0.5302 - acc: 0.7350 - val_loss: 0.5625 - val_acc: 0.7382\n",
      "Epoch 621/700\n",
      "8872/8872 [==============================] - 0s 25us/step - loss: 0.5302 - acc: 0.7316 - val_loss: 0.5552 - val_acc: 0.7462\n",
      "Epoch 622/700\n",
      "8872/8872 [==============================] - 0s 24us/step - loss: 0.5288 - acc: 0.7328 - val_loss: 0.5600 - val_acc: 0.7418\n",
      "Epoch 623/700\n",
      "8872/8872 [==============================] - 0s 26us/step - loss: 0.5299 - acc: 0.7346 - val_loss: 0.5559 - val_acc: 0.7449\n",
      "Epoch 624/700\n",
      "8872/8872 [==============================] - 0s 23us/step - loss: 0.5294 - acc: 0.7333 - val_loss: 0.5558 - val_acc: 0.7449\n",
      "Epoch 625/700\n",
      "8872/8872 [==============================] - 0s 23us/step - loss: 0.5316 - acc: 0.7330 - val_loss: 0.5609 - val_acc: 0.7412\n",
      "Epoch 626/700\n",
      "8872/8872 [==============================] - 0s 24us/step - loss: 0.5307 - acc: 0.7344 - val_loss: 0.5626 - val_acc: 0.7404\n",
      "Epoch 627/700\n",
      "8872/8872 [==============================] - 0s 25us/step - loss: 0.5284 - acc: 0.7365 - val_loss: 0.5621 - val_acc: 0.7404\n",
      "Epoch 628/700\n",
      "8872/8872 [==============================] - 0s 23us/step - loss: 0.5280 - acc: 0.7356 - val_loss: 0.5615 - val_acc: 0.7397\n",
      "Epoch 629/700\n",
      "8872/8872 [==============================] - 0s 24us/step - loss: 0.5292 - acc: 0.7366 - val_loss: 0.5595 - val_acc: 0.7427\n",
      "Epoch 630/700\n",
      "8872/8872 [==============================] - 0s 24us/step - loss: 0.5310 - acc: 0.7341 - val_loss: 0.5611 - val_acc: 0.7416\n",
      "Epoch 631/700\n",
      "8872/8872 [==============================] - 0s 25us/step - loss: 0.5304 - acc: 0.7340 - val_loss: 0.5667 - val_acc: 0.7388\n",
      "Epoch 632/700\n",
      "8872/8872 [==============================] - 0s 25us/step - loss: 0.5299 - acc: 0.7324 - val_loss: 0.5650 - val_acc: 0.7396\n",
      "Epoch 633/700\n",
      "8872/8872 [==============================] - 0s 26us/step - loss: 0.5297 - acc: 0.7352 - val_loss: 0.5692 - val_acc: 0.7364\n",
      "Epoch 634/700\n",
      "8872/8872 [==============================] - 0s 25us/step - loss: 0.5300 - acc: 0.7350 - val_loss: 0.5613 - val_acc: 0.7431\n",
      "Epoch 635/700\n",
      "8872/8872 [==============================] - 0s 30us/step - loss: 0.5287 - acc: 0.7349 - val_loss: 0.5581 - val_acc: 0.7447\n",
      "Epoch 636/700\n",
      "8872/8872 [==============================] - 0s 30us/step - loss: 0.5278 - acc: 0.7340 - val_loss: 0.5606 - val_acc: 0.7412\n",
      "Epoch 637/700\n",
      "8872/8872 [==============================] - 0s 29us/step - loss: 0.5291 - acc: 0.7337 - val_loss: 0.5592 - val_acc: 0.7425\n",
      "Epoch 638/700\n",
      "8872/8872 [==============================] - 0s 28us/step - loss: 0.5273 - acc: 0.7340 - val_loss: 0.5591 - val_acc: 0.7421\n",
      "Epoch 639/700\n",
      "8872/8872 [==============================] - 0s 26us/step - loss: 0.5275 - acc: 0.7328 - val_loss: 0.5601 - val_acc: 0.7433\n",
      "Epoch 640/700\n",
      "8872/8872 [==============================] - 0s 27us/step - loss: 0.5301 - acc: 0.7331 - val_loss: 0.5605 - val_acc: 0.7436\n",
      "Epoch 641/700\n",
      "8872/8872 [==============================] - 0s 27us/step - loss: 0.5289 - acc: 0.7325 - val_loss: 0.5645 - val_acc: 0.7407\n",
      "Epoch 642/700\n",
      "8872/8872 [==============================] - 0s 24us/step - loss: 0.5271 - acc: 0.7335 - val_loss: 0.5682 - val_acc: 0.7378\n",
      "Epoch 643/700\n",
      "8872/8872 [==============================] - 0s 26us/step - loss: 0.5287 - acc: 0.7317 - val_loss: 0.5598 - val_acc: 0.7439\n",
      "Epoch 644/700\n",
      "8872/8872 [==============================] - 0s 27us/step - loss: 0.5253 - acc: 0.7404 - val_loss: 0.5664 - val_acc: 0.7385\n",
      "Epoch 645/700\n",
      "8872/8872 [==============================] - 0s 26us/step - loss: 0.5279 - acc: 0.7344 - val_loss: 0.5593 - val_acc: 0.7437\n",
      "Epoch 646/700\n",
      "8872/8872 [==============================] - 0s 25us/step - loss: 0.5263 - acc: 0.7350 - val_loss: 0.5602 - val_acc: 0.7430\n",
      "Epoch 647/700\n",
      "8872/8872 [==============================] - 0s 26us/step - loss: 0.5291 - acc: 0.7362 - val_loss: 0.5621 - val_acc: 0.7427\n",
      "Epoch 648/700\n",
      "8872/8872 [==============================] - 0s 26us/step - loss: 0.5294 - acc: 0.7343 - val_loss: 0.5558 - val_acc: 0.7464\n",
      "Epoch 649/700\n",
      "8872/8872 [==============================] - 0s 31us/step - loss: 0.5270 - acc: 0.7367 - val_loss: 0.5613 - val_acc: 0.7421\n",
      "Epoch 650/700\n",
      "8872/8872 [==============================] - 0s 30us/step - loss: 0.5267 - acc: 0.7334 - val_loss: 0.5625 - val_acc: 0.7415\n",
      "Epoch 651/700\n",
      "8872/8872 [==============================] - 0s 26us/step - loss: 0.5261 - acc: 0.7387 - val_loss: 0.5632 - val_acc: 0.7404\n",
      "Epoch 652/700\n",
      "8872/8872 [==============================] - 0s 25us/step - loss: 0.5280 - acc: 0.7358 - val_loss: 0.5579 - val_acc: 0.7437\n",
      "Epoch 653/700\n",
      "8872/8872 [==============================] - 0s 26us/step - loss: 0.5260 - acc: 0.7401 - val_loss: 0.5522 - val_acc: 0.7492\n",
      "Epoch 654/700\n",
      "8872/8872 [==============================] - 0s 24us/step - loss: 0.5268 - acc: 0.7385 - val_loss: 0.5694 - val_acc: 0.7357\n",
      "Epoch 655/700\n",
      "8872/8872 [==============================] - 0s 24us/step - loss: 0.5279 - acc: 0.7305 - val_loss: 0.5571 - val_acc: 0.7436\n",
      "Epoch 656/700\n",
      "8872/8872 [==============================] - 0s 25us/step - loss: 0.5293 - acc: 0.7350 - val_loss: 0.5535 - val_acc: 0.7480\n",
      "Epoch 657/700\n",
      "8872/8872 [==============================] - 0s 26us/step - loss: 0.5280 - acc: 0.7343 - val_loss: 0.5630 - val_acc: 0.7375\n",
      "Epoch 658/700\n",
      "8872/8872 [==============================] - 0s 23us/step - loss: 0.5267 - acc: 0.7349 - val_loss: 0.5595 - val_acc: 0.7431\n",
      "Epoch 659/700\n",
      "8872/8872 [==============================] - 0s 26us/step - loss: 0.5262 - acc: 0.7328 - val_loss: 0.5619 - val_acc: 0.7412\n",
      "Epoch 660/700\n",
      "8872/8872 [==============================] - 0s 26us/step - loss: 0.5270 - acc: 0.7339 - val_loss: 0.5636 - val_acc: 0.7406\n",
      "Epoch 661/700\n",
      "8872/8872 [==============================] - 0s 24us/step - loss: 0.5254 - acc: 0.7375 - val_loss: 0.5623 - val_acc: 0.7436\n",
      "Epoch 662/700\n",
      "8872/8872 [==============================] - 0s 24us/step - loss: 0.5251 - acc: 0.7343 - val_loss: 0.5601 - val_acc: 0.7415\n",
      "Epoch 663/700\n",
      "8872/8872 [==============================] - 0s 22us/step - loss: 0.5266 - acc: 0.7391 - val_loss: 0.5633 - val_acc: 0.7403\n",
      "Epoch 664/700\n",
      "8872/8872 [==============================] - 0s 29us/step - loss: 0.5272 - acc: 0.7374 - val_loss: 0.5592 - val_acc: 0.7447\n",
      "Epoch 665/700\n",
      "8872/8872 [==============================] - 0s 24us/step - loss: 0.5298 - acc: 0.7392 - val_loss: 0.5557 - val_acc: 0.7471\n",
      "Epoch 666/700\n",
      "8872/8872 [==============================] - 0s 28us/step - loss: 0.5256 - acc: 0.7368 - val_loss: 0.5571 - val_acc: 0.7425\n",
      "Epoch 667/700\n",
      "8872/8872 [==============================] - 0s 25us/step - loss: 0.5279 - acc: 0.7373 - val_loss: 0.5608 - val_acc: 0.7412\n",
      "Epoch 668/700\n",
      "8872/8872 [==============================] - 0s 25us/step - loss: 0.5255 - acc: 0.7370 - val_loss: 0.5612 - val_acc: 0.7409\n",
      "Epoch 669/700\n",
      "8872/8872 [==============================] - 0s 30us/step - loss: 0.5265 - acc: 0.7370 - val_loss: 0.5585 - val_acc: 0.7430\n",
      "Epoch 670/700\n",
      "8872/8872 [==============================] - 0s 28us/step - loss: 0.5260 - acc: 0.7314 - val_loss: 0.5702 - val_acc: 0.7345\n",
      "Epoch 671/700\n",
      "8872/8872 [==============================] - 0s 27us/step - loss: 0.5251 - acc: 0.7390 - val_loss: 0.5638 - val_acc: 0.7396\n",
      "Epoch 672/700\n",
      "8872/8872 [==============================] - 0s 27us/step - loss: 0.5264 - acc: 0.7356 - val_loss: 0.5560 - val_acc: 0.7450\n",
      "Epoch 673/700\n",
      "8872/8872 [==============================] - 0s 24us/step - loss: 0.5258 - acc: 0.7360 - val_loss: 0.5642 - val_acc: 0.7384\n",
      "Epoch 674/700\n",
      "8872/8872 [==============================] - 0s 24us/step - loss: 0.5259 - acc: 0.7356 - val_loss: 0.5681 - val_acc: 0.7345\n",
      "Epoch 675/700\n",
      "8872/8872 [==============================] - 0s 27us/step - loss: 0.5260 - acc: 0.7353 - val_loss: 0.5574 - val_acc: 0.7428\n",
      "Epoch 676/700\n",
      "8872/8872 [==============================] - 0s 26us/step - loss: 0.5282 - acc: 0.7342 - val_loss: 0.5603 - val_acc: 0.7413\n",
      "Epoch 677/700\n",
      "8872/8872 [==============================] - 0s 29us/step - loss: 0.5278 - acc: 0.7348 - val_loss: 0.5541 - val_acc: 0.7468\n",
      "Epoch 678/700\n",
      "8872/8872 [==============================] - 0s 31us/step - loss: 0.5252 - acc: 0.7357 - val_loss: 0.5583 - val_acc: 0.7425\n",
      "Epoch 679/700\n",
      "8872/8872 [==============================] - 0s 27us/step - loss: 0.5244 - acc: 0.7375 - val_loss: 0.5610 - val_acc: 0.7415\n",
      "Epoch 680/700\n",
      "8872/8872 [==============================] - 0s 26us/step - loss: 0.5279 - acc: 0.7361 - val_loss: 0.5637 - val_acc: 0.7403\n",
      "Epoch 681/700\n",
      "8872/8872 [==============================] - 0s 24us/step - loss: 0.5252 - acc: 0.7343 - val_loss: 0.5609 - val_acc: 0.7413\n",
      "Epoch 682/700\n",
      "8872/8872 [==============================] - 0s 24us/step - loss: 0.5233 - acc: 0.7344 - val_loss: 0.5656 - val_acc: 0.7394\n",
      "Epoch 683/700\n",
      "8872/8872 [==============================] - 0s 26us/step - loss: 0.5248 - acc: 0.7367 - val_loss: 0.5672 - val_acc: 0.7381\n",
      "Epoch 684/700\n",
      "8872/8872 [==============================] - 0s 27us/step - loss: 0.5268 - acc: 0.7343 - val_loss: 0.5645 - val_acc: 0.7401\n",
      "Epoch 685/700\n",
      "8872/8872 [==============================] - 0s 24us/step - loss: 0.5230 - acc: 0.7403 - val_loss: 0.5629 - val_acc: 0.7403\n",
      "Epoch 686/700\n",
      "8872/8872 [==============================] - 0s 26us/step - loss: 0.5252 - acc: 0.7370 - val_loss: 0.5582 - val_acc: 0.7436\n",
      "Epoch 687/700\n",
      "8872/8872 [==============================] - 0s 24us/step - loss: 0.5251 - acc: 0.7386 - val_loss: 0.5559 - val_acc: 0.7431\n",
      "Epoch 688/700\n",
      "8872/8872 [==============================] - 0s 25us/step - loss: 0.5239 - acc: 0.7368 - val_loss: 0.5528 - val_acc: 0.7477\n",
      "Epoch 689/700\n",
      "8872/8872 [==============================] - 0s 26us/step - loss: 0.5241 - acc: 0.7387 - val_loss: 0.5621 - val_acc: 0.7413\n",
      "Epoch 690/700\n",
      "8872/8872 [==============================] - 0s 29us/step - loss: 0.5254 - acc: 0.7373 - val_loss: 0.5620 - val_acc: 0.7409\n",
      "Epoch 691/700\n",
      "8872/8872 [==============================] - 0s 29us/step - loss: 0.5241 - acc: 0.7381 - val_loss: 0.5645 - val_acc: 0.7393\n",
      "Epoch 692/700\n",
      "8872/8872 [==============================] - 0s 24us/step - loss: 0.5240 - acc: 0.7376 - val_loss: 0.5606 - val_acc: 0.7419\n",
      "Epoch 693/700\n",
      "8872/8872 [==============================] - 0s 26us/step - loss: 0.5237 - acc: 0.7374 - val_loss: 0.5588 - val_acc: 0.7427\n",
      "Epoch 694/700\n",
      "8872/8872 [==============================] - 0s 26us/step - loss: 0.5237 - acc: 0.7361 - val_loss: 0.5707 - val_acc: 0.7335\n",
      "Epoch 695/700\n",
      "8872/8872 [==============================] - 0s 24us/step - loss: 0.5224 - acc: 0.7395 - val_loss: 0.5584 - val_acc: 0.7431\n",
      "Epoch 696/700\n",
      "8872/8872 [==============================] - 0s 24us/step - loss: 0.5250 - acc: 0.7386 - val_loss: 0.5561 - val_acc: 0.7465\n",
      "Epoch 697/700\n",
      "8872/8872 [==============================] - 0s 27us/step - loss: 0.5241 - acc: 0.7403 - val_loss: 0.5642 - val_acc: 0.7391\n",
      "Epoch 698/700\n",
      "8872/8872 [==============================] - 0s 25us/step - loss: 0.5247 - acc: 0.7326 - val_loss: 0.5601 - val_acc: 0.7410\n",
      "Epoch 699/700\n",
      "8872/8872 [==============================] - 0s 23us/step - loss: 0.5248 - acc: 0.7370 - val_loss: 0.5613 - val_acc: 0.7404\n",
      "Epoch 700/700\n",
      "8872/8872 [==============================] - 0s 24us/step - loss: 0.5252 - acc: 0.7364 - val_loss: 0.5602 - val_acc: 0.7418\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(512, input_dim=X.shape[1], activation=\"relu\",kernel_regularizer=l1_l2(l1=0.0000001,l2=0.0000001)))\n",
    "model.add(Dropout(0.1))\n",
    "model.add(Dense(256, activation=\"relu\",kernel_regularizer=l1_l2(l1=0.0000001,l2=0.0000001)))\n",
    "model.add(Dropout(0.1))\n",
    "model.add(Dense(1, activation=\"sigmoid\"))\n",
    "model.compile(optimizer='sgd', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "network_history=model.fit(X, Y,validation_data=(X_test,Y_test),batch_size=256 ,epochs=700)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 300
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 173177,
     "status": "ok",
     "timestamp": 1571503852730,
     "user": {
      "displayName": "Mirko Giugliano",
      "photoUrl": "",
      "userId": "07128242895425647455"
     },
     "user_tz": -120
    },
    "id": "frkln-7sypXB",
    "outputId": "8338197f-7e6c-48c3-b066-ea0e0042c8b7"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7f39a86e8128>"
      ]
     },
     "execution_count": 29,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYsAAAEKCAYAAADjDHn2AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "x_plot = list(range(1,701))\n",
    "plt.figure()\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.plot(x_plot, network_history.history['acc'])\n",
    "plt.plot(x_plot, network_history.history['val_acc'])\n",
    "plt.legend(['Training', 'Validation'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 170
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 173490,
     "status": "ok",
     "timestamp": 1571503853067,
     "user": {
      "displayName": "Mirko Giugliano",
      "photoUrl": "",
      "userId": "07128242895425647455"
     },
     "user_tz": -120
    },
    "id": "5vc55Wz_6faT",
    "outputId": "927535fb-6957-40b1-c294-36754fa4bfdb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "confusion matrix\n",
      " [[4051 1162]\n",
      " [ 581  956]]\n",
      "precision\n",
      " [0.87456822 0.45136922]\n",
      "recall\n",
      " [0.77709572 0.62199089]\n",
      "f-score\n",
      " [0.82295582 0.52311902]\n"
     ]
    }
   ],
   "source": [
    "y_pred=model.predict(X_test)\n",
    "y_pred=y_pred>0.5\n",
    "\n",
    "cm=confusion_matrix(Y_test,y_pred)\n",
    "prf=precision_recall_fscore_support(Y_test,y_pred)\n",
    "\n",
    "print(f\"confusion matrix\\n {cm}\")\n",
    "print(f\"precision\\n {prf[0]}\")\n",
    "print(f\"recall\\n {prf[1]}\")\n",
    "print(f\"f-score\\n {prf[2]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 170
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 173487,
     "status": "ok",
     "timestamp": 1571503853068,
     "user": {
      "displayName": "Mirko Giugliano",
      "photoUrl": "",
      "userId": "07128242895425647455"
     },
     "user_tz": -120
    },
    "id": "4ncVZAlv6g4h",
    "outputId": "8b0646bb-af14-4f7d-d6e4-d9b616fe3b08",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.78      0.82      5213\n",
      "           1       0.45      0.62      0.52      1537\n",
      "\n",
      "    accuracy                           0.74      6750\n",
      "   macro avg       0.66      0.70      0.67      6750\n",
      "weighted avg       0.78      0.74      0.75      6750\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cr=classification_report(Y_test, y_pred)\n",
    "print(cr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### creazione e valutazione modello 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zAqj1-Nf_WUS"
   },
   "outputs": [],
   "source": [
    "adam = optimizers.Adam()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 54079,
     "status": "ok",
     "timestamp": 1571504320276,
     "user": {
      "displayName": "Mirko Giugliano",
      "photoUrl": "",
      "userId": "07128242895425647455"
     },
     "user_tz": -120
    },
    "id": "ESothxoPqMc0",
    "outputId": "0cdf04df-9a23-43ed-8e18-f487330ebb26"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 8872 samples, validate on 6750 samples\n",
      "Epoch 1/400\n",
      "8872/8872 [==============================] - 1s 81us/step - loss: 0.6732 - acc: 0.5795 - val_loss: 0.6150 - val_acc: 0.6837\n",
      "Epoch 2/400\n",
      "8872/8872 [==============================] - 0s 16us/step - loss: 0.6053 - acc: 0.6779 - val_loss: 0.5944 - val_acc: 0.7816\n",
      "Epoch 3/400\n",
      "8872/8872 [==============================] - 0s 17us/step - loss: 0.5924 - acc: 0.6975 - val_loss: 0.5760 - val_acc: 0.7698\n",
      "Epoch 4/400\n",
      "8872/8872 [==============================] - 0s 14us/step - loss: 0.5864 - acc: 0.6983 - val_loss: 0.5646 - val_acc: 0.7713\n",
      "Epoch 5/400\n",
      "8872/8872 [==============================] - 0s 14us/step - loss: 0.5835 - acc: 0.6996 - val_loss: 0.5785 - val_acc: 0.7655\n",
      "Epoch 6/400\n",
      "8872/8872 [==============================] - 0s 14us/step - loss: 0.5793 - acc: 0.7006 - val_loss: 0.5752 - val_acc: 0.7628\n",
      "Epoch 7/400\n",
      "8872/8872 [==============================] - 0s 14us/step - loss: 0.5775 - acc: 0.7022 - val_loss: 0.5588 - val_acc: 0.7732\n",
      "Epoch 8/400\n",
      "8872/8872 [==============================] - 0s 14us/step - loss: 0.5764 - acc: 0.7037 - val_loss: 0.5533 - val_acc: 0.7747\n",
      "Epoch 9/400\n",
      "8872/8872 [==============================] - 0s 14us/step - loss: 0.5728 - acc: 0.7060 - val_loss: 0.5798 - val_acc: 0.7492\n",
      "Epoch 10/400\n",
      "8872/8872 [==============================] - 0s 14us/step - loss: 0.5728 - acc: 0.7071 - val_loss: 0.5648 - val_acc: 0.7655\n",
      "Epoch 11/400\n",
      "8872/8872 [==============================] - 0s 14us/step - loss: 0.5699 - acc: 0.7050 - val_loss: 0.5642 - val_acc: 0.7639\n",
      "Epoch 12/400\n",
      "8872/8872 [==============================] - 0s 14us/step - loss: 0.5697 - acc: 0.7032 - val_loss: 0.5510 - val_acc: 0.7665\n",
      "Epoch 13/400\n",
      "8872/8872 [==============================] - 0s 14us/step - loss: 0.5678 - acc: 0.7077 - val_loss: 0.5656 - val_acc: 0.7612\n",
      "Epoch 14/400\n",
      "8872/8872 [==============================] - 0s 14us/step - loss: 0.5683 - acc: 0.7111 - val_loss: 0.5614 - val_acc: 0.7578\n",
      "Epoch 15/400\n",
      "8872/8872 [==============================] - 0s 14us/step - loss: 0.5706 - acc: 0.7039 - val_loss: 0.5629 - val_acc: 0.7644\n",
      "Epoch 16/400\n",
      "8872/8872 [==============================] - 0s 15us/step - loss: 0.5646 - acc: 0.7093 - val_loss: 0.5683 - val_acc: 0.7553\n",
      "Epoch 17/400\n",
      "8872/8872 [==============================] - 0s 13us/step - loss: 0.5652 - acc: 0.7067 - val_loss: 0.5495 - val_acc: 0.7658\n",
      "Epoch 18/400\n",
      "8872/8872 [==============================] - 0s 15us/step - loss: 0.5651 - acc: 0.7106 - val_loss: 0.5756 - val_acc: 0.7501\n",
      "Epoch 19/400\n",
      "8872/8872 [==============================] - 0s 14us/step - loss: 0.5630 - acc: 0.7119 - val_loss: 0.5539 - val_acc: 0.7665\n",
      "Epoch 20/400\n",
      "8872/8872 [==============================] - 0s 15us/step - loss: 0.5657 - acc: 0.7094 - val_loss: 0.5553 - val_acc: 0.7616\n",
      "Epoch 21/400\n",
      "8872/8872 [==============================] - 0s 15us/step - loss: 0.5628 - acc: 0.7112 - val_loss: 0.5508 - val_acc: 0.7680\n",
      "Epoch 22/400\n",
      "8872/8872 [==============================] - 0s 16us/step - loss: 0.5617 - acc: 0.7142 - val_loss: 0.5726 - val_acc: 0.7468\n",
      "Epoch 23/400\n",
      "8872/8872 [==============================] - 0s 15us/step - loss: 0.5629 - acc: 0.7133 - val_loss: 0.5458 - val_acc: 0.7677\n",
      "Epoch 24/400\n",
      "8872/8872 [==============================] - 0s 16us/step - loss: 0.5598 - acc: 0.7137 - val_loss: 0.5716 - val_acc: 0.7468\n",
      "Epoch 25/400\n",
      "8872/8872 [==============================] - 0s 15us/step - loss: 0.5615 - acc: 0.7122 - val_loss: 0.5441 - val_acc: 0.7664\n",
      "Epoch 26/400\n",
      "8872/8872 [==============================] - 0s 14us/step - loss: 0.5614 - acc: 0.7134 - val_loss: 0.5549 - val_acc: 0.7627\n",
      "Epoch 27/400\n",
      "8872/8872 [==============================] - 0s 15us/step - loss: 0.5593 - acc: 0.7137 - val_loss: 0.5649 - val_acc: 0.7499\n",
      "Epoch 28/400\n",
      "8872/8872 [==============================] - 0s 14us/step - loss: 0.5591 - acc: 0.7157 - val_loss: 0.5592 - val_acc: 0.7569\n",
      "Epoch 29/400\n",
      "8872/8872 [==============================] - 0s 14us/step - loss: 0.5584 - acc: 0.7153 - val_loss: 0.5677 - val_acc: 0.7496\n",
      "Epoch 30/400\n",
      "8872/8872 [==============================] - 0s 13us/step - loss: 0.5583 - acc: 0.7122 - val_loss: 0.5499 - val_acc: 0.7637\n",
      "Epoch 31/400\n",
      "8872/8872 [==============================] - 0s 15us/step - loss: 0.5594 - acc: 0.7127 - val_loss: 0.5730 - val_acc: 0.7462\n",
      "Epoch 32/400\n",
      "8872/8872 [==============================] - 0s 14us/step - loss: 0.5602 - acc: 0.7107 - val_loss: 0.5507 - val_acc: 0.7582\n",
      "Epoch 33/400\n",
      "8872/8872 [==============================] - 0s 14us/step - loss: 0.5586 - acc: 0.7146 - val_loss: 0.5618 - val_acc: 0.7516\n",
      "Epoch 34/400\n",
      "8872/8872 [==============================] - 0s 14us/step - loss: 0.5573 - acc: 0.7184 - val_loss: 0.5616 - val_acc: 0.7492\n",
      "Epoch 35/400\n",
      "8872/8872 [==============================] - 0s 14us/step - loss: 0.5565 - acc: 0.7190 - val_loss: 0.5501 - val_acc: 0.7630\n",
      "Epoch 36/400\n",
      "8872/8872 [==============================] - 0s 15us/step - loss: 0.5557 - acc: 0.7139 - val_loss: 0.5592 - val_acc: 0.7541\n",
      "Epoch 37/400\n",
      "8872/8872 [==============================] - 0s 14us/step - loss: 0.5571 - acc: 0.7163 - val_loss: 0.5628 - val_acc: 0.7502\n",
      "Epoch 38/400\n",
      "8872/8872 [==============================] - 0s 14us/step - loss: 0.5568 - acc: 0.7181 - val_loss: 0.5599 - val_acc: 0.7513\n",
      "Epoch 39/400\n",
      "8872/8872 [==============================] - 0s 18us/step - loss: 0.5556 - acc: 0.7188 - val_loss: 0.5537 - val_acc: 0.7547\n",
      "Epoch 40/400\n",
      "8872/8872 [==============================] - 0s 14us/step - loss: 0.5557 - acc: 0.7151 - val_loss: 0.5632 - val_acc: 0.7517\n",
      "Epoch 41/400\n",
      "8872/8872 [==============================] - 0s 13us/step - loss: 0.5565 - acc: 0.7172 - val_loss: 0.5530 - val_acc: 0.7535\n",
      "Epoch 42/400\n",
      "8872/8872 [==============================] - 0s 14us/step - loss: 0.5563 - acc: 0.7192 - val_loss: 0.5572 - val_acc: 0.7517\n",
      "Epoch 43/400\n",
      "8872/8872 [==============================] - 0s 14us/step - loss: 0.5550 - acc: 0.7148 - val_loss: 0.5536 - val_acc: 0.7516\n",
      "Epoch 44/400\n",
      "8872/8872 [==============================] - 0s 14us/step - loss: 0.5562 - acc: 0.7158 - val_loss: 0.5559 - val_acc: 0.7530\n",
      "Epoch 45/400\n",
      "8872/8872 [==============================] - 0s 13us/step - loss: 0.5556 - acc: 0.7186 - val_loss: 0.5600 - val_acc: 0.7520\n",
      "Epoch 46/400\n",
      "8872/8872 [==============================] - 0s 13us/step - loss: 0.5541 - acc: 0.7187 - val_loss: 0.5549 - val_acc: 0.7533\n",
      "Epoch 47/400\n",
      "8872/8872 [==============================] - 0s 15us/step - loss: 0.5544 - acc: 0.7174 - val_loss: 0.5717 - val_acc: 0.7388\n",
      "Epoch 48/400\n",
      "8872/8872 [==============================] - 0s 14us/step - loss: 0.5541 - acc: 0.7184 - val_loss: 0.5508 - val_acc: 0.7551\n",
      "Epoch 49/400\n",
      "8872/8872 [==============================] - 0s 15us/step - loss: 0.5546 - acc: 0.7191 - val_loss: 0.5593 - val_acc: 0.7502\n",
      "Epoch 50/400\n",
      "8872/8872 [==============================] - 0s 13us/step - loss: 0.5536 - acc: 0.7200 - val_loss: 0.5639 - val_acc: 0.7467\n",
      "Epoch 51/400\n",
      "8872/8872 [==============================] - 0s 15us/step - loss: 0.5555 - acc: 0.7170 - val_loss: 0.5521 - val_acc: 0.7550\n",
      "Epoch 52/400\n",
      "8872/8872 [==============================] - 0s 15us/step - loss: 0.5526 - acc: 0.7187 - val_loss: 0.5618 - val_acc: 0.7499\n",
      "Epoch 53/400\n",
      "8872/8872 [==============================] - 0s 14us/step - loss: 0.5526 - acc: 0.7165 - val_loss: 0.5593 - val_acc: 0.7521\n",
      "Epoch 54/400\n",
      "8872/8872 [==============================] - 0s 14us/step - loss: 0.5556 - acc: 0.7161 - val_loss: 0.5568 - val_acc: 0.7510\n",
      "Epoch 55/400\n",
      "8872/8872 [==============================] - 0s 18us/step - loss: 0.5518 - acc: 0.7191 - val_loss: 0.5567 - val_acc: 0.7508\n",
      "Epoch 56/400\n",
      "8872/8872 [==============================] - 0s 16us/step - loss: 0.5536 - acc: 0.7191 - val_loss: 0.5605 - val_acc: 0.7519\n",
      "Epoch 57/400\n",
      "8872/8872 [==============================] - 0s 16us/step - loss: 0.5522 - acc: 0.7155 - val_loss: 0.5552 - val_acc: 0.7527\n",
      "Epoch 58/400\n",
      "8872/8872 [==============================] - 0s 15us/step - loss: 0.5539 - acc: 0.7173 - val_loss: 0.5532 - val_acc: 0.7521\n",
      "Epoch 59/400\n",
      "8872/8872 [==============================] - 0s 15us/step - loss: 0.5529 - acc: 0.7196 - val_loss: 0.5601 - val_acc: 0.7495\n",
      "Epoch 60/400\n",
      "8872/8872 [==============================] - 0s 14us/step - loss: 0.5516 - acc: 0.7201 - val_loss: 0.5577 - val_acc: 0.7516\n",
      "Epoch 61/400\n",
      "8872/8872 [==============================] - 0s 13us/step - loss: 0.5525 - acc: 0.7186 - val_loss: 0.5625 - val_acc: 0.7487\n",
      "Epoch 62/400\n",
      "8872/8872 [==============================] - 0s 15us/step - loss: 0.5514 - acc: 0.7215 - val_loss: 0.5628 - val_acc: 0.7453\n",
      "Epoch 63/400\n",
      "8872/8872 [==============================] - 0s 15us/step - loss: 0.5540 - acc: 0.7182 - val_loss: 0.5558 - val_acc: 0.7533\n",
      "Epoch 64/400\n",
      "8872/8872 [==============================] - 0s 14us/step - loss: 0.5512 - acc: 0.7207 - val_loss: 0.5561 - val_acc: 0.7510\n",
      "Epoch 65/400\n",
      "8872/8872 [==============================] - 0s 13us/step - loss: 0.5518 - acc: 0.7191 - val_loss: 0.5601 - val_acc: 0.7486\n",
      "Epoch 66/400\n",
      "8872/8872 [==============================] - 0s 14us/step - loss: 0.5532 - acc: 0.7136 - val_loss: 0.5587 - val_acc: 0.7492\n",
      "Epoch 67/400\n",
      "8872/8872 [==============================] - 0s 14us/step - loss: 0.5524 - acc: 0.7213 - val_loss: 0.5582 - val_acc: 0.7487\n",
      "Epoch 68/400\n",
      "8872/8872 [==============================] - 0s 15us/step - loss: 0.5515 - acc: 0.7169 - val_loss: 0.5567 - val_acc: 0.7479\n",
      "Epoch 69/400\n",
      "8872/8872 [==============================] - 0s 14us/step - loss: 0.5510 - acc: 0.7225 - val_loss: 0.5629 - val_acc: 0.7467\n",
      "Epoch 70/400\n",
      "8872/8872 [==============================] - 0s 15us/step - loss: 0.5513 - acc: 0.7201 - val_loss: 0.5529 - val_acc: 0.7504\n",
      "Epoch 71/400\n",
      "8872/8872 [==============================] - 0s 14us/step - loss: 0.5513 - acc: 0.7227 - val_loss: 0.5582 - val_acc: 0.7467\n",
      "Epoch 72/400\n",
      "8872/8872 [==============================] - 0s 13us/step - loss: 0.5482 - acc: 0.7204 - val_loss: 0.5641 - val_acc: 0.7413\n",
      "Epoch 73/400\n",
      "8872/8872 [==============================] - 0s 16us/step - loss: 0.5499 - acc: 0.7202 - val_loss: 0.5516 - val_acc: 0.7535\n",
      "Epoch 74/400\n",
      "8872/8872 [==============================] - 0s 14us/step - loss: 0.5509 - acc: 0.7209 - val_loss: 0.5608 - val_acc: 0.7449\n",
      "Epoch 75/400\n",
      "8872/8872 [==============================] - 0s 14us/step - loss: 0.5493 - acc: 0.7175 - val_loss: 0.5629 - val_acc: 0.7406\n",
      "Epoch 76/400\n",
      "8872/8872 [==============================] - 0s 13us/step - loss: 0.5533 - acc: 0.7189 - val_loss: 0.5588 - val_acc: 0.7458\n",
      "Epoch 77/400\n",
      "8872/8872 [==============================] - 0s 14us/step - loss: 0.5499 - acc: 0.7162 - val_loss: 0.5601 - val_acc: 0.7430\n",
      "Epoch 78/400\n",
      "8872/8872 [==============================] - 0s 14us/step - loss: 0.5488 - acc: 0.7215 - val_loss: 0.5611 - val_acc: 0.7443\n",
      "Epoch 79/400\n",
      "8872/8872 [==============================] - 0s 14us/step - loss: 0.5514 - acc: 0.7196 - val_loss: 0.5533 - val_acc: 0.7505\n",
      "Epoch 80/400\n",
      "8872/8872 [==============================] - 0s 13us/step - loss: 0.5506 - acc: 0.7170 - val_loss: 0.5657 - val_acc: 0.7428\n",
      "Epoch 81/400\n",
      "8872/8872 [==============================] - 0s 13us/step - loss: 0.5511 - acc: 0.7188 - val_loss: 0.5571 - val_acc: 0.7452\n",
      "Epoch 82/400\n",
      "8872/8872 [==============================] - 0s 14us/step - loss: 0.5481 - acc: 0.7236 - val_loss: 0.5577 - val_acc: 0.7462\n",
      "Epoch 83/400\n",
      "8872/8872 [==============================] - 0s 13us/step - loss: 0.5505 - acc: 0.7181 - val_loss: 0.5577 - val_acc: 0.7473\n",
      "Epoch 84/400\n",
      "8872/8872 [==============================] - 0s 13us/step - loss: 0.5514 - acc: 0.7193 - val_loss: 0.5661 - val_acc: 0.7400\n",
      "Epoch 85/400\n",
      "8872/8872 [==============================] - 0s 13us/step - loss: 0.5504 - acc: 0.7222 - val_loss: 0.5579 - val_acc: 0.7458\n",
      "Epoch 86/400\n",
      "8872/8872 [==============================] - 0s 15us/step - loss: 0.5506 - acc: 0.7209 - val_loss: 0.5557 - val_acc: 0.7458\n",
      "Epoch 87/400\n",
      "8872/8872 [==============================] - 0s 15us/step - loss: 0.5517 - acc: 0.7186 - val_loss: 0.5681 - val_acc: 0.7359\n",
      "Epoch 88/400\n",
      "8872/8872 [==============================] - 0s 13us/step - loss: 0.5465 - acc: 0.7219 - val_loss: 0.5538 - val_acc: 0.7471\n",
      "Epoch 89/400\n",
      "8872/8872 [==============================] - 0s 15us/step - loss: 0.5492 - acc: 0.7254 - val_loss: 0.5641 - val_acc: 0.7419\n",
      "Epoch 90/400\n",
      "8872/8872 [==============================] - 0s 15us/step - loss: 0.5483 - acc: 0.7210 - val_loss: 0.5586 - val_acc: 0.7444\n",
      "Epoch 91/400\n",
      "8872/8872 [==============================] - 0s 16us/step - loss: 0.5489 - acc: 0.7224 - val_loss: 0.5619 - val_acc: 0.7421\n",
      "Epoch 92/400\n",
      "8872/8872 [==============================] - 0s 16us/step - loss: 0.5492 - acc: 0.7206 - val_loss: 0.5657 - val_acc: 0.7401\n",
      "Epoch 93/400\n",
      "8872/8872 [==============================] - 0s 14us/step - loss: 0.5483 - acc: 0.7224 - val_loss: 0.5583 - val_acc: 0.7440\n",
      "Epoch 94/400\n",
      "8872/8872 [==============================] - 0s 14us/step - loss: 0.5479 - acc: 0.7236 - val_loss: 0.5607 - val_acc: 0.7421\n",
      "Epoch 95/400\n",
      "8872/8872 [==============================] - 0s 14us/step - loss: 0.5488 - acc: 0.7211 - val_loss: 0.5680 - val_acc: 0.7342\n",
      "Epoch 96/400\n",
      "8872/8872 [==============================] - 0s 15us/step - loss: 0.5488 - acc: 0.7219 - val_loss: 0.5555 - val_acc: 0.7447\n",
      "Epoch 97/400\n",
      "8872/8872 [==============================] - 0s 13us/step - loss: 0.5454 - acc: 0.7201 - val_loss: 0.5638 - val_acc: 0.7400\n",
      "Epoch 98/400\n",
      "8872/8872 [==============================] - 0s 13us/step - loss: 0.5495 - acc: 0.7179 - val_loss: 0.5641 - val_acc: 0.7378\n",
      "Epoch 99/400\n",
      "8872/8872 [==============================] - 0s 13us/step - loss: 0.5469 - acc: 0.7236 - val_loss: 0.5584 - val_acc: 0.7427\n",
      "Epoch 100/400\n",
      "8872/8872 [==============================] - 0s 13us/step - loss: 0.5483 - acc: 0.7215 - val_loss: 0.5598 - val_acc: 0.7447\n",
      "Epoch 101/400\n",
      "8872/8872 [==============================] - 0s 14us/step - loss: 0.5466 - acc: 0.7207 - val_loss: 0.5541 - val_acc: 0.7450\n",
      "Epoch 102/400\n",
      "8872/8872 [==============================] - 0s 14us/step - loss: 0.5497 - acc: 0.7217 - val_loss: 0.5649 - val_acc: 0.7360\n",
      "Epoch 103/400\n",
      "8872/8872 [==============================] - 0s 14us/step - loss: 0.5465 - acc: 0.7213 - val_loss: 0.5672 - val_acc: 0.7356\n",
      "Epoch 104/400\n",
      "8872/8872 [==============================] - 0s 15us/step - loss: 0.5475 - acc: 0.7222 - val_loss: 0.5610 - val_acc: 0.7397\n",
      "Epoch 105/400\n",
      "8872/8872 [==============================] - 0s 14us/step - loss: 0.5469 - acc: 0.7227 - val_loss: 0.5605 - val_acc: 0.7440\n",
      "Epoch 106/400\n",
      "8872/8872 [==============================] - 0s 14us/step - loss: 0.5483 - acc: 0.7200 - val_loss: 0.5584 - val_acc: 0.7433\n",
      "Epoch 107/400\n",
      "8872/8872 [==============================] - 0s 13us/step - loss: 0.5472 - acc: 0.7232 - val_loss: 0.5594 - val_acc: 0.7444\n",
      "Epoch 108/400\n",
      "8872/8872 [==============================] - 0s 14us/step - loss: 0.5474 - acc: 0.7209 - val_loss: 0.5544 - val_acc: 0.7470\n",
      "Epoch 109/400\n",
      "8872/8872 [==============================] - 0s 13us/step - loss: 0.5455 - acc: 0.7233 - val_loss: 0.5631 - val_acc: 0.7378\n",
      "Epoch 110/400\n",
      "8872/8872 [==============================] - 0s 14us/step - loss: 0.5478 - acc: 0.7209 - val_loss: 0.5633 - val_acc: 0.7399\n",
      "Epoch 111/400\n",
      "8872/8872 [==============================] - 0s 14us/step - loss: 0.5485 - acc: 0.7183 - val_loss: 0.5596 - val_acc: 0.7418\n",
      "Epoch 112/400\n",
      "8872/8872 [==============================] - 0s 14us/step - loss: 0.5444 - acc: 0.7254 - val_loss: 0.5646 - val_acc: 0.7370\n",
      "Epoch 113/400\n",
      "8872/8872 [==============================] - 0s 15us/step - loss: 0.5461 - acc: 0.7241 - val_loss: 0.5620 - val_acc: 0.7391\n",
      "Epoch 114/400\n",
      "8872/8872 [==============================] - 0s 13us/step - loss: 0.5483 - acc: 0.7198 - val_loss: 0.5615 - val_acc: 0.7418\n",
      "Epoch 115/400\n",
      "8872/8872 [==============================] - 0s 14us/step - loss: 0.5465 - acc: 0.7245 - val_loss: 0.5601 - val_acc: 0.7424\n",
      "Epoch 116/400\n",
      "8872/8872 [==============================] - 0s 14us/step - loss: 0.5451 - acc: 0.7261 - val_loss: 0.5554 - val_acc: 0.7459\n",
      "Epoch 117/400\n",
      "8872/8872 [==============================] - 0s 13us/step - loss: 0.5445 - acc: 0.7260 - val_loss: 0.5629 - val_acc: 0.7378\n",
      "Epoch 118/400\n",
      "8872/8872 [==============================] - 0s 14us/step - loss: 0.5445 - acc: 0.7211 - val_loss: 0.5582 - val_acc: 0.7431\n",
      "Epoch 119/400\n",
      "8872/8872 [==============================] - 0s 16us/step - loss: 0.5452 - acc: 0.7223 - val_loss: 0.5693 - val_acc: 0.7307\n",
      "Epoch 120/400\n",
      "8872/8872 [==============================] - 0s 17us/step - loss: 0.5471 - acc: 0.7193 - val_loss: 0.5533 - val_acc: 0.7467\n",
      "Epoch 121/400\n",
      "8872/8872 [==============================] - 0s 14us/step - loss: 0.5434 - acc: 0.7219 - val_loss: 0.5648 - val_acc: 0.7351\n",
      "Epoch 122/400\n",
      "8872/8872 [==============================] - 0s 13us/step - loss: 0.5435 - acc: 0.7254 - val_loss: 0.5614 - val_acc: 0.7404\n",
      "Epoch 123/400\n",
      "8872/8872 [==============================] - 0s 14us/step - loss: 0.5427 - acc: 0.7242 - val_loss: 0.5690 - val_acc: 0.7330\n",
      "Epoch 124/400\n",
      "8872/8872 [==============================] - 0s 14us/step - loss: 0.5452 - acc: 0.7240 - val_loss: 0.5541 - val_acc: 0.7476\n",
      "Epoch 125/400\n",
      "8872/8872 [==============================] - 0s 14us/step - loss: 0.5432 - acc: 0.7239 - val_loss: 0.5743 - val_acc: 0.7298\n",
      "Epoch 126/400\n",
      "8872/8872 [==============================] - 0s 13us/step - loss: 0.5433 - acc: 0.7244 - val_loss: 0.5575 - val_acc: 0.7418\n",
      "Epoch 127/400\n",
      "8872/8872 [==============================] - 0s 14us/step - loss: 0.5446 - acc: 0.7224 - val_loss: 0.5614 - val_acc: 0.7384\n",
      "Epoch 128/400\n",
      "8872/8872 [==============================] - 0s 14us/step - loss: 0.5435 - acc: 0.7259 - val_loss: 0.5620 - val_acc: 0.7387\n",
      "Epoch 129/400\n",
      "8872/8872 [==============================] - 0s 14us/step - loss: 0.5462 - acc: 0.7223 - val_loss: 0.5610 - val_acc: 0.7373\n",
      "Epoch 130/400\n",
      "8872/8872 [==============================] - 0s 17us/step - loss: 0.5446 - acc: 0.7264 - val_loss: 0.5580 - val_acc: 0.7456\n",
      "Epoch 131/400\n",
      "8872/8872 [==============================] - 0s 15us/step - loss: 0.5462 - acc: 0.7204 - val_loss: 0.5641 - val_acc: 0.7372\n",
      "Epoch 132/400\n",
      "8872/8872 [==============================] - 0s 15us/step - loss: 0.5439 - acc: 0.7225 - val_loss: 0.5657 - val_acc: 0.7357\n",
      "Epoch 133/400\n",
      "8872/8872 [==============================] - 0s 14us/step - loss: 0.5443 - acc: 0.7228 - val_loss: 0.5603 - val_acc: 0.7407\n",
      "Epoch 134/400\n",
      "8872/8872 [==============================] - 0s 18us/step - loss: 0.5402 - acc: 0.7257 - val_loss: 0.5640 - val_acc: 0.7373\n",
      "Epoch 135/400\n",
      "8872/8872 [==============================] - 0s 15us/step - loss: 0.5418 - acc: 0.7273 - val_loss: 0.5652 - val_acc: 0.7361\n",
      "Epoch 136/400\n",
      "8872/8872 [==============================] - 0s 14us/step - loss: 0.5432 - acc: 0.7280 - val_loss: 0.5621 - val_acc: 0.7387\n",
      "Epoch 137/400\n",
      "8872/8872 [==============================] - 0s 17us/step - loss: 0.5430 - acc: 0.7261 - val_loss: 0.5607 - val_acc: 0.7404\n",
      "Epoch 138/400\n",
      "8872/8872 [==============================] - 0s 16us/step - loss: 0.5430 - acc: 0.7271 - val_loss: 0.5654 - val_acc: 0.7353\n",
      "Epoch 139/400\n",
      "8872/8872 [==============================] - 0s 15us/step - loss: 0.5423 - acc: 0.7229 - val_loss: 0.5605 - val_acc: 0.7384\n",
      "Epoch 140/400\n",
      "8872/8872 [==============================] - 0s 13us/step - loss: 0.5430 - acc: 0.7240 - val_loss: 0.5619 - val_acc: 0.7379\n",
      "Epoch 141/400\n",
      "8872/8872 [==============================] - 0s 14us/step - loss: 0.5436 - acc: 0.7245 - val_loss: 0.5665 - val_acc: 0.7347\n",
      "Epoch 142/400\n",
      "8872/8872 [==============================] - 0s 15us/step - loss: 0.5439 - acc: 0.7260 - val_loss: 0.5601 - val_acc: 0.7381\n",
      "Epoch 143/400\n",
      "8872/8872 [==============================] - 0s 13us/step - loss: 0.5416 - acc: 0.7275 - val_loss: 0.5614 - val_acc: 0.7407\n",
      "Epoch 144/400\n",
      "8872/8872 [==============================] - 0s 18us/step - loss: 0.5421 - acc: 0.7244 - val_loss: 0.5648 - val_acc: 0.7364\n",
      "Epoch 145/400\n",
      "8872/8872 [==============================] - 0s 15us/step - loss: 0.5428 - acc: 0.7232 - val_loss: 0.5573 - val_acc: 0.7431\n",
      "Epoch 146/400\n",
      "8872/8872 [==============================] - 0s 14us/step - loss: 0.5470 - acc: 0.7193 - val_loss: 0.5630 - val_acc: 0.7356\n",
      "Epoch 147/400\n",
      "8872/8872 [==============================] - 0s 15us/step - loss: 0.5435 - acc: 0.7259 - val_loss: 0.5638 - val_acc: 0.7364\n",
      "Epoch 148/400\n",
      "8872/8872 [==============================] - 0s 16us/step - loss: 0.5436 - acc: 0.7223 - val_loss: 0.5645 - val_acc: 0.7364\n",
      "Epoch 149/400\n",
      "8872/8872 [==============================] - 0s 18us/step - loss: 0.5438 - acc: 0.7249 - val_loss: 0.5654 - val_acc: 0.7327\n",
      "Epoch 150/400\n",
      "8872/8872 [==============================] - 0s 15us/step - loss: 0.5429 - acc: 0.7224 - val_loss: 0.5605 - val_acc: 0.7387\n",
      "Epoch 151/400\n",
      "8872/8872 [==============================] - 0s 13us/step - loss: 0.5420 - acc: 0.7251 - val_loss: 0.5682 - val_acc: 0.7317\n",
      "Epoch 152/400\n",
      "8872/8872 [==============================] - 0s 13us/step - loss: 0.5403 - acc: 0.7316 - val_loss: 0.5598 - val_acc: 0.7403\n",
      "Epoch 153/400\n",
      "8872/8872 [==============================] - 0s 14us/step - loss: 0.5422 - acc: 0.7263 - val_loss: 0.5663 - val_acc: 0.7338\n",
      "Epoch 154/400\n",
      "8872/8872 [==============================] - 0s 13us/step - loss: 0.5426 - acc: 0.7272 - val_loss: 0.5654 - val_acc: 0.7345\n",
      "Epoch 155/400\n",
      "8872/8872 [==============================] - 0s 13us/step - loss: 0.5449 - acc: 0.7217 - val_loss: 0.5583 - val_acc: 0.7410\n",
      "Epoch 156/400\n",
      "8872/8872 [==============================] - 0s 13us/step - loss: 0.5446 - acc: 0.7244 - val_loss: 0.5610 - val_acc: 0.7388\n",
      "Epoch 157/400\n",
      "8872/8872 [==============================] - 0s 15us/step - loss: 0.5404 - acc: 0.7263 - val_loss: 0.5637 - val_acc: 0.7363\n",
      "Epoch 158/400\n",
      "8872/8872 [==============================] - 0s 17us/step - loss: 0.5430 - acc: 0.7205 - val_loss: 0.5559 - val_acc: 0.7404\n",
      "Epoch 159/400\n",
      "8872/8872 [==============================] - 0s 16us/step - loss: 0.5429 - acc: 0.7208 - val_loss: 0.5720 - val_acc: 0.7287\n",
      "Epoch 160/400\n",
      "8872/8872 [==============================] - 0s 16us/step - loss: 0.5425 - acc: 0.7236 - val_loss: 0.5621 - val_acc: 0.7356\n",
      "Epoch 161/400\n",
      "8872/8872 [==============================] - 0s 16us/step - loss: 0.5407 - acc: 0.7254 - val_loss: 0.5628 - val_acc: 0.7369\n",
      "Epoch 162/400\n",
      "8872/8872 [==============================] - 0s 14us/step - loss: 0.5418 - acc: 0.7244 - val_loss: 0.5637 - val_acc: 0.7354\n",
      "Epoch 163/400\n",
      "8872/8872 [==============================] - 0s 15us/step - loss: 0.5415 - acc: 0.7244 - val_loss: 0.5618 - val_acc: 0.7373\n",
      "Epoch 164/400\n",
      "8872/8872 [==============================] - 0s 15us/step - loss: 0.5405 - acc: 0.7241 - val_loss: 0.5715 - val_acc: 0.7271\n",
      "Epoch 165/400\n",
      "8872/8872 [==============================] - 0s 15us/step - loss: 0.5415 - acc: 0.7225 - val_loss: 0.5638 - val_acc: 0.7330\n",
      "Epoch 166/400\n",
      "8872/8872 [==============================] - 0s 14us/step - loss: 0.5439 - acc: 0.7234 - val_loss: 0.5633 - val_acc: 0.7370\n",
      "Epoch 167/400\n",
      "8872/8872 [==============================] - 0s 14us/step - loss: 0.5415 - acc: 0.7267 - val_loss: 0.5571 - val_acc: 0.7422\n",
      "Epoch 168/400\n",
      "8872/8872 [==============================] - 0s 15us/step - loss: 0.5404 - acc: 0.7255 - val_loss: 0.5689 - val_acc: 0.7299\n",
      "Epoch 169/400\n",
      "8872/8872 [==============================] - 0s 14us/step - loss: 0.5412 - acc: 0.7268 - val_loss: 0.5617 - val_acc: 0.7370\n",
      "Epoch 170/400\n",
      "8872/8872 [==============================] - 0s 14us/step - loss: 0.5414 - acc: 0.7243 - val_loss: 0.5666 - val_acc: 0.7330\n",
      "Epoch 171/400\n",
      "8872/8872 [==============================] - 0s 13us/step - loss: 0.5403 - acc: 0.7269 - val_loss: 0.5574 - val_acc: 0.7391\n",
      "Epoch 172/400\n",
      "8872/8872 [==============================] - 0s 14us/step - loss: 0.5411 - acc: 0.7287 - val_loss: 0.5688 - val_acc: 0.7307\n",
      "Epoch 173/400\n",
      "8872/8872 [==============================] - 0s 14us/step - loss: 0.5420 - acc: 0.7252 - val_loss: 0.5574 - val_acc: 0.7404\n",
      "Epoch 174/400\n",
      "8872/8872 [==============================] - 0s 17us/step - loss: 0.5384 - acc: 0.7268 - val_loss: 0.5630 - val_acc: 0.7339\n",
      "Epoch 175/400\n",
      "8872/8872 [==============================] - 0s 16us/step - loss: 0.5386 - acc: 0.7280 - val_loss: 0.5686 - val_acc: 0.7304\n",
      "Epoch 176/400\n",
      "8872/8872 [==============================] - 0s 15us/step - loss: 0.5412 - acc: 0.7248 - val_loss: 0.5606 - val_acc: 0.7384\n",
      "Epoch 177/400\n",
      "8872/8872 [==============================] - 0s 15us/step - loss: 0.5401 - acc: 0.7270 - val_loss: 0.5729 - val_acc: 0.7259\n",
      "Epoch 178/400\n",
      "8872/8872 [==============================] - 0s 14us/step - loss: 0.5394 - acc: 0.7269 - val_loss: 0.5578 - val_acc: 0.7410\n",
      "Epoch 179/400\n",
      "8872/8872 [==============================] - 0s 14us/step - loss: 0.5396 - acc: 0.7222 - val_loss: 0.5688 - val_acc: 0.7326\n",
      "Epoch 180/400\n",
      "8872/8872 [==============================] - 0s 13us/step - loss: 0.5373 - acc: 0.7271 - val_loss: 0.5584 - val_acc: 0.7394\n",
      "Epoch 181/400\n",
      "8872/8872 [==============================] - 0s 15us/step - loss: 0.5384 - acc: 0.7255 - val_loss: 0.5664 - val_acc: 0.7332\n",
      "Epoch 182/400\n",
      "8872/8872 [==============================] - 0s 14us/step - loss: 0.5417 - acc: 0.7257 - val_loss: 0.5645 - val_acc: 0.7329\n",
      "Epoch 183/400\n",
      "8872/8872 [==============================] - 0s 14us/step - loss: 0.5402 - acc: 0.7288 - val_loss: 0.5691 - val_acc: 0.7345\n",
      "Epoch 184/400\n",
      "8872/8872 [==============================] - 0s 15us/step - loss: 0.5403 - acc: 0.7269 - val_loss: 0.5630 - val_acc: 0.7356\n",
      "Epoch 185/400\n",
      "8872/8872 [==============================] - 0s 14us/step - loss: 0.5412 - acc: 0.7261 - val_loss: 0.5669 - val_acc: 0.7332\n",
      "Epoch 186/400\n",
      "8872/8872 [==============================] - 0s 14us/step - loss: 0.5401 - acc: 0.7285 - val_loss: 0.5607 - val_acc: 0.7409\n",
      "Epoch 187/400\n",
      "8872/8872 [==============================] - 0s 15us/step - loss: 0.5403 - acc: 0.7237 - val_loss: 0.5755 - val_acc: 0.7261\n",
      "Epoch 188/400\n",
      "8872/8872 [==============================] - 0s 14us/step - loss: 0.5411 - acc: 0.7263 - val_loss: 0.5595 - val_acc: 0.7418\n",
      "Epoch 189/400\n",
      "8872/8872 [==============================] - 0s 15us/step - loss: 0.5408 - acc: 0.7254 - val_loss: 0.5618 - val_acc: 0.7382\n",
      "Epoch 190/400\n",
      "8872/8872 [==============================] - 0s 16us/step - loss: 0.5403 - acc: 0.7267 - val_loss: 0.5666 - val_acc: 0.7326\n",
      "Epoch 191/400\n",
      "8872/8872 [==============================] - 0s 16us/step - loss: 0.5369 - acc: 0.7267 - val_loss: 0.5597 - val_acc: 0.7373\n",
      "Epoch 192/400\n",
      "8872/8872 [==============================] - 0s 16us/step - loss: 0.5375 - acc: 0.7275 - val_loss: 0.5681 - val_acc: 0.7326\n",
      "Epoch 193/400\n",
      "8872/8872 [==============================] - 0s 15us/step - loss: 0.5387 - acc: 0.7263 - val_loss: 0.5626 - val_acc: 0.7379\n",
      "Epoch 194/400\n",
      "8872/8872 [==============================] - 0s 14us/step - loss: 0.5407 - acc: 0.7275 - val_loss: 0.5683 - val_acc: 0.7323\n",
      "Epoch 195/400\n",
      "8872/8872 [==============================] - 0s 14us/step - loss: 0.5393 - acc: 0.7269 - val_loss: 0.5610 - val_acc: 0.7373\n",
      "Epoch 196/400\n",
      "8872/8872 [==============================] - 0s 16us/step - loss: 0.5401 - acc: 0.7293 - val_loss: 0.5700 - val_acc: 0.7302\n",
      "Epoch 197/400\n",
      "8872/8872 [==============================] - 0s 15us/step - loss: 0.5387 - acc: 0.7285 - val_loss: 0.5669 - val_acc: 0.7338\n",
      "Epoch 198/400\n",
      "8872/8872 [==============================] - 0s 16us/step - loss: 0.5367 - acc: 0.7316 - val_loss: 0.5621 - val_acc: 0.7387\n",
      "Epoch 199/400\n",
      "8872/8872 [==============================] - 0s 16us/step - loss: 0.5392 - acc: 0.7278 - val_loss: 0.5719 - val_acc: 0.7276\n",
      "Epoch 200/400\n",
      "8872/8872 [==============================] - 0s 15us/step - loss: 0.5368 - acc: 0.7280 - val_loss: 0.5691 - val_acc: 0.7369\n",
      "Epoch 201/400\n",
      "8872/8872 [==============================] - 0s 14us/step - loss: 0.5379 - acc: 0.7295 - val_loss: 0.5629 - val_acc: 0.7385\n",
      "Epoch 202/400\n",
      "8872/8872 [==============================] - 0s 14us/step - loss: 0.5405 - acc: 0.7254 - val_loss: 0.5639 - val_acc: 0.7321\n",
      "Epoch 203/400\n",
      "8872/8872 [==============================] - 0s 15us/step - loss: 0.5391 - acc: 0.7237 - val_loss: 0.5679 - val_acc: 0.7329\n",
      "Epoch 204/400\n",
      "8872/8872 [==============================] - 0s 16us/step - loss: 0.5406 - acc: 0.7258 - val_loss: 0.5640 - val_acc: 0.7342\n",
      "Epoch 205/400\n",
      "8872/8872 [==============================] - 0s 15us/step - loss: 0.5399 - acc: 0.7291 - val_loss: 0.5702 - val_acc: 0.7304\n",
      "Epoch 206/400\n",
      "8872/8872 [==============================] - 0s 14us/step - loss: 0.5384 - acc: 0.7285 - val_loss: 0.5640 - val_acc: 0.7381\n",
      "Epoch 207/400\n",
      "8872/8872 [==============================] - 0s 14us/step - loss: 0.5371 - acc: 0.7288 - val_loss: 0.5677 - val_acc: 0.7348\n",
      "Epoch 208/400\n",
      "8872/8872 [==============================] - 0s 13us/step - loss: 0.5390 - acc: 0.7285 - val_loss: 0.5612 - val_acc: 0.7404\n",
      "Epoch 209/400\n",
      "8872/8872 [==============================] - 0s 14us/step - loss: 0.5385 - acc: 0.7262 - val_loss: 0.5682 - val_acc: 0.7330\n",
      "Epoch 210/400\n",
      "8872/8872 [==============================] - 0s 14us/step - loss: 0.5385 - acc: 0.7260 - val_loss: 0.5683 - val_acc: 0.7324\n",
      "Epoch 211/400\n",
      "8872/8872 [==============================] - 0s 17us/step - loss: 0.5392 - acc: 0.7266 - val_loss: 0.5626 - val_acc: 0.7375\n",
      "Epoch 212/400\n",
      "8872/8872 [==============================] - 0s 14us/step - loss: 0.5372 - acc: 0.7299 - val_loss: 0.5664 - val_acc: 0.7317\n",
      "Epoch 213/400\n",
      "8872/8872 [==============================] - 0s 15us/step - loss: 0.5391 - acc: 0.7273 - val_loss: 0.5754 - val_acc: 0.7279\n",
      "Epoch 214/400\n",
      "8872/8872 [==============================] - 0s 15us/step - loss: 0.5368 - acc: 0.7295 - val_loss: 0.5570 - val_acc: 0.7422\n",
      "Epoch 215/400\n",
      "8872/8872 [==============================] - 0s 14us/step - loss: 0.5387 - acc: 0.7290 - val_loss: 0.5625 - val_acc: 0.7367\n",
      "Epoch 216/400\n",
      "8872/8872 [==============================] - 0s 14us/step - loss: 0.5368 - acc: 0.7297 - val_loss: 0.5680 - val_acc: 0.7354\n",
      "Epoch 217/400\n",
      "8872/8872 [==============================] - 0s 13us/step - loss: 0.5406 - acc: 0.7235 - val_loss: 0.5638 - val_acc: 0.7348\n",
      "Epoch 218/400\n",
      "8872/8872 [==============================] - 0s 15us/step - loss: 0.5403 - acc: 0.7250 - val_loss: 0.5679 - val_acc: 0.7326\n",
      "Epoch 219/400\n",
      "8872/8872 [==============================] - 0s 14us/step - loss: 0.5364 - acc: 0.7258 - val_loss: 0.5587 - val_acc: 0.7410\n",
      "Epoch 220/400\n",
      "8872/8872 [==============================] - 0s 13us/step - loss: 0.5388 - acc: 0.7288 - val_loss: 0.5665 - val_acc: 0.7359\n",
      "Epoch 221/400\n",
      "8872/8872 [==============================] - 0s 13us/step - loss: 0.5366 - acc: 0.7293 - val_loss: 0.5667 - val_acc: 0.7317\n",
      "Epoch 222/400\n",
      "8872/8872 [==============================] - 0s 14us/step - loss: 0.5337 - acc: 0.7280 - val_loss: 0.5660 - val_acc: 0.7345\n",
      "Epoch 223/400\n",
      "8872/8872 [==============================] - 0s 13us/step - loss: 0.5383 - acc: 0.7291 - val_loss: 0.5713 - val_acc: 0.7326\n",
      "Epoch 224/400\n",
      "8872/8872 [==============================] - 0s 13us/step - loss: 0.5365 - acc: 0.7293 - val_loss: 0.5644 - val_acc: 0.7373\n",
      "Epoch 225/400\n",
      "8872/8872 [==============================] - 0s 14us/step - loss: 0.5391 - acc: 0.7270 - val_loss: 0.5688 - val_acc: 0.7313\n",
      "Epoch 226/400\n",
      "8872/8872 [==============================] - 0s 15us/step - loss: 0.5382 - acc: 0.7250 - val_loss: 0.5667 - val_acc: 0.7359\n",
      "Epoch 227/400\n",
      "8872/8872 [==============================] - 0s 14us/step - loss: 0.5362 - acc: 0.7295 - val_loss: 0.5639 - val_acc: 0.7376\n",
      "Epoch 228/400\n",
      "8872/8872 [==============================] - 0s 15us/step - loss: 0.5381 - acc: 0.7267 - val_loss: 0.5666 - val_acc: 0.7364\n",
      "Epoch 229/400\n",
      "8872/8872 [==============================] - 0s 13us/step - loss: 0.5360 - acc: 0.7294 - val_loss: 0.5679 - val_acc: 0.7335\n",
      "Epoch 230/400\n",
      "8872/8872 [==============================] - 0s 14us/step - loss: 0.5387 - acc: 0.7227 - val_loss: 0.5593 - val_acc: 0.7419\n",
      "Epoch 231/400\n",
      "8872/8872 [==============================] - 0s 13us/step - loss: 0.5376 - acc: 0.7248 - val_loss: 0.5663 - val_acc: 0.7350\n",
      "Epoch 232/400\n",
      "8872/8872 [==============================] - 0s 13us/step - loss: 0.5368 - acc: 0.7269 - val_loss: 0.5650 - val_acc: 0.7381\n",
      "Epoch 233/400\n",
      "8872/8872 [==============================] - 0s 14us/step - loss: 0.5357 - acc: 0.7333 - val_loss: 0.5699 - val_acc: 0.7356\n",
      "Epoch 234/400\n",
      "8872/8872 [==============================] - 0s 13us/step - loss: 0.5356 - acc: 0.7302 - val_loss: 0.5586 - val_acc: 0.7419\n",
      "Epoch 235/400\n",
      "8872/8872 [==============================] - 0s 14us/step - loss: 0.5356 - acc: 0.7294 - val_loss: 0.5671 - val_acc: 0.7330\n",
      "Epoch 236/400\n",
      "8872/8872 [==============================] - 0s 15us/step - loss: 0.5372 - acc: 0.7317 - val_loss: 0.5632 - val_acc: 0.7370\n",
      "Epoch 237/400\n",
      "8872/8872 [==============================] - 0s 15us/step - loss: 0.5335 - acc: 0.7282 - val_loss: 0.5745 - val_acc: 0.7295\n",
      "Epoch 238/400\n",
      "8872/8872 [==============================] - 0s 15us/step - loss: 0.5391 - acc: 0.7276 - val_loss: 0.5690 - val_acc: 0.7313\n",
      "Epoch 239/400\n",
      "8872/8872 [==============================] - 0s 13us/step - loss: 0.5356 - acc: 0.7293 - val_loss: 0.5566 - val_acc: 0.7419\n",
      "Epoch 240/400\n",
      "8872/8872 [==============================] - 0s 14us/step - loss: 0.5358 - acc: 0.7298 - val_loss: 0.5681 - val_acc: 0.7332\n",
      "Epoch 241/400\n",
      "8872/8872 [==============================] - 0s 14us/step - loss: 0.5370 - acc: 0.7321 - val_loss: 0.5674 - val_acc: 0.7361\n",
      "Epoch 242/400\n",
      "8872/8872 [==============================] - 0s 13us/step - loss: 0.5341 - acc: 0.7272 - val_loss: 0.5645 - val_acc: 0.7336\n",
      "Epoch 243/400\n",
      "8872/8872 [==============================] - 0s 14us/step - loss: 0.5378 - acc: 0.7260 - val_loss: 0.5668 - val_acc: 0.7356\n",
      "Epoch 244/400\n",
      "8872/8872 [==============================] - 0s 19us/step - loss: 0.5366 - acc: 0.7257 - val_loss: 0.5610 - val_acc: 0.7400\n",
      "Epoch 245/400\n",
      "8872/8872 [==============================] - 0s 16us/step - loss: 0.5364 - acc: 0.7281 - val_loss: 0.5672 - val_acc: 0.7359\n",
      "Epoch 246/400\n",
      "8872/8872 [==============================] - 0s 14us/step - loss: 0.5357 - acc: 0.7261 - val_loss: 0.5636 - val_acc: 0.7378\n",
      "Epoch 247/400\n",
      "8872/8872 [==============================] - 0s 14us/step - loss: 0.5387 - acc: 0.7266 - val_loss: 0.5646 - val_acc: 0.7361\n",
      "Epoch 248/400\n",
      "8872/8872 [==============================] - 0s 14us/step - loss: 0.5384 - acc: 0.7246 - val_loss: 0.5672 - val_acc: 0.7350\n",
      "Epoch 249/400\n",
      "8872/8872 [==============================] - 0s 14us/step - loss: 0.5341 - acc: 0.7323 - val_loss: 0.5688 - val_acc: 0.7336\n",
      "Epoch 250/400\n",
      "8872/8872 [==============================] - 0s 14us/step - loss: 0.5339 - acc: 0.7326 - val_loss: 0.5642 - val_acc: 0.7348\n",
      "Epoch 251/400\n",
      "8872/8872 [==============================] - 0s 14us/step - loss: 0.5352 - acc: 0.7298 - val_loss: 0.5638 - val_acc: 0.7372\n",
      "Epoch 252/400\n",
      "8872/8872 [==============================] - 0s 15us/step - loss: 0.5359 - acc: 0.7335 - val_loss: 0.5725 - val_acc: 0.7277\n",
      "Epoch 253/400\n",
      "8872/8872 [==============================] - 0s 14us/step - loss: 0.5355 - acc: 0.7282 - val_loss: 0.5668 - val_acc: 0.7345\n",
      "Epoch 254/400\n",
      "8872/8872 [==============================] - 0s 14us/step - loss: 0.5360 - acc: 0.7282 - val_loss: 0.5657 - val_acc: 0.7351\n",
      "Epoch 255/400\n",
      "8872/8872 [==============================] - 0s 14us/step - loss: 0.5330 - acc: 0.7300 - val_loss: 0.5662 - val_acc: 0.7376\n",
      "Epoch 256/400\n",
      "8872/8872 [==============================] - 0s 14us/step - loss: 0.5348 - acc: 0.7273 - val_loss: 0.5699 - val_acc: 0.7320\n",
      "Epoch 257/400\n",
      "8872/8872 [==============================] - 0s 14us/step - loss: 0.5350 - acc: 0.7285 - val_loss: 0.5620 - val_acc: 0.7403\n",
      "Epoch 258/400\n",
      "8872/8872 [==============================] - 0s 14us/step - loss: 0.5358 - acc: 0.7303 - val_loss: 0.5711 - val_acc: 0.7295\n",
      "Epoch 259/400\n",
      "8872/8872 [==============================] - 0s 13us/step - loss: 0.5349 - acc: 0.7291 - val_loss: 0.5638 - val_acc: 0.7369\n",
      "Epoch 260/400\n",
      "8872/8872 [==============================] - 0s 15us/step - loss: 0.5356 - acc: 0.7313 - val_loss: 0.5728 - val_acc: 0.7284\n",
      "Epoch 261/400\n",
      "8872/8872 [==============================] - 0s 13us/step - loss: 0.5361 - acc: 0.7255 - val_loss: 0.5599 - val_acc: 0.7416\n",
      "Epoch 262/400\n",
      "8872/8872 [==============================] - 0s 13us/step - loss: 0.5328 - acc: 0.7361 - val_loss: 0.5672 - val_acc: 0.7335\n",
      "Epoch 263/400\n",
      "8872/8872 [==============================] - 0s 14us/step - loss: 0.5357 - acc: 0.7271 - val_loss: 0.5613 - val_acc: 0.7397\n",
      "Epoch 264/400\n",
      "8872/8872 [==============================] - 0s 14us/step - loss: 0.5345 - acc: 0.7275 - val_loss: 0.5594 - val_acc: 0.7419\n",
      "Epoch 265/400\n",
      "8872/8872 [==============================] - 0s 15us/step - loss: 0.5349 - acc: 0.7329 - val_loss: 0.5669 - val_acc: 0.7369\n",
      "Epoch 266/400\n",
      "8872/8872 [==============================] - 0s 15us/step - loss: 0.5345 - acc: 0.7293 - val_loss: 0.5674 - val_acc: 0.7347\n",
      "Epoch 267/400\n",
      "8872/8872 [==============================] - 0s 14us/step - loss: 0.5342 - acc: 0.7289 - val_loss: 0.5672 - val_acc: 0.7353\n",
      "Epoch 268/400\n",
      "8872/8872 [==============================] - 0s 15us/step - loss: 0.5329 - acc: 0.7310 - val_loss: 0.5600 - val_acc: 0.7394\n",
      "Epoch 269/400\n",
      "8872/8872 [==============================] - 0s 13us/step - loss: 0.5354 - acc: 0.7264 - val_loss: 0.5752 - val_acc: 0.7241\n",
      "Epoch 270/400\n",
      "8872/8872 [==============================] - 0s 14us/step - loss: 0.5362 - acc: 0.7293 - val_loss: 0.5651 - val_acc: 0.7388\n",
      "Epoch 271/400\n",
      "8872/8872 [==============================] - 0s 15us/step - loss: 0.5340 - acc: 0.7295 - val_loss: 0.5695 - val_acc: 0.7292\n",
      "Epoch 272/400\n",
      "8872/8872 [==============================] - 0s 14us/step - loss: 0.5308 - acc: 0.7358 - val_loss: 0.5602 - val_acc: 0.7427\n",
      "Epoch 273/400\n",
      "8872/8872 [==============================] - 0s 14us/step - loss: 0.5362 - acc: 0.7312 - val_loss: 0.5675 - val_acc: 0.7335\n",
      "Epoch 274/400\n",
      "8872/8872 [==============================] - 0s 16us/step - loss: 0.5372 - acc: 0.7257 - val_loss: 0.5655 - val_acc: 0.7350\n",
      "Epoch 275/400\n",
      "8872/8872 [==============================] - 0s 15us/step - loss: 0.5363 - acc: 0.7277 - val_loss: 0.5634 - val_acc: 0.7394\n",
      "Epoch 276/400\n",
      "8872/8872 [==============================] - 0s 17us/step - loss: 0.5361 - acc: 0.7280 - val_loss: 0.5717 - val_acc: 0.7307\n",
      "Epoch 277/400\n",
      "8872/8872 [==============================] - 0s 16us/step - loss: 0.5351 - acc: 0.7300 - val_loss: 0.5707 - val_acc: 0.7342\n",
      "Epoch 278/400\n",
      "8872/8872 [==============================] - 0s 16us/step - loss: 0.5354 - acc: 0.7267 - val_loss: 0.5644 - val_acc: 0.7327\n",
      "Epoch 279/400\n",
      "8872/8872 [==============================] - 0s 18us/step - loss: 0.5325 - acc: 0.7346 - val_loss: 0.5647 - val_acc: 0.7350\n",
      "Epoch 280/400\n",
      "8872/8872 [==============================] - 0s 18us/step - loss: 0.5331 - acc: 0.7295 - val_loss: 0.5721 - val_acc: 0.7301\n",
      "Epoch 281/400\n",
      "8872/8872 [==============================] - 0s 13us/step - loss: 0.5351 - acc: 0.7280 - val_loss: 0.5628 - val_acc: 0.7344\n",
      "Epoch 282/400\n",
      "8872/8872 [==============================] - 0s 13us/step - loss: 0.5368 - acc: 0.7291 - val_loss: 0.5718 - val_acc: 0.7338\n",
      "Epoch 283/400\n",
      "8872/8872 [==============================] - 0s 15us/step - loss: 0.5359 - acc: 0.7260 - val_loss: 0.5604 - val_acc: 0.7378\n",
      "Epoch 284/400\n",
      "8872/8872 [==============================] - 0s 16us/step - loss: 0.5309 - acc: 0.7306 - val_loss: 0.5697 - val_acc: 0.7329\n",
      "Epoch 285/400\n",
      "8872/8872 [==============================] - 0s 13us/step - loss: 0.5320 - acc: 0.7305 - val_loss: 0.5643 - val_acc: 0.7372\n",
      "Epoch 286/400\n",
      "8872/8872 [==============================] - 0s 13us/step - loss: 0.5341 - acc: 0.7326 - val_loss: 0.5641 - val_acc: 0.7361\n",
      "Epoch 287/400\n",
      "8872/8872 [==============================] - 0s 14us/step - loss: 0.5361 - acc: 0.7303 - val_loss: 0.5719 - val_acc: 0.7299\n",
      "Epoch 288/400\n",
      "8872/8872 [==============================] - 0s 13us/step - loss: 0.5338 - acc: 0.7282 - val_loss: 0.5728 - val_acc: 0.7308\n",
      "Epoch 289/400\n",
      "8872/8872 [==============================] - 0s 14us/step - loss: 0.5348 - acc: 0.7293 - val_loss: 0.5629 - val_acc: 0.7393\n",
      "Epoch 290/400\n",
      "8872/8872 [==============================] - 0s 14us/step - loss: 0.5309 - acc: 0.7305 - val_loss: 0.5706 - val_acc: 0.7317\n",
      "Epoch 291/400\n",
      "8872/8872 [==============================] - 0s 15us/step - loss: 0.5339 - acc: 0.7303 - val_loss: 0.5724 - val_acc: 0.7323\n",
      "Epoch 292/400\n",
      "8872/8872 [==============================] - 0s 13us/step - loss: 0.5337 - acc: 0.7269 - val_loss: 0.5697 - val_acc: 0.7295\n",
      "Epoch 293/400\n",
      "8872/8872 [==============================] - 0s 14us/step - loss: 0.5339 - acc: 0.7314 - val_loss: 0.5725 - val_acc: 0.7270\n",
      "Epoch 294/400\n",
      "8872/8872 [==============================] - 0s 14us/step - loss: 0.5312 - acc: 0.7310 - val_loss: 0.5639 - val_acc: 0.7376\n",
      "Epoch 295/400\n",
      "8872/8872 [==============================] - 0s 14us/step - loss: 0.5363 - acc: 0.7263 - val_loss: 0.5752 - val_acc: 0.7268\n",
      "Epoch 296/400\n",
      "8872/8872 [==============================] - 0s 14us/step - loss: 0.5340 - acc: 0.7280 - val_loss: 0.5647 - val_acc: 0.7387\n",
      "Epoch 297/400\n",
      "8872/8872 [==============================] - 0s 15us/step - loss: 0.5350 - acc: 0.7317 - val_loss: 0.5721 - val_acc: 0.7332\n",
      "Epoch 298/400\n",
      "8872/8872 [==============================] - 0s 15us/step - loss: 0.5336 - acc: 0.7288 - val_loss: 0.5671 - val_acc: 0.7361\n",
      "Epoch 299/400\n",
      "8872/8872 [==============================] - 0s 14us/step - loss: 0.5324 - acc: 0.7343 - val_loss: 0.5662 - val_acc: 0.7351\n",
      "Epoch 300/400\n",
      "8872/8872 [==============================] - 0s 14us/step - loss: 0.5317 - acc: 0.7358 - val_loss: 0.5656 - val_acc: 0.7370\n",
      "Epoch 301/400\n",
      "8872/8872 [==============================] - 0s 15us/step - loss: 0.5326 - acc: 0.7314 - val_loss: 0.5694 - val_acc: 0.7357\n",
      "Epoch 302/400\n",
      "8872/8872 [==============================] - 0s 15us/step - loss: 0.5320 - acc: 0.7298 - val_loss: 0.5734 - val_acc: 0.7280\n",
      "Epoch 303/400\n",
      "8872/8872 [==============================] - 0s 14us/step - loss: 0.5330 - acc: 0.7300 - val_loss: 0.5607 - val_acc: 0.7397\n",
      "Epoch 304/400\n",
      "8872/8872 [==============================] - 0s 14us/step - loss: 0.5354 - acc: 0.7271 - val_loss: 0.5740 - val_acc: 0.7234\n",
      "Epoch 305/400\n",
      "8872/8872 [==============================] - 0s 14us/step - loss: 0.5326 - acc: 0.7310 - val_loss: 0.5644 - val_acc: 0.7381\n",
      "Epoch 306/400\n",
      "8872/8872 [==============================] - 0s 14us/step - loss: 0.5321 - acc: 0.7291 - val_loss: 0.5639 - val_acc: 0.7372\n",
      "Epoch 307/400\n",
      "8872/8872 [==============================] - 0s 14us/step - loss: 0.5312 - acc: 0.7357 - val_loss: 0.5730 - val_acc: 0.7317\n",
      "Epoch 308/400\n",
      "8872/8872 [==============================] - 0s 14us/step - loss: 0.5324 - acc: 0.7294 - val_loss: 0.5640 - val_acc: 0.7390\n",
      "Epoch 309/400\n",
      "8872/8872 [==============================] - 0s 13us/step - loss: 0.5332 - acc: 0.7311 - val_loss: 0.5730 - val_acc: 0.7332\n",
      "Epoch 310/400\n",
      "8872/8872 [==============================] - 0s 14us/step - loss: 0.5354 - acc: 0.7302 - val_loss: 0.5625 - val_acc: 0.7379\n",
      "Epoch 311/400\n",
      "8872/8872 [==============================] - 0s 14us/step - loss: 0.5313 - acc: 0.7319 - val_loss: 0.5612 - val_acc: 0.7431\n",
      "Epoch 312/400\n",
      "8872/8872 [==============================] - 0s 14us/step - loss: 0.5293 - acc: 0.7330 - val_loss: 0.5747 - val_acc: 0.7286\n",
      "Epoch 313/400\n",
      "8872/8872 [==============================] - 0s 15us/step - loss: 0.5341 - acc: 0.7294 - val_loss: 0.5641 - val_acc: 0.7400\n",
      "Epoch 314/400\n",
      "8872/8872 [==============================] - 0s 14us/step - loss: 0.5322 - acc: 0.7293 - val_loss: 0.5726 - val_acc: 0.7326\n",
      "Epoch 315/400\n",
      "8872/8872 [==============================] - 0s 14us/step - loss: 0.5338 - acc: 0.7315 - val_loss: 0.5656 - val_acc: 0.7341\n",
      "Epoch 316/400\n",
      "8872/8872 [==============================] - 0s 15us/step - loss: 0.5305 - acc: 0.7341 - val_loss: 0.5604 - val_acc: 0.7418\n",
      "Epoch 317/400\n",
      "8872/8872 [==============================] - 0s 14us/step - loss: 0.5344 - acc: 0.7299 - val_loss: 0.5706 - val_acc: 0.7333\n",
      "Epoch 318/400\n",
      "8872/8872 [==============================] - 0s 14us/step - loss: 0.5335 - acc: 0.7285 - val_loss: 0.5652 - val_acc: 0.7373\n",
      "Epoch 319/400\n",
      "8872/8872 [==============================] - 0s 15us/step - loss: 0.5317 - acc: 0.7312 - val_loss: 0.5686 - val_acc: 0.7338\n",
      "Epoch 320/400\n",
      "8872/8872 [==============================] - 0s 16us/step - loss: 0.5325 - acc: 0.7329 - val_loss: 0.5695 - val_acc: 0.7347\n",
      "Epoch 321/400\n",
      "8872/8872 [==============================] - 0s 15us/step - loss: 0.5322 - acc: 0.7308 - val_loss: 0.5670 - val_acc: 0.7350\n",
      "Epoch 322/400\n",
      "8872/8872 [==============================] - 0s 14us/step - loss: 0.5301 - acc: 0.7362 - val_loss: 0.5597 - val_acc: 0.7412\n",
      "Epoch 323/400\n",
      "8872/8872 [==============================] - 0s 15us/step - loss: 0.5312 - acc: 0.7311 - val_loss: 0.5771 - val_acc: 0.7262\n",
      "Epoch 324/400\n",
      "8872/8872 [==============================] - 0s 14us/step - loss: 0.5330 - acc: 0.7290 - val_loss: 0.5623 - val_acc: 0.7382\n",
      "Epoch 325/400\n",
      "8872/8872 [==============================] - 0s 15us/step - loss: 0.5319 - acc: 0.7303 - val_loss: 0.5738 - val_acc: 0.7277\n",
      "Epoch 326/400\n",
      "8872/8872 [==============================] - 0s 14us/step - loss: 0.5328 - acc: 0.7323 - val_loss: 0.5612 - val_acc: 0.7384\n",
      "Epoch 327/400\n",
      "8872/8872 [==============================] - 0s 14us/step - loss: 0.5296 - acc: 0.7358 - val_loss: 0.5708 - val_acc: 0.7311\n",
      "Epoch 328/400\n",
      "8872/8872 [==============================] - 0s 16us/step - loss: 0.5308 - acc: 0.7314 - val_loss: 0.5673 - val_acc: 0.7354\n",
      "Epoch 329/400\n",
      "8872/8872 [==============================] - 0s 16us/step - loss: 0.5295 - acc: 0.7303 - val_loss: 0.5728 - val_acc: 0.7310\n",
      "Epoch 330/400\n",
      "8872/8872 [==============================] - 0s 16us/step - loss: 0.5322 - acc: 0.7352 - val_loss: 0.5673 - val_acc: 0.7323\n",
      "Epoch 331/400\n",
      "8872/8872 [==============================] - 0s 17us/step - loss: 0.5325 - acc: 0.7328 - val_loss: 0.5678 - val_acc: 0.7332\n",
      "Epoch 332/400\n",
      "8872/8872 [==============================] - 0s 16us/step - loss: 0.5326 - acc: 0.7329 - val_loss: 0.5715 - val_acc: 0.7314\n",
      "Epoch 333/400\n",
      "8872/8872 [==============================] - 0s 15us/step - loss: 0.5295 - acc: 0.7335 - val_loss: 0.5662 - val_acc: 0.7351\n",
      "Epoch 334/400\n",
      "8872/8872 [==============================] - 0s 15us/step - loss: 0.5320 - acc: 0.7313 - val_loss: 0.5791 - val_acc: 0.7286\n",
      "Epoch 335/400\n",
      "8872/8872 [==============================] - 0s 16us/step - loss: 0.5318 - acc: 0.7311 - val_loss: 0.5636 - val_acc: 0.7400\n",
      "Epoch 336/400\n",
      "8872/8872 [==============================] - 0s 17us/step - loss: 0.5318 - acc: 0.7298 - val_loss: 0.5665 - val_acc: 0.7350\n",
      "Epoch 337/400\n",
      "8872/8872 [==============================] - 0s 16us/step - loss: 0.5327 - acc: 0.7315 - val_loss: 0.5687 - val_acc: 0.7307\n",
      "Epoch 338/400\n",
      "8872/8872 [==============================] - 0s 17us/step - loss: 0.5325 - acc: 0.7319 - val_loss: 0.5652 - val_acc: 0.7370\n",
      "Epoch 339/400\n",
      "8872/8872 [==============================] - 0s 16us/step - loss: 0.5287 - acc: 0.7332 - val_loss: 0.5736 - val_acc: 0.7336\n",
      "Epoch 340/400\n",
      "8872/8872 [==============================] - 0s 16us/step - loss: 0.5304 - acc: 0.7326 - val_loss: 0.5709 - val_acc: 0.7317\n",
      "Epoch 341/400\n",
      "8872/8872 [==============================] - 0s 13us/step - loss: 0.5308 - acc: 0.7350 - val_loss: 0.5668 - val_acc: 0.7350\n",
      "Epoch 342/400\n",
      "8872/8872 [==============================] - 0s 16us/step - loss: 0.5303 - acc: 0.7313 - val_loss: 0.5738 - val_acc: 0.7290\n",
      "Epoch 343/400\n",
      "8872/8872 [==============================] - 0s 15us/step - loss: 0.5327 - acc: 0.7360 - val_loss: 0.5727 - val_acc: 0.7310\n",
      "Epoch 344/400\n",
      "8872/8872 [==============================] - 0s 16us/step - loss: 0.5324 - acc: 0.7321 - val_loss: 0.5589 - val_acc: 0.7410\n",
      "Epoch 345/400\n",
      "8872/8872 [==============================] - 0s 15us/step - loss: 0.5341 - acc: 0.7299 - val_loss: 0.5721 - val_acc: 0.7313\n",
      "Epoch 346/400\n",
      "8872/8872 [==============================] - 0s 14us/step - loss: 0.5336 - acc: 0.7305 - val_loss: 0.5686 - val_acc: 0.7336\n",
      "Epoch 347/400\n",
      "8872/8872 [==============================] - 0s 15us/step - loss: 0.5297 - acc: 0.7311 - val_loss: 0.5664 - val_acc: 0.7332\n",
      "Epoch 348/400\n",
      "8872/8872 [==============================] - 0s 14us/step - loss: 0.5340 - acc: 0.7306 - val_loss: 0.5668 - val_acc: 0.7361\n",
      "Epoch 349/400\n",
      "8872/8872 [==============================] - 0s 15us/step - loss: 0.5313 - acc: 0.7326 - val_loss: 0.5713 - val_acc: 0.7292\n",
      "Epoch 350/400\n",
      "8872/8872 [==============================] - 0s 18us/step - loss: 0.5325 - acc: 0.7323 - val_loss: 0.5634 - val_acc: 0.7364\n",
      "Epoch 351/400\n",
      "8872/8872 [==============================] - 0s 16us/step - loss: 0.5329 - acc: 0.7293 - val_loss: 0.5623 - val_acc: 0.7359\n",
      "Epoch 352/400\n",
      "8872/8872 [==============================] - 0s 15us/step - loss: 0.5293 - acc: 0.7332 - val_loss: 0.5646 - val_acc: 0.7366\n",
      "Epoch 353/400\n",
      "8872/8872 [==============================] - 0s 15us/step - loss: 0.5315 - acc: 0.7350 - val_loss: 0.5693 - val_acc: 0.7326\n",
      "Epoch 354/400\n",
      "8872/8872 [==============================] - 0s 14us/step - loss: 0.5322 - acc: 0.7333 - val_loss: 0.5708 - val_acc: 0.7321\n",
      "Epoch 355/400\n",
      "8872/8872 [==============================] - 0s 15us/step - loss: 0.5306 - acc: 0.7339 - val_loss: 0.5715 - val_acc: 0.7295\n",
      "Epoch 356/400\n",
      "8872/8872 [==============================] - 0s 17us/step - loss: 0.5304 - acc: 0.7308 - val_loss: 0.5650 - val_acc: 0.7396\n",
      "Epoch 357/400\n",
      "8872/8872 [==============================] - 0s 15us/step - loss: 0.5324 - acc: 0.7310 - val_loss: 0.5703 - val_acc: 0.7317\n",
      "Epoch 358/400\n",
      "8872/8872 [==============================] - 0s 15us/step - loss: 0.5291 - acc: 0.7349 - val_loss: 0.5683 - val_acc: 0.7363\n",
      "Epoch 359/400\n",
      "8872/8872 [==============================] - 0s 14us/step - loss: 0.5297 - acc: 0.7316 - val_loss: 0.5682 - val_acc: 0.7366\n",
      "Epoch 360/400\n",
      "8872/8872 [==============================] - 0s 15us/step - loss: 0.5307 - acc: 0.7305 - val_loss: 0.5601 - val_acc: 0.7393\n",
      "Epoch 361/400\n",
      "8872/8872 [==============================] - 0s 14us/step - loss: 0.5337 - acc: 0.7280 - val_loss: 0.5703 - val_acc: 0.7316\n",
      "Epoch 362/400\n",
      "8872/8872 [==============================] - 0s 15us/step - loss: 0.5319 - acc: 0.7326 - val_loss: 0.5669 - val_acc: 0.7341\n",
      "Epoch 363/400\n",
      "8872/8872 [==============================] - 0s 14us/step - loss: 0.5306 - acc: 0.7341 - val_loss: 0.5712 - val_acc: 0.7332\n",
      "Epoch 364/400\n",
      "8872/8872 [==============================] - 0s 15us/step - loss: 0.5284 - acc: 0.7347 - val_loss: 0.5665 - val_acc: 0.7359\n",
      "Epoch 365/400\n",
      "8872/8872 [==============================] - 0s 14us/step - loss: 0.5302 - acc: 0.7358 - val_loss: 0.5701 - val_acc: 0.7347\n",
      "Epoch 366/400\n",
      "8872/8872 [==============================] - 0s 14us/step - loss: 0.5312 - acc: 0.7316 - val_loss: 0.5673 - val_acc: 0.7363\n",
      "Epoch 367/400\n",
      "8872/8872 [==============================] - 0s 14us/step - loss: 0.5316 - acc: 0.7325 - val_loss: 0.5738 - val_acc: 0.7302\n",
      "Epoch 368/400\n",
      "8872/8872 [==============================] - 0s 16us/step - loss: 0.5340 - acc: 0.7329 - val_loss: 0.5706 - val_acc: 0.7299\n",
      "Epoch 369/400\n",
      "8872/8872 [==============================] - 0s 14us/step - loss: 0.5335 - acc: 0.7308 - val_loss: 0.5673 - val_acc: 0.7336\n",
      "Epoch 370/400\n",
      "8872/8872 [==============================] - 0s 14us/step - loss: 0.5288 - acc: 0.7266 - val_loss: 0.5662 - val_acc: 0.7333\n",
      "Epoch 371/400\n",
      "8872/8872 [==============================] - 0s 14us/step - loss: 0.5297 - acc: 0.7372 - val_loss: 0.5694 - val_acc: 0.7326\n",
      "Epoch 372/400\n",
      "8872/8872 [==============================] - 0s 14us/step - loss: 0.5320 - acc: 0.7337 - val_loss: 0.5726 - val_acc: 0.7329\n",
      "Epoch 373/400\n",
      "8872/8872 [==============================] - 0s 14us/step - loss: 0.5346 - acc: 0.7254 - val_loss: 0.5693 - val_acc: 0.7330\n",
      "Epoch 374/400\n",
      "8872/8872 [==============================] - 0s 14us/step - loss: 0.5302 - acc: 0.7304 - val_loss: 0.5636 - val_acc: 0.7399\n",
      "Epoch 375/400\n",
      "8872/8872 [==============================] - 0s 14us/step - loss: 0.5318 - acc: 0.7326 - val_loss: 0.5691 - val_acc: 0.7316\n",
      "Epoch 376/400\n",
      "8872/8872 [==============================] - 0s 15us/step - loss: 0.5298 - acc: 0.7343 - val_loss: 0.5683 - val_acc: 0.7311\n",
      "Epoch 377/400\n",
      "8872/8872 [==============================] - 0s 16us/step - loss: 0.5269 - acc: 0.7391 - val_loss: 0.5651 - val_acc: 0.7347\n",
      "Epoch 378/400\n",
      "8872/8872 [==============================] - 0s 14us/step - loss: 0.5276 - acc: 0.7396 - val_loss: 0.5740 - val_acc: 0.7279\n",
      "Epoch 379/400\n",
      "8872/8872 [==============================] - 0s 14us/step - loss: 0.5298 - acc: 0.7342 - val_loss: 0.5647 - val_acc: 0.7363\n",
      "Epoch 380/400\n",
      "8872/8872 [==============================] - 0s 15us/step - loss: 0.5313 - acc: 0.7313 - val_loss: 0.5671 - val_acc: 0.7326\n",
      "Epoch 381/400\n",
      "8872/8872 [==============================] - 0s 16us/step - loss: 0.5321 - acc: 0.7384 - val_loss: 0.5759 - val_acc: 0.7287\n",
      "Epoch 382/400\n",
      "8872/8872 [==============================] - 0s 14us/step - loss: 0.5290 - acc: 0.7360 - val_loss: 0.5681 - val_acc: 0.7335\n",
      "Epoch 383/400\n",
      "8872/8872 [==============================] - 0s 14us/step - loss: 0.5307 - acc: 0.7324 - val_loss: 0.5725 - val_acc: 0.7286\n",
      "Epoch 384/400\n",
      "8872/8872 [==============================] - 0s 15us/step - loss: 0.5292 - acc: 0.7346 - val_loss: 0.5636 - val_acc: 0.7350\n",
      "Epoch 385/400\n",
      "8872/8872 [==============================] - 0s 14us/step - loss: 0.5315 - acc: 0.7358 - val_loss: 0.5650 - val_acc: 0.7350\n",
      "Epoch 386/400\n",
      "8872/8872 [==============================] - 0s 14us/step - loss: 0.5321 - acc: 0.7311 - val_loss: 0.5736 - val_acc: 0.7304\n",
      "Epoch 387/400\n",
      "8872/8872 [==============================] - 0s 15us/step - loss: 0.5322 - acc: 0.7322 - val_loss: 0.5630 - val_acc: 0.7370\n",
      "Epoch 388/400\n",
      "8872/8872 [==============================] - 0s 14us/step - loss: 0.5316 - acc: 0.7375 - val_loss: 0.5641 - val_acc: 0.7321\n",
      "Epoch 389/400\n",
      "8872/8872 [==============================] - 0s 14us/step - loss: 0.5330 - acc: 0.7361 - val_loss: 0.5755 - val_acc: 0.7267\n",
      "Epoch 390/400\n",
      "8872/8872 [==============================] - 0s 15us/step - loss: 0.5263 - acc: 0.7322 - val_loss: 0.5675 - val_acc: 0.7313\n",
      "Epoch 391/400\n",
      "8872/8872 [==============================] - 0s 13us/step - loss: 0.5316 - acc: 0.7302 - val_loss: 0.5734 - val_acc: 0.7279\n",
      "Epoch 392/400\n",
      "8872/8872 [==============================] - 0s 15us/step - loss: 0.5302 - acc: 0.7344 - val_loss: 0.5611 - val_acc: 0.7397\n",
      "Epoch 393/400\n",
      "8872/8872 [==============================] - 0s 13us/step - loss: 0.5278 - acc: 0.7352 - val_loss: 0.5753 - val_acc: 0.7234\n",
      "Epoch 394/400\n",
      "8872/8872 [==============================] - 0s 15us/step - loss: 0.5297 - acc: 0.7364 - val_loss: 0.5647 - val_acc: 0.7342\n",
      "Epoch 395/400\n",
      "8872/8872 [==============================] - 0s 14us/step - loss: 0.5290 - acc: 0.7338 - val_loss: 0.5749 - val_acc: 0.7239\n",
      "Epoch 396/400\n",
      "8872/8872 [==============================] - 0s 14us/step - loss: 0.5303 - acc: 0.7331 - val_loss: 0.5675 - val_acc: 0.7308\n",
      "Epoch 397/400\n",
      "8872/8872 [==============================] - 0s 15us/step - loss: 0.5352 - acc: 0.7296 - val_loss: 0.5611 - val_acc: 0.7384\n",
      "Epoch 398/400\n",
      "8872/8872 [==============================] - 0s 15us/step - loss: 0.5330 - acc: 0.7348 - val_loss: 0.5707 - val_acc: 0.7308\n",
      "Epoch 399/400\n",
      "8872/8872 [==============================] - 0s 13us/step - loss: 0.5292 - acc: 0.7316 - val_loss: 0.5631 - val_acc: 0.7333\n",
      "Epoch 400/400\n",
      "8872/8872 [==============================] - 0s 15us/step - loss: 0.5304 - acc: 0.7268 - val_loss: 0.5677 - val_acc: 0.7335\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Dense(32, input_dim=X.shape[1]))#,kernel_regularizer=l1_l2(l1=0.001,l2=0.001)))\n",
    "model.add(LeakyReLU(alpha=0.2))\n",
    "model.add(Dropout(0.05))\n",
    "model.add(Dense(16))##,kernel_regularizer=l1_l2(l1=0.001,l2=0.001)))\n",
    "model.add(LeakyReLU(alpha=0.2))\n",
    "model.add(Dropout(0.05))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.compile(optimizer=adam, loss='binary_crossentropy', metrics=['accuracy'])\n",
    "network_history=model.fit(X, Y,validation_data=(X_test,Y_test),batch_size=512 ,epochs=400)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 300
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 50867,
     "status": "ok",
     "timestamp": 1571504320897,
     "user": {
      "displayName": "Mirko Giugliano",
      "photoUrl": "",
      "userId": "07128242895425647455"
     },
     "user_tz": -120
    },
    "id": "bYE_7S-AulQT",
    "outputId": "6fcfbb1a-4c0e-4af5-bc6e-3cfc2eb655bb"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7f39a5c6b748>"
      ]
     },
     "execution_count": 51,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZIAAAEKCAYAAAA4t9PUAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "x_plot = list(range(1,401))\n",
    "plt.figure()\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.plot(x_plot, network_history.history['acc'])\n",
    "plt.plot(x_plot, network_history.history['val_acc'])\n",
    "plt.legend(['Training', 'Validation'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 170
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 44443,
     "status": "ok",
     "timestamp": 1571504321219,
     "user": {
      "displayName": "Mirko Giugliano",
      "photoUrl": "",
      "userId": "07128242895425647455"
     },
     "user_tz": -120
    },
    "id": "7is0W5YSulTg",
    "outputId": "83321440-739f-4a07-8076-098073560fc6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "confusion matrix\n",
      " [[3972 1241]\n",
      " [ 558  979]]\n",
      "precision\n",
      " [0.87682119 0.44099099]\n",
      "recall\n",
      " [0.7619413  0.63695511]\n",
      "f-score\n",
      " [0.81535461 0.5211605 ]\n"
     ]
    }
   ],
   "source": [
    "y_pred=model.predict(X_test)\n",
    "y_pred=y_pred>0.5\n",
    "\n",
    "cm=confusion_matrix(Y_test,y_pred)\n",
    "prf=precision_recall_fscore_support(Y_test,y_pred)\n",
    "\n",
    "print(f\"confusion matrix\\n {cm}\")\n",
    "print(f\"precision\\n {prf[0]}\")\n",
    "print(f\"recall\\n {prf[1]}\")\n",
    "print(f\"f-score\\n {prf[2]}\")\n",
    "\n",
    "\n",
    "                   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 170
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 46130,
     "status": "ok",
     "timestamp": 1571504320898,
     "user": {
      "displayName": "Mirko Giugliano",
      "photoUrl": "",
      "userId": "07128242895425647455"
     },
     "user_tz": -120
    },
    "id": "--q7to063Qob",
    "outputId": "7dd52e5c-a180-4c09-834b-47d78c4de98e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.77      0.82      5213\n",
      "           1       0.45      0.63      0.52      1537\n",
      "\n",
      "    accuracy                           0.74      6750\n",
      "   macro avg       0.66      0.70      0.67      6750\n",
      "weighted avg       0.78      0.74      0.75      6750\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cr=classification_report(Y_test, y_pred)\n",
    "print(cr)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "peras2.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
